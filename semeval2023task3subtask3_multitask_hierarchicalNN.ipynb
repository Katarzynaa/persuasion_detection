{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0OWqzAD081Ph"
   },
   "source": [
    "# Multitask Hierachical Neural Network for Persuasion Techniques Detection\n",
    "\n",
    "This is a solution of kb team for Semeval 2023 task 3 subtask 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 109,
     "status": "ok",
     "timestamp": 1671050265516,
     "user": {
      "displayName": "Katarzyna Baraniak",
      "userId": "09959407714606546607"
     },
     "user_tz": -60
    },
    "id": "GD5x6JMgZTio"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "def seed_everything(seed=73):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    # some cudnn methods can be random even after fixing the seed unless you tell it to be deterministic\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "seed_everything(1234)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 79,
     "status": "ok",
     "timestamp": 1671050265517,
     "user": {
      "displayName": "Katarzyna Baraniak",
      "userId": "09959407714606546607"
     },
     "user_tz": -60
    },
    "id": "V2LNzgO5kKcr",
    "outputId": "fd6ed375-2d29-4267-a1b4-834c2f1cad99",
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "lang=\"en\" #set language"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## READ input data and spans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "def make_dataframe_subtask3(input_folder, labels_fn=None, spans=None):\n",
    "    txt_files = [f for  f in os.listdir(spans) if f.endswith('.txt')]\n",
    "    print(\"number of files: \", len(txt_files))\n",
    "    # print()\n",
    "    df_labels = pd.DataFrame(columns=[\"id\",\"label\", \"start\", \"end\"])\n",
    "    # print(txt_files)\n",
    "    for i, js in enumerate(txt_files):\n",
    "        # print(js\n",
    "        with open(os.path.join(spans, js)) as file:\n",
    "            line=file.readline()\n",
    "            # print(line)\n",
    "            while line!=\"\":\n",
    "                l=line.split()\n",
    "                # print(l[0])\n",
    "                df_labels=df_labels.append({\"id\":l[0], \"label\":l[1], \"start\":l[2], \"end\":l[3]}, ignore_index=True)\n",
    "                line=file.readline()\n",
    "\n",
    "    #MAKE TXT DATAFRAME\n",
    "    text = pd.DataFrame()\n",
    "    articles=[]\n",
    "    for fil in tqdm(filter(lambda x: x.endswith('.txt') and x.startswith(\"art\"), os.listdir(input_folder))):\n",
    "        iD = fil[7:].split('.')[0]\n",
    "        # print(\"------------------------------------------\")\n",
    "        # print(fil)\n",
    "        art_labels=df_labels[df_labels[\"id\"]==iD]\n",
    "        art_labels[\"start\"]=art_labels[\"start\"].astype(int)\n",
    "        art_labels[\"end\"]=art_labels[\"end\"].astype(int)\n",
    "\n",
    "        article=open(input_folder+fil,'r', encoding=\"utf-8\", errors='ignore').read()\n",
    "        # print(article)\n",
    "        for row in art_labels.iterrows():\n",
    "            start= int(row[1][\"start\"])#-12\n",
    "            end= int(row[1][\"end\"])#-12\n",
    "            # print(article[start : end], row[1][\"label\"])\n",
    "        lines = list(enumerate(open(input_folder+fil,'r', encoding=\"utf-8\", errors='ignore').read().splitlines(),1))\n",
    "        start_line=0\n",
    "        end_line=0\n",
    "        start_ends=()\n",
    "        for line in lines:\n",
    "            # print(line[1])\n",
    "            start_line=end_line\n",
    "            end_line=end_line+len(line[1])\n",
    "            # print(start_line)\n",
    "            od_do=list()\n",
    "            for span in art_labels[(art_labels.start>=start_line)&(art_labels.end<end_line)].iterrows():\n",
    "                od=span[1].start-start_line\n",
    "                do=span[1].end-start_line\n",
    "                od_do.append({\"start\":od, \"end\":do, \"label\":span[1][\"label\"]})\n",
    "            text=text.append({\"id\": iD, \"line\":line[0], \"text\":line[1], \"spans\":od_do}, ignore_index=True)\n",
    "            \n",
    "                \n",
    "        # text.extend([(iD,) + line for line in lines])\n",
    "    print(text)\n",
    "    df_text = pd.DataFrame(text, columns=['id','line','text', \"spans\"])\n",
    "    df_text.id = df_text.id.apply(int)\n",
    "    df_text.line = df_text.line.apply(int)\n",
    "    df_text = df_text[df_text.text.str.strip().str.len() > 0].copy()\n",
    "    df_text = df_text.set_index(['id','line'])\n",
    "    \n",
    "    df = df_text\n",
    "\n",
    "    if labels_fn:\n",
    "        #MAKE LABEL DATAFRAME\n",
    "        labels = pd.read_csv(labels_fn,sep='\\t',encoding='utf-8',header=None)\n",
    "        labels = labels.rename(columns={0:'id',1:'line',2:'labels'})\n",
    "        labels = labels.set_index(['id','line'])\n",
    "        labels = labels[labels.labels.notna()].copy()\n",
    "\n",
    "        #JOIN\n",
    "        df = labels.join(df_text)[['text','spans','labels']]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "labels_test_fn=\"/data/en/dev-labels-subtask-3.txt\"\n",
    "folder_dev=\"/data/en/dev-articles-subtask-3/\"\n",
    "labels_train_fn=\"/data/en/train-labels-subtask-3.txt\"\n",
    "folder_train=\"/data/en/train-articles-subtask-3/\"\n",
    "train_span=\"/data/\"+lang+\"/train-labels-subtask-3-spans\"\n",
    "test_span=\"/data/\"+lang+\"/dev-labels-subtask-3-spans\"\n",
    "\n",
    "print('Loading training...')\n",
    "train=make_dataframe_subtask3(folder_train, labels_train_fn, train_span)\n",
    "print('Loading dev...')\n",
    "test=make_dataframe_subtask3(folder_dev, labels_test_fn, test_span)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "executionInfo": {
     "elapsed": 13,
     "status": "ok",
     "timestamp": 1671050266280,
     "user": {
      "displayName": "Katarzyna Baraniak",
      "userId": "09959407714606546607"
     },
     "user_tz": -60
    },
    "id": "Z7namsVGMJ5t",
    "outputId": "0f434e79-b639-4e80-b438-1181e996ba52"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>line</th>\n",
       "      <th>text</th>\n",
       "      <th>spans</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>111111111</td>\n",
       "      <td>3</td>\n",
       "      <td>Geneva - The World Health Organisation chief o...</td>\n",
       "      <td>[{'start': 90, 'end': 98, 'label': 'Doubt'}]</td>\n",
       "      <td>Doubt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>111111111</td>\n",
       "      <td>5</td>\n",
       "      <td>\"The next transmission could be more pronounce...</td>\n",
       "      <td>[{'start': 5, 'end': 63, 'label': 'Appeal_to_A...</td>\n",
       "      <td>Appeal_to_Authority</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>111111111</td>\n",
       "      <td>13</td>\n",
       "      <td>But Tedros voiced alarm that \"plague in Madaga...</td>\n",
       "      <td>[{'start': 74, 'end': 96, 'label': 'Repetition'}]</td>\n",
       "      <td>Repetition</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>111111111</td>\n",
       "      <td>17</td>\n",
       "      <td>He also pointed to the presence of the pneumon...</td>\n",
       "      <td>[]</td>\n",
       "      <td>Appeal_to_Fear-Prejudice</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>111111111</td>\n",
       "      <td>19</td>\n",
       "      <td>He praised the rapid response from WHO and Mad...</td>\n",
       "      <td>[]</td>\n",
       "      <td>Appeal_to_Fear-Prejudice</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3755</th>\n",
       "      <td>999001970</td>\n",
       "      <td>4</td>\n",
       "      <td>Also the Left killed comedy. This is what its ...</td>\n",
       "      <td>[{'start': 8, 'end': 30, 'label': 'Slogans'}]</td>\n",
       "      <td>Exaggeration-Minimisation,Slogans</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3756</th>\n",
       "      <td>999001970</td>\n",
       "      <td>5</td>\n",
       "      <td>Saturday Night Live writer and comedian Nimesh...</td>\n",
       "      <td>[]</td>\n",
       "      <td>Exaggeration-Minimisation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3757</th>\n",
       "      <td>999001970</td>\n",
       "      <td>6</td>\n",
       "      <td>That's what Columbia snowflakes thought was of...</td>\n",
       "      <td>[{'start': 17, 'end': 36, 'label': 'Name_Calli...</td>\n",
       "      <td>Name_Calling-Labeling</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3758</th>\n",
       "      <td>999001970</td>\n",
       "      <td>8</td>\n",
       "      <td>Comrades, these jokes you have been listening ...</td>\n",
       "      <td>[]</td>\n",
       "      <td>Exaggeration-Minimisation,Name_Calling-Labeling</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3759</th>\n",
       "      <td>999001970</td>\n",
       "      <td>13</td>\n",
       "      <td>I'm sure Patel felt very, like, accepted.</td>\n",
       "      <td>[]</td>\n",
       "      <td>Exaggeration-Minimisation</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3760 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             id  line                                               text  \\\n",
       "0     111111111     3  Geneva - The World Health Organisation chief o...   \n",
       "1     111111111     5  \"The next transmission could be more pronounce...   \n",
       "2     111111111    13  But Tedros voiced alarm that \"plague in Madaga...   \n",
       "3     111111111    17  He also pointed to the presence of the pneumon...   \n",
       "4     111111111    19  He praised the rapid response from WHO and Mad...   \n",
       "...         ...   ...                                                ...   \n",
       "3755  999001970     4  Also the Left killed comedy. This is what its ...   \n",
       "3756  999001970     5  Saturday Night Live writer and comedian Nimesh...   \n",
       "3757  999001970     6  That's what Columbia snowflakes thought was of...   \n",
       "3758  999001970     8  Comrades, these jokes you have been listening ...   \n",
       "3759  999001970    13          I'm sure Patel felt very, like, accepted.   \n",
       "\n",
       "                                                  spans  \\\n",
       "0          [{'start': 90, 'end': 98, 'label': 'Doubt'}]   \n",
       "1     [{'start': 5, 'end': 63, 'label': 'Appeal_to_A...   \n",
       "2     [{'start': 74, 'end': 96, 'label': 'Repetition'}]   \n",
       "3                                                    []   \n",
       "4                                                    []   \n",
       "...                                                 ...   \n",
       "3755      [{'start': 8, 'end': 30, 'label': 'Slogans'}]   \n",
       "3756                                                 []   \n",
       "3757  [{'start': 17, 'end': 36, 'label': 'Name_Calli...   \n",
       "3758                                                 []   \n",
       "3759                                                 []   \n",
       "\n",
       "                                               labels  \n",
       "0                                               Doubt  \n",
       "1                                 Appeal_to_Authority  \n",
       "2                                          Repetition  \n",
       "3                            Appeal_to_Fear-Prejudice  \n",
       "4                            Appeal_to_Fear-Prejudice  \n",
       "...                                               ...  \n",
       "3755                Exaggeration-Minimisation,Slogans  \n",
       "3756                        Exaggeration-Minimisation  \n",
       "3757                            Name_Calling-Labeling  \n",
       "3758  Exaggeration-Minimisation,Name_Calling-Labeling  \n",
       "3759                        Exaggeration-Minimisation  \n",
       "\n",
       "[3760 rows x 5 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.reset_index(inplace=True)\n",
    "test.reset_index(inplace=True)\n",
    "\n",
    "train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Change span to IO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import spacy\n",
    "\n",
    "\n",
    "#add spacy model for chosen language\n",
    "if lang==\"po\":\n",
    "    nlp = spacy.load(\"pl_core_news_sm\")\n",
    "if lang==\"en\":\n",
    "    nlp = spacy.load(\"en_core_web_sm\")\n",
    "    \n",
    "train[\"tokens\"]=\"\"\n",
    "train[\"pos\"]=\"\"\n",
    "train[\"mani_tags\"]=\"\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#train\n",
    "for i, (sentence, annotations) in enumerate(zip(train[\"text\"],train[\"spans\"])):\n",
    "    doc=nlp(sentence)\n",
    "    token_list=[]\n",
    "    mani_tag=[]\n",
    "    \n",
    "    for token in doc:\n",
    "        token_list.append(str(token.text))\n",
    "#         print(token)\n",
    "        pos_list.append(str(token.pos_))\n",
    "\n",
    "\n",
    "    train[\"tokens\"][i]=token_list\n",
    "    train[\"pos\"][i]=pos_list\n",
    "    \n",
    "    if len(annotations)==0:\n",
    "        \n",
    "        for j in range(0,len(token_list)):\n",
    "            mani_tag.append(\"O\")\n",
    "        \n",
    "        train[\"mani_tags\"][i]=mani_tag\n",
    "    else:\n",
    "        start=0\n",
    "        ann_mani=pd.DataFrame(annotations)\n",
    "        ann_mani= ann_mani.sort_values(\"start\")\n",
    "   \n",
    "        for j, ann in ann_mani.iterrows():\n",
    "            token_idx=0\n",
    "            for token in nlp(sentence[start:ann[\"start\"]].strip()):\n",
    "    #                 \n",
    "                    mani_tag.append(\"O\")\n",
    "            for token in nlp(sentence[ann[\"start\"]:ann[\"end\"]].strip()):\n",
    "                start=ann[\"end\"]\n",
    "                if(token_idx==0):\n",
    "                    mani_tag.append(\"I\")\n",
    "                else:\n",
    "                    mani_tag.append(\"I\")\n",
    "\n",
    "                token_idx+=1\n",
    "            for token in nlp(sentence[ann[\"end\"]:].strip()):\n",
    "                    mani_tag.append(\"O\")\n",
    "        train[\"mani_tags\"][i]=mani_tag\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test[\"tokens\"]=\"\"\n",
    "test[\"pos\"]=\"\"\n",
    "test[\"mani_tags\"]=\"\"\n",
    "\n",
    "#test\n",
    "for i, (sentence, annotations) in enumerate(zip(test[\"text\"],test[\"spans\"])):\n",
    "    doc=nlp(sentence)\n",
    "    token_list=[]\n",
    "    mani_tag=[]\n",
    "    \n",
    "    for token in doc:\n",
    "        token_list.append(str(token.text))\n",
    "\n",
    "        pos_list.append(str(token.pos_))\n",
    "\n",
    "\n",
    "    test[\"tokens\"][i]=token_list\n",
    "    test[\"pos\"][i]=pos_list\n",
    "    \n",
    "    if len(annotations)==0:\n",
    "        \n",
    "        for j in range(0,len(token_list)):\n",
    "            mani_tag.append(\"O\")\n",
    "        \n",
    "        test[\"mani_tags\"][i]=mani_tag\n",
    "    else:\n",
    "        start=0\n",
    "        ann_mani=pd.DataFrame(annotations)\n",
    "        ann_mani= ann_mani.sort_values(\"start\")\n",
    "   \n",
    "        for j, ann in ann_mani.iterrows():\n",
    "            token_idx=0\n",
    "            for token in nlp(sentence[start:ann[\"start\"]].strip()):\n",
    "                    mani_tag.append(\"O\")\n",
    "            for token in nlp(sentence[ann[\"start\"]:ann[\"end\"]].strip()):\n",
    "                start=ann[\"end\"]\n",
    "                if(token_idx==0):\n",
    "                    mani_tag.append(\"I-\")\n",
    "                else:\n",
    "                    mani_tag.append(\"I-\")\n",
    "\n",
    "                token_idx+=1\n",
    "            for token in nlp(sentence[ann[\"end\"]:].strip()):\n",
    "                    mani_tag.append(\"O\")\n",
    "        test[\"mani_tags\"][i]=mani_tag\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1671050270195,
     "user": {
      "displayName": "Katarzyna Baraniak",
      "userId": "09959407714606546607"
     },
     "user_tz": -60
    },
    "id": "4Qw7RE6u6L4z",
    "outputId": "f6fbb121-7f2f-404f-9311-d20a945a29c6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'False_Dilemma-No_Choice': 0,\n",
       " 'Guilt_by_Association': 1,\n",
       " 'Loaded_Language': 2,\n",
       " 'Flag_Waving': 3,\n",
       " 'Obfuscation-Vagueness-Confusion': 4,\n",
       " 'Red_Herring': 5,\n",
       " 'Appeal_to_Authority': 6,\n",
       " 'Whataboutism': 7,\n",
       " 'Doubt': 8,\n",
       " 'Appeal_to_Popularity': 9,\n",
       " 'Conversation_Killer': 10,\n",
       " 'Causal_Oversimplification': 11,\n",
       " 'Name_Calling-Labeling': 12,\n",
       " 'Appeal_to_Fear-Prejudice': 13,\n",
       " 'Straw_Man': 14,\n",
       " 'Slogans': 15,\n",
       " 'Repetition': 16,\n",
       " 'Appeal_to_Hypocrisy': 17,\n",
       " 'Exaggeration-Minimisation': 18}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import pandas as pd \n",
    "\n",
    "frames_list=[]\n",
    "for frames in train[\"labels\"]:\n",
    "  fs=frames.split(\",\")\n",
    "  for f in fs:\n",
    "    frames_list.append(f)\n",
    "\n",
    "frames_to_ids = {k: v for v, k in enumerate(set(frames_list))}\n",
    "ids_to_frames = {v: k for v, k in enumerate(set(frames_list))}\n",
    "frames_to_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "tags=[]\n",
    "for tag in train[\"mani_tags\"]:\n",
    "    tags=tags+tag\n",
    "\n",
    "    \n",
    "\n",
    "print(\"Number of tags: {}\".format(len(set(tags))))\n",
    "c = Counter(tags)\n",
    "\n",
    "print( c.items())\n",
    "\n",
    "\n",
    "\n",
    "tags_to_ids = {k: v for v, k in enumerate(set(tags))}\n",
    "ids_to_tags = {v: k for v, k in enumerate(set(tags))}\n",
    "tags_to_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1671050272215,
     "user": {
      "displayName": "Katarzyna Baraniak",
      "userId": "09959407714606546607"
     },
     "user_tz": -60
    },
    "id": "QZZU-1_80GMw"
   },
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "n_labels=len(frames_to_ids)\n",
    "\n",
    "def one_hot_encoder(df):\n",
    "    one_hot_encoding = []\n",
    "    for i in tqdm(range(len(df))):\n",
    "        temp = [0]*n_labels\n",
    "        label_indices = df.iloc[i][\"labels\"].split(\",\")\n",
    "        for index in label_indices:\n",
    "            temp[frames_to_ids[index]] = 1\n",
    "        one_hot_encoding.append(temp)\n",
    "    return pd.DataFrame(one_hot_encoding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 456,
     "referenced_widgets": [
      "da22f896c64c48fbb5f098e1b6cb8cb3",
      "b12494951bae49d29fc7706a2b8a0114",
      "2e6cb11d793040f7940221279053ad1b",
      "81ce3f1390b843778e9d83441f25f72c",
      "7258d508c61e447eb18f3ee1b9393c17",
      "cf3a355dad12440cb799b467a92b7b04",
      "6aab9c00fc0441948ab55483ba849245",
      "498f1ac1fdd64441856eef36bf717276",
      "9a89037cc5a3425e8811fd3de0fa696e",
      "5f4b1b43ff284fabbcb3cedd4acabd2e",
      "9d84110857414d49ba319128e7d9b08f"
     ]
    },
    "executionInfo": {
     "elapsed": 1546,
     "status": "ok",
     "timestamp": 1671050274395,
     "user": {
      "displayName": "Katarzyna Baraniak",
      "userId": "09959407714606546607"
     },
     "user_tz": -60
    },
    "id": "cOHtukdcACMC",
    "outputId": "22b13c57-e463-49da-e847-199887517580"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa3b566d91ed4d05966d1c5467555848",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3760 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2963ad4999f04139ade6989daab0f6b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1120 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3755</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3756</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3757</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3758</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3759</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3760 rows × 19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      0   1   2   3   4   5   6   7   8   9   10  11  12  13  14  15  16  17  \\\n",
       "0      0   0   0   0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   \n",
       "1      0   0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   \n",
       "2      0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   \n",
       "3      0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   \n",
       "4      0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   \n",
       "...   ..  ..  ..  ..  ..  ..  ..  ..  ..  ..  ..  ..  ..  ..  ..  ..  ..  ..   \n",
       "3755   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   \n",
       "3756   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   \n",
       "3757   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   \n",
       "3758   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   \n",
       "3759   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   \n",
       "\n",
       "      18  \n",
       "0      0  \n",
       "1      0  \n",
       "2      0  \n",
       "3      0  \n",
       "4      0  \n",
       "...   ..  \n",
       "3755   1  \n",
       "3756   1  \n",
       "3757   0  \n",
       "3758   1  \n",
       "3759   1  \n",
       "\n",
       "[3760 rows x 19 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ohe_labels = one_hot_encoder(train)\n",
    "test_ohe_labels = one_hot_encoder(test)\n",
    "\n",
    "train_ohe_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "executionInfo": {
     "elapsed": 581,
     "status": "ok",
     "timestamp": 1671050275430,
     "user": {
      "displayName": "Katarzyna Baraniak",
      "userId": "09959407714606546607"
     },
     "user_tz": -60
    },
    "id": "OG_nlSVmaQv1",
    "outputId": "29519264-889f-4954-8f4e-79f2f6ac4265"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>line</th>\n",
       "      <th>text</th>\n",
       "      <th>spans</th>\n",
       "      <th>labels</th>\n",
       "      <th>tokens</th>\n",
       "      <th>pos</th>\n",
       "      <th>mani_tags</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>...</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>111111111</td>\n",
       "      <td>3</td>\n",
       "      <td>Geneva - The World Health Organisation chief o...</td>\n",
       "      <td>[{'start': 90, 'end': 98, 'label': 'Doubt'}]</td>\n",
       "      <td>Doubt</td>\n",
       "      <td>[Geneva, -, The, World, Health, Organisation, ...</td>\n",
       "      <td>[NOUN, PUNCT, PROPN, PROPN, ADJ, NOUN, VERB, P...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>111111111</td>\n",
       "      <td>5</td>\n",
       "      <td>\"The next transmission could be more pronounce...</td>\n",
       "      <td>[{'start': 5, 'end': 63, 'label': 'Appeal_to_A...</td>\n",
       "      <td>Appeal_to_Authority</td>\n",
       "      <td>[\", The, next, transmission, could, be, more, ...</td>\n",
       "      <td>[PUNCT, NOUN, ADJ, NOUN, NOUN, X, NOUN, NOUN, ...</td>\n",
       "      <td>[O, O, I-, I-, I-, I-, I-, I-, I-, I-, I-, I-,...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>111111111</td>\n",
       "      <td>13</td>\n",
       "      <td>But Tedros voiced alarm that \"plague in Madaga...</td>\n",
       "      <td>[{'start': 74, 'end': 96, 'label': 'Repetition'}]</td>\n",
       "      <td>Repetition</td>\n",
       "      <td>[But, Tedros, voiced, alarm, that, \", plague, ...</td>\n",
       "      <td>[X, PROPN, ADJ, NOUN, VERB, PUNCT, NOUN, X, PR...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>111111111</td>\n",
       "      <td>17</td>\n",
       "      <td>He also pointed to the presence of the pneumon...</td>\n",
       "      <td>[]</td>\n",
       "      <td>Appeal_to_Fear-Prejudice</td>\n",
       "      <td>[He, also, pointed, to, the, presence, of, the...</td>\n",
       "      <td>[NOUN, NOUN, NOUN, AUX, X, NOUN, X, X, NOUN, N...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>111111111</td>\n",
       "      <td>19</td>\n",
       "      <td>He praised the rapid response from WHO and Mad...</td>\n",
       "      <td>[]</td>\n",
       "      <td>Appeal_to_Fear-Prejudice</td>\n",
       "      <td>[He, praised, the, rapid, response, from, WHO,...</td>\n",
       "      <td>[PROPN, PROPN, CCONJ, NOUN, NOUN, NOUN, PROPN,...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3755</th>\n",
       "      <td>999001970</td>\n",
       "      <td>4</td>\n",
       "      <td>Also the Left killed comedy. This is what its ...</td>\n",
       "      <td>[{'start': 8, 'end': 30, 'label': 'Slogans'}]</td>\n",
       "      <td>Exaggeration-Minimisation,Slogans</td>\n",
       "      <td>[Also, the, Left, killed, comedy, ., This, is,...</td>\n",
       "      <td>[NOUN, X, PROPN, NOUN, ADV, PUNCT, NOUN, X, AD...</td>\n",
       "      <td>[O, O, I-, I-, I-, I-, I-, O, O, O, O, O, O, O...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3756</th>\n",
       "      <td>999001970</td>\n",
       "      <td>5</td>\n",
       "      <td>Saturday Night Live writer and comedian Nimesh...</td>\n",
       "      <td>[]</td>\n",
       "      <td>Exaggeration-Minimisation</td>\n",
       "      <td>[Saturday, Night, Live, writer, and, comedian,...</td>\n",
       "      <td>[NOUN, NOUN, VERB, NOUN, CCONJ, NOUN, PROPN, N...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3757</th>\n",
       "      <td>999001970</td>\n",
       "      <td>6</td>\n",
       "      <td>That's what Columbia snowflakes thought was of...</td>\n",
       "      <td>[{'start': 17, 'end': 36, 'label': 'Name_Calli...</td>\n",
       "      <td>Name_Calling-Labeling</td>\n",
       "      <td>[That's, what, Columbia, snowflakes, thought, ...</td>\n",
       "      <td>[PROPN, NOUN, NOUN, NOUN, NUM, PRON, VERB, PUN...</td>\n",
       "      <td>[O, O, O, I-, I-, I-, O, O, O, O, O, O, O, O, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3758</th>\n",
       "      <td>999001970</td>\n",
       "      <td>8</td>\n",
       "      <td>Comrades, these jokes you have been listening ...</td>\n",
       "      <td>[]</td>\n",
       "      <td>Exaggeration-Minimisation,Name_Calling-Labeling</td>\n",
       "      <td>[Comrades, ,, these, jokes, you, have, been, l...</td>\n",
       "      <td>[PROPN, PUNCT, VERB, NOUN, X, NOUN, ADJ, NOUN,...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3759</th>\n",
       "      <td>999001970</td>\n",
       "      <td>13</td>\n",
       "      <td>I'm sure Patel felt very, like, accepted.</td>\n",
       "      <td>[]</td>\n",
       "      <td>Exaggeration-Minimisation</td>\n",
       "      <td>[I'm, sure, Patel, felt, very, ,, like, ,, acc...</td>\n",
       "      <td>[NOUN, PROPN, NOUN, NOUN, NOUN, PUNCT, NOUN, P...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3760 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             id  line                                               text  \\\n",
       "0     111111111     3  Geneva - The World Health Organisation chief o...   \n",
       "1     111111111     5  \"The next transmission could be more pronounce...   \n",
       "2     111111111    13  But Tedros voiced alarm that \"plague in Madaga...   \n",
       "3     111111111    17  He also pointed to the presence of the pneumon...   \n",
       "4     111111111    19  He praised the rapid response from WHO and Mad...   \n",
       "...         ...   ...                                                ...   \n",
       "3755  999001970     4  Also the Left killed comedy. This is what its ...   \n",
       "3756  999001970     5  Saturday Night Live writer and comedian Nimesh...   \n",
       "3757  999001970     6  That's what Columbia snowflakes thought was of...   \n",
       "3758  999001970     8  Comrades, these jokes you have been listening ...   \n",
       "3759  999001970    13          I'm sure Patel felt very, like, accepted.   \n",
       "\n",
       "                                                  spans  \\\n",
       "0          [{'start': 90, 'end': 98, 'label': 'Doubt'}]   \n",
       "1     [{'start': 5, 'end': 63, 'label': 'Appeal_to_A...   \n",
       "2     [{'start': 74, 'end': 96, 'label': 'Repetition'}]   \n",
       "3                                                    []   \n",
       "4                                                    []   \n",
       "...                                                 ...   \n",
       "3755      [{'start': 8, 'end': 30, 'label': 'Slogans'}]   \n",
       "3756                                                 []   \n",
       "3757  [{'start': 17, 'end': 36, 'label': 'Name_Calli...   \n",
       "3758                                                 []   \n",
       "3759                                                 []   \n",
       "\n",
       "                                               labels  \\\n",
       "0                                               Doubt   \n",
       "1                                 Appeal_to_Authority   \n",
       "2                                          Repetition   \n",
       "3                            Appeal_to_Fear-Prejudice   \n",
       "4                            Appeal_to_Fear-Prejudice   \n",
       "...                                               ...   \n",
       "3755                Exaggeration-Minimisation,Slogans   \n",
       "3756                        Exaggeration-Minimisation   \n",
       "3757                            Name_Calling-Labeling   \n",
       "3758  Exaggeration-Minimisation,Name_Calling-Labeling   \n",
       "3759                        Exaggeration-Minimisation   \n",
       "\n",
       "                                                 tokens  \\\n",
       "0     [Geneva, -, The, World, Health, Organisation, ...   \n",
       "1     [\", The, next, transmission, could, be, more, ...   \n",
       "2     [But, Tedros, voiced, alarm, that, \", plague, ...   \n",
       "3     [He, also, pointed, to, the, presence, of, the...   \n",
       "4     [He, praised, the, rapid, response, from, WHO,...   \n",
       "...                                                 ...   \n",
       "3755  [Also, the, Left, killed, comedy, ., This, is,...   \n",
       "3756  [Saturday, Night, Live, writer, and, comedian,...   \n",
       "3757  [That's, what, Columbia, snowflakes, thought, ...   \n",
       "3758  [Comrades, ,, these, jokes, you, have, been, l...   \n",
       "3759  [I'm, sure, Patel, felt, very, ,, like, ,, acc...   \n",
       "\n",
       "                                                    pos  \\\n",
       "0     [NOUN, PUNCT, PROPN, PROPN, ADJ, NOUN, VERB, P...   \n",
       "1     [PUNCT, NOUN, ADJ, NOUN, NOUN, X, NOUN, NOUN, ...   \n",
       "2     [X, PROPN, ADJ, NOUN, VERB, PUNCT, NOUN, X, PR...   \n",
       "3     [NOUN, NOUN, NOUN, AUX, X, NOUN, X, X, NOUN, N...   \n",
       "4     [PROPN, PROPN, CCONJ, NOUN, NOUN, NOUN, PROPN,...   \n",
       "...                                                 ...   \n",
       "3755  [NOUN, X, PROPN, NOUN, ADV, PUNCT, NOUN, X, AD...   \n",
       "3756  [NOUN, NOUN, VERB, NOUN, CCONJ, NOUN, PROPN, N...   \n",
       "3757  [PROPN, NOUN, NOUN, NOUN, NUM, PRON, VERB, PUN...   \n",
       "3758  [PROPN, PUNCT, VERB, NOUN, X, NOUN, ADJ, NOUN,...   \n",
       "3759  [NOUN, PROPN, NOUN, NOUN, NOUN, PUNCT, NOUN, P...   \n",
       "\n",
       "                                              mani_tags  0  1  ...  9  10  11  \\\n",
       "0     [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...  0  0  ...  0   0   0   \n",
       "1     [O, O, I-, I-, I-, I-, I-, I-, I-, I-, I-, I-,...  0  0  ...  0   0   0   \n",
       "2     [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...  0  0  ...  0   0   0   \n",
       "3     [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...  0  0  ...  0   0   0   \n",
       "4     [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...  0  0  ...  0   0   0   \n",
       "...                                                 ... .. ..  ... ..  ..  ..   \n",
       "3755  [O, O, I-, I-, I-, I-, I-, O, O, O, O, O, O, O...  0  0  ...  0   0   0   \n",
       "3756  [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...  0  0  ...  0   0   0   \n",
       "3757  [O, O, O, I-, I-, I-, O, O, O, O, O, O, O, O, ...  0  0  ...  0   0   0   \n",
       "3758            [O, O, O, O, O, O, O, O, O, O, O, O, O]  0  0  ...  0   0   0   \n",
       "3759                     [O, O, O, O, O, O, O, O, O, O]  0  0  ...  0   0   0   \n",
       "\n",
       "      12  13  14  15  16  17  18  \n",
       "0      0   0   0   0   0   0   0  \n",
       "1      0   0   0   0   0   0   0  \n",
       "2      0   0   0   0   1   0   0  \n",
       "3      0   1   0   0   0   0   0  \n",
       "4      0   1   0   0   0   0   0  \n",
       "...   ..  ..  ..  ..  ..  ..  ..  \n",
       "3755   0   0   0   1   0   0   1  \n",
       "3756   0   0   0   0   0   0   1  \n",
       "3757   1   0   0   0   0   0   0  \n",
       "3758   1   0   0   0   0   0   1  \n",
       "3759   0   0   0   0   0   0   1  \n",
       "\n",
       "[3760 rows x 27 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.concat([train, train_ohe_labels], axis=1)\n",
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>line</th>\n",
       "      <th>text</th>\n",
       "      <th>spans</th>\n",
       "      <th>labels</th>\n",
       "      <th>tokens</th>\n",
       "      <th>pos</th>\n",
       "      <th>mani_tags</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>...</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>813452859</td>\n",
       "      <td>7</td>\n",
       "      <td>Michael Swadling: I guess her only chance is i...</td>\n",
       "      <td>[{'start': 84, 'end': 106, 'label': 'Loaded_La...</td>\n",
       "      <td>False_Dilemma-No_Choice,Loaded_Language</td>\n",
       "      <td>[Michael, Swadling, :, I, guess, her, only, ch...</td>\n",
       "      <td>[PROPN, PROPN, PUNCT, CCONJ, NOUN, PUNCT, ADJ,...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>813452859</td>\n",
       "      <td>9</td>\n",
       "      <td>There is a chance; as unfortunately there are ...</td>\n",
       "      <td>[{'start': 133, 'end': 226, 'label': 'False_Di...</td>\n",
       "      <td>False_Dilemma-No_Choice,Loaded_Language,Name_C...</td>\n",
       "      <td>[There, is, a, chance, ;, as, unfortunately, t...</td>\n",
       "      <td>[PROPN, CCONJ, CCONJ, NOUN, PUNCT, NOUN, NOUN,...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>813452859</td>\n",
       "      <td>11</td>\n",
       "      <td>Michael Swadling: The EU withdrawal act is in ...</td>\n",
       "      <td>[]</td>\n",
       "      <td>Conversation_Killer</td>\n",
       "      <td>[Michael, Swadling, :, The, EU, withdrawal, ac...</td>\n",
       "      <td>[PROPN, PROPN, PUNCT, PROPN, PROPN, NOUN, NOUN...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>813452859</td>\n",
       "      <td>12</td>\n",
       "      <td>I often use the example of an iPhone to people...</td>\n",
       "      <td>[]</td>\n",
       "      <td>Conversation_Killer,Red_Herring</td>\n",
       "      <td>[I, often, use, the, example, of, an, iPhone, ...</td>\n",
       "      <td>[CCONJ, NOUN, DET, X, ADV, X, X, PROPN, PRON, ...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>813452859</td>\n",
       "      <td>15</td>\n",
       "      <td>Michael Swadling: The EU makes a profit on its...</td>\n",
       "      <td>[]</td>\n",
       "      <td>Obfuscation-Vagueness-Confusion</td>\n",
       "      <td>[Michael, Swadling, :, The, EU, makes, a, prof...</td>\n",
       "      <td>[PROPN, PROPN, PUNCT, PROPN, PROPN, VERB, CCON...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1115</th>\n",
       "      <td>833053676</td>\n",
       "      <td>7</td>\n",
       "      <td>“I don’t think he’s legitimate.</td>\n",
       "      <td>[]</td>\n",
       "      <td>Doubt</td>\n",
       "      <td>[“, I, don, ’, t, think, he, ’, s, legitimate, .]</td>\n",
       "      <td>[PUNCT, X, X, PROPN, PRON, NOUN, PROPN, NOUN, ...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1116</th>\n",
       "      <td>833067493</td>\n",
       "      <td>4</td>\n",
       "      <td>'Democrats, the test results are back, and Don...</td>\n",
       "      <td>[{'start': 4, 'end': 72, 'label': 'Loaded_Lang...</td>\n",
       "      <td>Loaded_Language</td>\n",
       "      <td>[', Democrats, ,, the, test, results, are, bac...</td>\n",
       "      <td>[PUNCT, PROPN, PUNCT, CCONJ, NOUN, ADV, PROPN,...</td>\n",
       "      <td>[O, O, I-, I-, I-, I-, I-, I-, I-, I-, I-, I-,...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1117</th>\n",
       "      <td>833067493</td>\n",
       "      <td>5</td>\n",
       "      <td>Trump Jr added in a comment: '... and your pre...</td>\n",
       "      <td>[]</td>\n",
       "      <td>Loaded_Language</td>\n",
       "      <td>[Trump, Jr, added, in, a, comment, :, ', .., ....</td>\n",
       "      <td>[NOUN, X, NOUN, NOUN, CCONJ, NOUN, PUNCT, PUNC...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1118</th>\n",
       "      <td>833067493</td>\n",
       "      <td>8</td>\n",
       "      <td>Trump Jr (seen last year) mocked Democrats say...</td>\n",
       "      <td>[]</td>\n",
       "      <td>Loaded_Language</td>\n",
       "      <td>[Trump, Jr, (, seen, last, year, ), mocked, De...</td>\n",
       "      <td>[NOUN, PROPN, PUNCT, NOUN, X, PROPN, PUNCT, PR...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1119</th>\n",
       "      <td>833067493</td>\n",
       "      <td>9</td>\n",
       "      <td>It came as President Donald Trump's supporters...</td>\n",
       "      <td>[{'start': 55, 'end': 64, 'label': 'Loaded_Lan...</td>\n",
       "      <td>Loaded_Language</td>\n",
       "      <td>[It, came, as, President, Donald, Trump's, sup...</td>\n",
       "      <td>[X, X, PRON, NOUN, PROPN, PROPN, NOUN, NOUN, A...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, I-, I-, O, O, O, O, O...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1120 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             id  line                                               text  \\\n",
       "0     813452859     7  Michael Swadling: I guess her only chance is i...   \n",
       "1     813452859     9  There is a chance; as unfortunately there are ...   \n",
       "2     813452859    11  Michael Swadling: The EU withdrawal act is in ...   \n",
       "3     813452859    12  I often use the example of an iPhone to people...   \n",
       "4     813452859    15  Michael Swadling: The EU makes a profit on its...   \n",
       "...         ...   ...                                                ...   \n",
       "1115  833053676     7                    “I don’t think he’s legitimate.   \n",
       "1116  833067493     4  'Democrats, the test results are back, and Don...   \n",
       "1117  833067493     5  Trump Jr added in a comment: '... and your pre...   \n",
       "1118  833067493     8  Trump Jr (seen last year) mocked Democrats say...   \n",
       "1119  833067493     9  It came as President Donald Trump's supporters...   \n",
       "\n",
       "                                                  spans  \\\n",
       "0     [{'start': 84, 'end': 106, 'label': 'Loaded_La...   \n",
       "1     [{'start': 133, 'end': 226, 'label': 'False_Di...   \n",
       "2                                                    []   \n",
       "3                                                    []   \n",
       "4                                                    []   \n",
       "...                                                 ...   \n",
       "1115                                                 []   \n",
       "1116  [{'start': 4, 'end': 72, 'label': 'Loaded_Lang...   \n",
       "1117                                                 []   \n",
       "1118                                                 []   \n",
       "1119  [{'start': 55, 'end': 64, 'label': 'Loaded_Lan...   \n",
       "\n",
       "                                                 labels  \\\n",
       "0               False_Dilemma-No_Choice,Loaded_Language   \n",
       "1     False_Dilemma-No_Choice,Loaded_Language,Name_C...   \n",
       "2                                   Conversation_Killer   \n",
       "3                       Conversation_Killer,Red_Herring   \n",
       "4                       Obfuscation-Vagueness-Confusion   \n",
       "...                                                 ...   \n",
       "1115                                              Doubt   \n",
       "1116                                    Loaded_Language   \n",
       "1117                                    Loaded_Language   \n",
       "1118                                    Loaded_Language   \n",
       "1119                                    Loaded_Language   \n",
       "\n",
       "                                                 tokens  \\\n",
       "0     [Michael, Swadling, :, I, guess, her, only, ch...   \n",
       "1     [There, is, a, chance, ;, as, unfortunately, t...   \n",
       "2     [Michael, Swadling, :, The, EU, withdrawal, ac...   \n",
       "3     [I, often, use, the, example, of, an, iPhone, ...   \n",
       "4     [Michael, Swadling, :, The, EU, makes, a, prof...   \n",
       "...                                                 ...   \n",
       "1115  [“, I, don, ’, t, think, he, ’, s, legitimate, .]   \n",
       "1116  [', Democrats, ,, the, test, results, are, bac...   \n",
       "1117  [Trump, Jr, added, in, a, comment, :, ', .., ....   \n",
       "1118  [Trump, Jr, (, seen, last, year, ), mocked, De...   \n",
       "1119  [It, came, as, President, Donald, Trump's, sup...   \n",
       "\n",
       "                                                    pos  \\\n",
       "0     [PROPN, PROPN, PUNCT, CCONJ, NOUN, PUNCT, ADJ,...   \n",
       "1     [PROPN, CCONJ, CCONJ, NOUN, PUNCT, NOUN, NOUN,...   \n",
       "2     [PROPN, PROPN, PUNCT, PROPN, PROPN, NOUN, NOUN...   \n",
       "3     [CCONJ, NOUN, DET, X, ADV, X, X, PROPN, PRON, ...   \n",
       "4     [PROPN, PROPN, PUNCT, PROPN, PROPN, VERB, CCON...   \n",
       "...                                                 ...   \n",
       "1115  [PUNCT, X, X, PROPN, PRON, NOUN, PROPN, NOUN, ...   \n",
       "1116  [PUNCT, PROPN, PUNCT, CCONJ, NOUN, ADV, PROPN,...   \n",
       "1117  [NOUN, X, NOUN, NOUN, CCONJ, NOUN, PUNCT, PUNC...   \n",
       "1118  [NOUN, PROPN, PUNCT, NOUN, X, PROPN, PUNCT, PR...   \n",
       "1119  [X, X, PRON, NOUN, PROPN, PROPN, NOUN, NOUN, A...   \n",
       "\n",
       "                                              mani_tags  0  1  ...  9  10  11  \\\n",
       "0     [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...  1  0  ...  0   0   0   \n",
       "1     [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...  1  0  ...  0   0   0   \n",
       "2     [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...  0  0  ...  0   1   0   \n",
       "3     [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...  0  0  ...  0   1   0   \n",
       "4     [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...  0  0  ...  0   0   0   \n",
       "...                                                 ... .. ..  ... ..  ..  ..   \n",
       "1115                  [O, O, O, O, O, O, O, O, O, O, O]  0  0  ...  0   0   0   \n",
       "1116  [O, O, I-, I-, I-, I-, I-, I-, I-, I-, I-, I-,...  0  0  ...  0   0   0   \n",
       "1117  [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...  0  0  ...  0   0   0   \n",
       "1118  [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...  0  0  ...  0   0   0   \n",
       "1119  [O, O, O, O, O, O, O, O, I-, I-, O, O, O, O, O...  0  0  ...  0   0   0   \n",
       "\n",
       "      12  13  14  15  16  17  18  \n",
       "0      0   0   0   0   0   0   0  \n",
       "1      1   0   0   0   0   0   0  \n",
       "2      0   0   0   0   0   0   0  \n",
       "3      0   0   0   0   0   0   0  \n",
       "4      0   0   0   0   0   0   0  \n",
       "...   ..  ..  ..  ..  ..  ..  ..  \n",
       "1115   0   0   0   0   0   0   0  \n",
       "1116   0   0   0   0   0   0   0  \n",
       "1117   0   0   0   0   0   0   0  \n",
       "1118   0   0   0   0   0   0   0  \n",
       "1119   0   0   0   0   0   0   0  \n",
       "\n",
       "[1120 rows x 27 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = pd.concat([test, test_ohe_labels], axis=1)\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 509,
     "status": "ok",
     "timestamp": 1671050280024,
     "user": {
      "displayName": "Katarzyna Baraniak",
      "userId": "09959407714606546607"
     },
     "user_tz": -60
    },
    "id": "VfEs2qOoagiR",
    "outputId": "4ad54843-3053-42ca-f019-a4c6a52dbc18"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 samples from Obfuscation-Vagueness-Confusion sentiment: \n",
      "\n",
      "The cardinal’s staff asked that CNA change his answer about liturgically “blessing” gay unions to: “There are no general solutions and I think that would not be right, because we are talking about pastoral care for individual cases, and that applies to other areas as well, which we cannot regulate, where we have no sets of rules.”\n",
      "\n",
      "What is true for Corker is doubly true for the Democrats.\n",
      "\n",
      "The case of Amber Guyger, the police officer who admitted to shooting 26-year-old Botham Jean in his apartment for no reason, is a glaring example of “blue privilege” at work in our society. Guyger claims that she accidentally entered the wrong apartment and shot a man who she thought was a burglar, however, eyewitness testimony has contradicted her initial statement.\n",
      "\n",
      "The cardinal’s office maintains that rather than saying “yes,” there is a possibility of liturgical “blessing” of gay unions, he answered the question in a more subtle way without giving an explicit “yes.” However, the German Bishops’ Conference doesn’t seem to deny the rest of his statements on how “one must encourage priests” to give encouragement to homosexual couples, which could include public blessings that would take a “liturgical” form.\n",
      "\n",
      "The authorities stonewalled at every turn. And, predictably, the killer gets a pass. Allahu Akbar usually means motive unknown.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def inspect_category_wise_data(label, n=5):\n",
    "    samples = train[train[label] == 1].sample(n)\n",
    "    sentiment = ids_to_frames[label]\n",
    "    \n",
    "    print(f\"{n} samples from {sentiment} sentiment: \\n\")\n",
    "    for text in samples[\"text\"]:\n",
    "        print(text, end='\\n\\n')\n",
    "\n",
    "inspect_category_wise_data(4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "executionInfo": {
     "elapsed": 14,
     "status": "ok",
     "timestamp": 1671050288033,
     "user": {
      "displayName": "Katarzyna Baraniak",
      "userId": "09959407714606546607"
     },
     "user_tz": -60
    },
    "id": "5td1GntgXH-L"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "executionInfo": {
     "elapsed": 14,
     "status": "ok",
     "timestamp": 1671050288034,
     "user": {
      "displayName": "Katarzyna Baraniak",
      "userId": "09959407714606546607"
     },
     "user_tz": -60
    },
    "id": "CoVZ8gEEXIAe"
   },
   "outputs": [],
   "source": [
    "if lang==\"en\":\n",
    "  BERT_MODEL = \"bert-base-cased\"\n",
    "  BERT_MODEL = \"/mnt/lun2/kbaraniak/data/tmpen4/test-mlm\"\n",
    "if lang==\"po\":\n",
    "  BERT_MODEL = \"/mnt/lun2/kbaraniak/data/tmp3/test-mlm\"\n",
    "  #BERT_MODEL = \"dkleczek/bert-base-polish-uncased-v1\"\n",
    "if lang==\"fr\":\n",
    "  BERT_MODEL = \"dbmdz/bert-base-french-europeana-cased\"#\"camembert/camembert-base\"\n",
    "if lang==\"it\":\n",
    "  BERT_MODEL = \"dbmdz/bert-base-italian-uncased\"#\n",
    "if lang==\"ru\":\n",
    "  BERT_MODEL = \"DeepPavlov/bert-base-bg-cs-pl-ru-cased\"#\"rubert\"\n",
    "if lang==\"ge\":\n",
    "  BERT_MODEL = \"dbmdz/bert-base-german-uncased\"#\n",
    "\n",
    "\n",
    "from transformers import AutoTokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(BERT_MODEL,local_files_only=True, cache_dir=\"/mnt/lun2/kbaraniak/data/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "executionInfo": {
     "elapsed": 23,
     "status": "ok",
     "timestamp": 1671035680384,
     "user": {
      "displayName": "Katarzyna Baraniak",
      "userId": "09959407714606546607"
     },
     "user_tz": -60
    },
    "id": "EOsl0eC726Ui"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "executionInfo": {
     "elapsed": 13,
     "status": "ok",
     "timestamp": 1671050288034,
     "user": {
      "displayName": "Katarzyna Baraniak",
      "userId": "09959407714606546607"
     },
     "user_tz": -60
    },
    "id": "XHukMTKbv4uo"
   },
   "outputs": [],
   "source": [
    "import transformers\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FvWMiNa0eO0W"
   },
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1671050288670,
     "user": {
      "displayName": "Katarzyna Baraniak",
      "userId": "09959407714606546607"
     },
     "user_tz": -60
    },
    "id": "a81w8AI5eMxN"
   },
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "\n",
    "class PropagandaClassifier(nn.Module):\n",
    "    def __init__(self, n_classes,num_labels, do_prob, bert_model):\n",
    "        super(PropagandaClassifier, self).__init__()\n",
    "        self.bert = BertModel.from_pretrained(bert_model,local_files_only=True, cache_dir=\"/mnt/lun2/kbaraniak/data/\")\n",
    "        \n",
    "\n",
    "        self.dropout = nn.Dropout(do_prob)\n",
    "        self.out = nn.Linear(768, n_classes)\n",
    "        \n",
    "        self.dropout2 = nn.Dropout(do_prob)\n",
    "        self.tagger = nn.Linear(768, num_labels)\n",
    "        self.m=nn.Softmax( dim=2)\n",
    "       \n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        output_bert = self.bert(input_ids, attention_mask=attention_mask)\n",
    "        \n",
    "        \n",
    "        #tokens\n",
    "        output_tag1=self.dropout(output_bert[0])\n",
    "        output_tag=self.tagger(output_tag1)\n",
    "       \n",
    "        softm=self.m(output_tag)\n",
    "        \n",
    "        indexes=torch.argmax(softm, axis=2)\n",
    "        \n",
    "        ind=[]\n",
    "        for i in range(0, indexes.shape[0]):\n",
    "            one=False\n",
    "            for j in range(0, indexes.shape[1]):\n",
    "                \n",
    "                if indexes[i,j]==1:\n",
    "                    ind.append(j)\n",
    "                    one=True\n",
    "                    break\n",
    "            if one==False: #jesli brak 1 to tez chcemy miec index\n",
    "                ind.append(0)\n",
    "    \n",
    "        a=torch.range(0,len(indexes)-1,dtype=torch.long)\n",
    "        \n",
    "        output_1=output_bert[0][a,ind, :]\n",
    "        output_2 = self.dropout(output_1)\n",
    "        output = self.out(output_2)\n",
    "        return output, output_tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2702,
     "status": "ok",
     "timestamp": 1671050294782,
     "user": {
      "displayName": "Katarzyna Baraniak",
      "userId": "09959407714606546607"
     },
     "user_tz": -60
    },
    "id": "iPdwbNWFop8r",
    "outputId": "1fe3d3c2-ea99-421d-f3ed-2eeb9de80f28"
   },
   "outputs": [],
   "source": [
    "from transformers import BertTokenizerFast, BertConfig, BertModel\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hQjYLllc1rgW"
   },
   "source": [
    "## Prepare dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1671050294782,
     "user": {
      "displayName": "Katarzyna Baraniak",
      "userId": "09959407714606546607"
     },
     "user_tz": -60
    },
    "id": "O0SA74jC01gh"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import AutoTokenizer\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class MyDataset(Dataset):\n",
    "\n",
    "  def __init__(self,df, tokenizer, max_len):\n",
    "    \n",
    "    self.article=df[\"text\"]#[t.lower() for t in df[\"text\"]]\n",
    "    \n",
    "\n",
    "    self.tokenizer=tokenizer\n",
    "    self.max_len=max_len\n",
    "    self.id= df[\"id\"]\n",
    "    self.line=df[\"line\"]\n",
    "\n",
    "    if \"labels\" in df.columns:\n",
    "       self.labels=df[range(len(frames_to_ids))].values.tolist()\n",
    "    else:\n",
    "      self.labels=[]\n",
    "    self.mani_tags=[]\n",
    "    if \"mani_tags\" in df.columns:\n",
    "        self.mani_tags=df[\"mani_tags\"]\n",
    "  def __len__(self):\n",
    "    return len(self.article)\n",
    "  \n",
    "  def __getitem__(self,idx):\n",
    "    if len(self.labels)>0:\n",
    "      labels=self.labels[idx]\n",
    "    else:\n",
    "      labels=0\n",
    "    if len( self.mani_tags)>0:\n",
    "        token_word_labels = self.mani_tags[idx][0].split(\",\") \n",
    "        token_labels = [tags_to_ids[label] for label in token_word_labels] \n",
    "    else:\n",
    "        token_labels=[]\n",
    "    idart=self.id[idx]\n",
    "    line=self.line[idx]\n",
    "     # print(labels)\n",
    "    encoding = self.tokenizer(self.article[idx],\n",
    "                             is_split_into_words=False,\n",
    "                             #is_pretokenized=True, \n",
    "                             return_offsets_mapping=True, \n",
    "                             padding='max_length', \n",
    "                             truncation=True, \n",
    "                             max_length=self.max_len)#.set_format(\"torch\")\n",
    "\n",
    "    # create an empty array of -100 of length max_length\n",
    "    encoded_labels = np.ones(len(encoding[\"offset_mapping\"]), dtype=int) * -100\n",
    "        \n",
    "    i = -1\n",
    "    if len( self.mani_tags)>0:\n",
    "        for idx, mapping in enumerate(encoding[\"offset_mapping\"]):\n",
    "    \n",
    "                if mapping[1]!=0:# next\n",
    "                    if mapping[0] == 0:#only if begginign of a word\n",
    "                        i += 1\n",
    "                    encoded_labels[idx] = token_labels[i]\n",
    "\n",
    "    \n",
    "\n",
    "   \n",
    "    \n",
    "\n",
    "    items = {key: torch.as_tensor(val) for key, val in encoding.items()}\n",
    "    items[\"labels\"]=torch.as_tensor(labels) \n",
    "    items[\"id\"]=idart\n",
    "    items[\"line\"]=line\n",
    "    items['token_labels'] = torch.as_tensor(encoded_labels)\n",
    "\n",
    "\n",
    "    \n",
    "    return items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "executionInfo": {
     "elapsed": 1120,
     "status": "ok",
     "timestamp": 1671050308939,
     "user": {
      "displayName": "Katarzyna Baraniak",
      "userId": "09959407714606546607"
     },
     "user_tz": -60
    },
    "id": "SqYGM2sY01h-"
   },
   "outputs": [],
   "source": [
    "#setup\n",
    "\n",
    "MAX_LEN = 256\n",
    "TRAIN_BATCH_SIZE = 8\n",
    "VALID_BATCH_SIZE = 8\n",
    "EPOCHS = 30\n",
    "LEARNING_RATE = 1e-05\n",
    "MAX_GRAD_NORM = 10\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train_test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN Dataset: (3760, 27)\n",
      "TEST Dataset: (1120, 27)\n"
     ]
    }
   ],
   "source": [
    "print(\"TRAIN Dataset: {}\".format(train.shape))\n",
    "print(\"TEST Dataset: {}\".format(test.shape))\n",
    "training_set = MyDataset(train, tokenizer, MAX_LEN)\n",
    "test_set = MyDataset(test, tokenizer, MAX_LEN)\n",
    "\n",
    "# # myDs=MyDataset(bias_lexical, tokenizer)\n",
    "train_loader=DataLoader(training_set,batch_size=TRAIN_BATCH_SIZE,shuffle=True)\n",
    "test_loader=DataLoader(test_set,batch_size=VALID_BATCH_SIZE, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dnQU65IQFBGM"
   },
   "source": [
    "## log metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "executionInfo": {
     "elapsed": 418,
     "status": "ok",
     "timestamp": 1671050333502,
     "user": {
      "displayName": "Katarzyna Baraniak",
      "userId": "09959407714606546607"
     },
     "user_tz": -60
    },
    "id": "ypbE4GDconNa"
   },
   "outputs": [],
   "source": [
    "from sklearn import metrics, model_selection, preprocessing\n",
    "from sklearn.metrics import precision_recall_fscore_support as score\n",
    "\n",
    "\n",
    "def log_metrics(preds, labels):\n",
    "    preds = torch.stack(preds)\n",
    "    # print(preds)\n",
    "    preds = preds.cpu().detach().numpy()\n",
    "    # print(preds)\n",
    "    labels = torch.stack(labels)\n",
    "    labels = labels.cpu().detach().numpy()\n",
    "\n",
    "\n",
    "    preds=preds >0.5\n",
    "    class_rep=classification_report( labels, preds, target_names= frames_to_ids.keys())\n",
    "    print(class_rep)\n",
    "    precision,recall,fscore,support=score(labels, preds,average='micro')\n",
    "    precision,recall,fscore_macro,support=score(labels, preds,average='macro')\n",
    "\n",
    "    return {\"f1_micro\":fscore, \"f1_macro\":fscore_macro}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "executionInfo": {
     "elapsed": 912,
     "status": "ok",
     "timestamp": 1671050340101,
     "user": {
      "displayName": "Katarzyna Baraniak",
      "userId": "09959407714606546607"
     },
     "user_tz": -60
    },
    "id": "4e7o3x9g01mB"
   },
   "outputs": [],
   "source": [
    "from transformers import BertTokenizerFast, BertConfig, BertModel\n",
    "from torch.nn import CrossEntropyLoss\n",
    "# from transformers.models.bert.modeling_bert import BertModel\n",
    "from transformers.models.bert import BertPreTrainedModel\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def training(epoch, test=True):\n",
    "    tr_loss, tr_accuracy = 0, 0\n",
    "    nb_tr_examples, nb_tr_steps = 0, 0\n",
    "    tr_preds, tr_labels = [], []\n",
    "    # put model in training mode\n",
    "    model.train()\n",
    "    print(\"Start\")\n",
    "    for idx, batch in enumerate(train_loader):\n",
    "\n",
    "       \n",
    "\n",
    "        ids = batch['input_ids'].to(device, dtype = torch.long)\n",
    "        mask = batch['attention_mask'].to(device, dtype = torch.long)\n",
    "        labels = batch['labels'].to(device, dtype = torch.long)\n",
    "        tag_labels=batch['token_labels'].to(device, dtype = torch.long)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        \n",
    "        output, output_tokens = model(input_ids=ids, attention_mask=mask)\n",
    "        \n",
    "        loss_sequence = loss_fct(output, labels.float())\n",
    "        loss_tokens = loss_fct2(output_tokens.view(-1, len(tags_to_ids)), tag_labels.view(-1))\n",
    "\n",
    "        loss=loss_sequence+loss_tokens*0.5\n",
    "        tr_loss += loss.item()\n",
    "        \n",
    "        tr_logits=output\n",
    "\n",
    "        nb_tr_steps += 1\n",
    "        nb_tr_examples += labels.size(0)\n",
    "        \n",
    "        if idx % 100==0:\n",
    "            loss_step = tr_loss/nb_tr_steps\n",
    "            print(f\"Training loss per 100 training steps: {loss_step}\")\n",
    "           \n",
    "    \n",
    "        # gradient clipping\n",
    "        torch.nn.utils.clip_grad_norm_(\n",
    "            parameters=model.parameters(), max_norm=MAX_GRAD_NORM\n",
    "        )\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        \n",
    "\n",
    "    epoch_loss = tr_loss / nb_tr_steps\n",
    "    tr_accuracy = tr_accuracy / nb_tr_steps\n",
    "    print(f\"Training loss epoch: {epoch_loss}\")\n",
    "    print(f\"Training accuracy epoch: {tr_accuracy}\")\n",
    "\n",
    "    \n",
    "    print(\"Training eval\")\n",
    "    model.eval()\n",
    "    tr_preds, tr_labels = [], []\n",
    "    loss=0\n",
    "    for batch in train_loader:\n",
    "      \n",
    "      ids = batch['input_ids'].to(device, dtype = torch.long)\n",
    "      mask = batch['attention_mask'].to(device, dtype = torch.long)\n",
    "      labels = batch['labels'].to(device, dtype = torch.long)\n",
    "      tag_labels=batch['token_labels'].to(device, dtype = torch.long)\n",
    "\n",
    "      with torch.no_grad():\n",
    "          output, output_tokens = model(input_ids=ids, attention_mask=mask,)\n",
    "          loss+=loss_fct(output, labels.float())\n",
    "          \n",
    "\n",
    "          preds=torch.sigmoid(output)>0.5\n",
    "          tr_labels +=[lab.cpu() for lab in labels ]\n",
    "          tr_preds+=[lab for lab in preds ]\n",
    "         \n",
    "    \n",
    "    loss_train=loss/len(train_loader)\n",
    "    print(loss_train)\n",
    "    res=log_metrics(tr_preds, tr_labels)\n",
    "\n",
    "    print(\"Test eval\")\n",
    "    model.eval()\n",
    "    tr_preds, tr_labels = [], []\n",
    "    loss=0\n",
    "    if test:\n",
    "      for batch in test_loader:\n",
    "        ids = batch['input_ids'].to(device, dtype = torch.long)\n",
    "        mask = batch['attention_mask'].to(device, dtype = torch.long)\n",
    "        labels = batch['labels'].to(device, dtype = torch.long)\n",
    "        tag_labels=batch['token_labels'].to(device, dtype = torch.long)\n",
    "\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            \n",
    "            output, output_tokens = model(input_ids=ids, attention_mask=mask,)\n",
    "            loss+=loss_fct(output, labels.float())\n",
    "            preds=torch.sigmoid(output)>0.5\n",
    "            tr_labels.extend(labels)\n",
    "            tr_preds.extend(preds)\n",
    "            \n",
    "      loss_test=loss/len(test_loader)\n",
    "      res_test=log_metrics(tr_preds, tr_labels)\n",
    "      print(loss_test)\n",
    "      return loss_train, loss_test, res[\"f1_micro\"], res[\"f1_macro\"], res_test[\"f1_micro\"], res_test[\"f1_macro\"]\n",
    "    else:\n",
    "      return loss_train, 0, res[\"f1_micro\"],res[\"f1_macro\"], 0,0\n",
    "\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[29.81967213114754,\n",
       " 62.728813559322035,\n",
       " 1.078496406854616,\n",
       " 12.101045296167248,\n",
       " 207.88888888888889,\n",
       " 84.45454545454545,\n",
       " 23.415584415584416,\n",
       " 234.0,\n",
       " 6.258687258687258,\n",
       " 249.66666666666666,\n",
       " 40.31868131868132,\n",
       " 16.652582159624412,\n",
       " 2.840653728294178,\n",
       " 11.129032258064516,\n",
       " 249.66666666666666,\n",
       " 23.575163398692812,\n",
       " 5.911764705882353,\n",
       " 93.0,\n",
       " 7.068669527896995]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_weights=[]\n",
    "for i in range(len(frames_to_ids)):\n",
    "    class_weights.append((len(train)-sum(train[i]))/sum(train[i]))\n",
    "class_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5vkgUNgq0130",
    "outputId": "9f927c9e-6607-4fb5-ff56-994b1b48e344",
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at /mnt/lun2/kbaraniak/data/tmpen4/test-mlm were not used when initializing BertModel: ['cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertModel were not initialized from the model checkpoint at /mnt/lun2/kbaraniak/data/tmpen4/test-mlm and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training epoch: 1\n",
      "Start\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/lun2/pjwstk.edu.pl/kbaraniak/semeval/sem/lib64/python3.6/site-packages/ipykernel_launcher.py:62: UserWarning: torch.range is deprecated and will be removed in a future release because its behavior is inconsistent with Python's range builtin. Instead, use torch.arange, which produces values in [start, end).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss per 100 training steps: 1.779594898223877\n",
      "Training loss per 100 training steps: 1.3159680360614663\n",
      "Training loss per 100 training steps: 1.306007193392189\n",
      "Training loss per 100 training steps: 1.3131451388926205\n",
      "Training loss per 100 training steps: 1.3072991990983636\n",
      "Training loss epoch: 1.3128823470562063\n",
      "Training accuracy epoch: 0.0\n",
      "Training eval\n",
      "tensor(1.2160, device='cuda:2')\n",
      "                                 precision    recall  f1-score   support\n",
      "\n",
      "                          Doubt       0.25      0.32      0.28       518\n",
      "Obfuscation-Vagueness-Confusion       0.01      0.83      0.02        18\n",
      "           Appeal_to_Popularity       0.00      1.00      0.01        15\n",
      "      Exaggeration-Minimisation       0.15      0.60      0.24       466\n",
      "            Conversation_Killer       0.03      0.82      0.07        91\n",
      "                   Whataboutism       0.02      0.88      0.04        16\n",
      "                        Slogans       0.12      0.31      0.18       153\n",
      "           Guilt_by_Association       0.06      0.80      0.11        59\n",
      "            Appeal_to_Hypocrisy       0.01      1.00      0.02        40\n",
      "                     Repetition       0.25      0.33      0.28       544\n",
      "                    Flag_Waving       0.14      0.84      0.24       287\n",
      "          Name_Calling-Labeling       0.28      0.70      0.40       979\n",
      "      Causal_Oversimplification       0.06      0.98      0.11       213\n",
      "                Loaded_Language       0.50      0.87      0.63      1809\n",
      "                    Red_Herring       0.02      1.00      0.03        44\n",
      "        False_Dilemma-No_Choice       0.07      0.71      0.13       122\n",
      "                      Straw_Man       0.36      0.33      0.34        15\n",
      "       Appeal_to_Fear-Prejudice       0.13      0.89      0.22       310\n",
      "            Appeal_to_Authority       0.09      0.50      0.15       154\n",
      "\n",
      "                      micro avg       0.12      0.70      0.20      5853\n",
      "                      macro avg       0.13      0.72      0.18      5853\n",
      "                   weighted avg       0.28      0.70      0.37      5853\n",
      "                    samples avg       0.12      0.70      0.20      5853\n",
      "\n",
      "Test eval\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/lun2/pjwstk.edu.pl/kbaraniak/semeval/sem/lib64/python3.6/site-packages/ipykernel_launcher.py:62: UserWarning: torch.range is deprecated and will be removed in a future release because its behavior is inconsistent with Python's range builtin. Instead, use torch.arange, which produces values in [start, end).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                 precision    recall  f1-score   support\n",
      "\n",
      "                          Doubt       0.29      0.18      0.22       187\n",
      "Obfuscation-Vagueness-Confusion       0.02      0.38      0.03        13\n",
      "           Appeal_to_Popularity       0.03      0.88      0.06        34\n",
      "      Exaggeration-Minimisation       0.11      0.82      0.19       115\n",
      "            Conversation_Killer       0.03      0.88      0.05        25\n",
      "                   Whataboutism       0.01      1.00      0.01         2\n",
      "                        Slogans       0.08      0.32      0.13        28\n",
      "           Guilt_by_Association       0.02      0.50      0.03         4\n",
      "            Appeal_to_Hypocrisy       0.01      1.00      0.01         8\n",
      "                     Repetition       0.14      0.13      0.14       141\n",
      "                    Flag_Waving       0.11      0.88      0.19        96\n",
      "          Name_Calling-Labeling       0.25      0.84      0.38       250\n",
      "      Causal_Oversimplification       0.03      1.00      0.05        24\n",
      "                Loaded_Language       0.44      0.73      0.55       483\n",
      "                    Red_Herring       0.02      0.79      0.03        19\n",
      "        False_Dilemma-No_Choice       0.14      0.54      0.22        63\n",
      "                      Straw_Man       0.00      0.00      0.00         9\n",
      "       Appeal_to_Fear-Prejudice       0.20      0.72      0.31       137\n",
      "            Appeal_to_Authority       0.02      0.04      0.02        28\n",
      "\n",
      "                      micro avg       0.10      0.63      0.18      1666\n",
      "                      macro avg       0.10      0.61      0.14      1666\n",
      "                   weighted avg       0.25      0.63      0.32      1666\n",
      "                    samples avg       0.10      0.61      0.17      1666\n",
      "\n",
      "tensor(1.5060, device='cuda:2')\n",
      "tensor(1.2160, device='cuda:2') tensor(1.5060, device='cuda:2') 0.20347456567929006 0.17821443827424177\n",
      "Training epoch: 2\n",
      "Start\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/lun2/pjwstk.edu.pl/kbaraniak/semeval/sem/lib64/python3.6/site-packages/ipykernel_launcher.py:62: UserWarning: torch.range is deprecated and will be removed in a future release because its behavior is inconsistent with Python's range builtin. Instead, use torch.arange, which produces values in [start, end).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss per 100 training steps: 2.2579851150512695\n",
      "Training loss per 100 training steps: 1.241610560676839\n",
      "Training loss per 100 training steps: 1.2132926165167965\n",
      "Training loss per 100 training steps: 1.2074064212384017\n",
      "Training loss per 100 training steps: 1.217533703902713\n",
      "Training loss epoch: 1.2101513555709351\n",
      "Training accuracy epoch: 0.0\n",
      "Training eval\n",
      "tensor(1.0678, device='cuda:2')\n",
      "                                 precision    recall  f1-score   support\n",
      "\n",
      "                          Doubt       0.20      0.81      0.32       518\n",
      "Obfuscation-Vagueness-Confusion       0.03      0.94      0.06        18\n",
      "           Appeal_to_Popularity       0.02      0.67      0.05        15\n",
      "      Exaggeration-Minimisation       0.18      0.59      0.27       466\n",
      "            Conversation_Killer       0.11      0.53      0.18        91\n",
      "                   Whataboutism       0.02      0.94      0.04        16\n",
      "                        Slogans       0.10      0.83      0.18       153\n",
      "           Guilt_by_Association       0.05      1.00      0.09        59\n",
      "            Appeal_to_Hypocrisy       0.01      1.00      0.03        40\n",
      "                     Repetition       0.20      0.65      0.31       544\n",
      "                    Flag_Waving       0.27      0.66      0.38       287\n",
      "          Name_Calling-Labeling       0.35      0.75      0.48       979\n",
      "      Causal_Oversimplification       0.08      0.89      0.15       213\n",
      "                Loaded_Language       0.55      0.67      0.60      1809\n",
      "                    Red_Herring       0.02      1.00      0.04        44\n",
      "        False_Dilemma-No_Choice       0.10      0.75      0.17       122\n",
      "                      Straw_Man       0.01      1.00      0.01        15\n",
      "       Appeal_to_Fear-Prejudice       0.24      0.55      0.33       310\n",
      "            Appeal_to_Authority       0.09      0.73      0.15       154\n",
      "\n",
      "                      micro avg       0.15      0.70      0.24      5853\n",
      "                      macro avg       0.14      0.79      0.20      5853\n",
      "                   weighted avg       0.32      0.70      0.40      5853\n",
      "                    samples avg       0.15      0.70      0.24      5853\n",
      "\n",
      "Test eval\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/lun2/pjwstk.edu.pl/kbaraniak/semeval/sem/lib64/python3.6/site-packages/ipykernel_launcher.py:62: UserWarning: torch.range is deprecated and will be removed in a future release because its behavior is inconsistent with Python's range builtin. Instead, use torch.arange, which produces values in [start, end).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                 precision    recall  f1-score   support\n",
      "\n",
      "                          Doubt       0.22      0.68      0.33       187\n",
      "Obfuscation-Vagueness-Confusion       0.03      0.31      0.06        13\n",
      "           Appeal_to_Popularity       0.00      0.00      0.00        34\n",
      "      Exaggeration-Minimisation       0.10      0.54      0.18       115\n",
      "            Conversation_Killer       0.04      0.88      0.08        25\n",
      "                   Whataboutism       0.00      1.00      0.01         2\n",
      "                        Slogans       0.06      0.68      0.10        28\n",
      "           Guilt_by_Association       0.02      1.00      0.04         4\n",
      "            Appeal_to_Hypocrisy       0.01      0.75      0.01         8\n",
      "                     Repetition       0.14      0.35      0.20       141\n",
      "                    Flag_Waving       0.22      0.76      0.34        96\n",
      "          Name_Calling-Labeling       0.32      0.78      0.46       250\n",
      "      Causal_Oversimplification       0.03      0.50      0.06        24\n",
      "                Loaded_Language       0.48      0.53      0.51       483\n",
      "                    Red_Herring       0.02      0.84      0.05        19\n",
      "        False_Dilemma-No_Choice       0.16      0.73      0.27        63\n",
      "                      Straw_Man       0.01      0.67      0.01         9\n",
      "       Appeal_to_Fear-Prejudice       0.24      0.18      0.21       137\n",
      "            Appeal_to_Authority       0.02      0.18      0.04        28\n",
      "\n",
      "                      micro avg       0.12      0.56      0.20      1666\n",
      "                      macro avg       0.11      0.60      0.15      1666\n",
      "                   weighted avg       0.27      0.56      0.33      1666\n",
      "                    samples avg       0.12      0.55      0.19      1666\n",
      "\n",
      "tensor(1.6593, device='cuda:2')\n",
      "tensor(1.0678, device='cuda:2') tensor(1.6593, device='cuda:2') 0.24098782771535582 0.19508110936682366\n",
      "Training epoch: 3\n",
      "Start\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/lun2/pjwstk.edu.pl/kbaraniak/semeval/sem/lib64/python3.6/site-packages/ipykernel_launcher.py:62: UserWarning: torch.range is deprecated and will be removed in a future release because its behavior is inconsistent with Python's range builtin. Instead, use torch.arange, which produces values in [start, end).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss per 100 training steps: 1.7802680730819702\n",
      "Training loss per 100 training steps: 1.0738414838762567\n",
      "Training loss per 100 training steps: 1.0655012018051906\n",
      "Training loss per 100 training steps: 1.0962365865707397\n",
      "Training loss per 100 training steps: 1.0943491641720038\n",
      "Training loss epoch: 1.0883979659131233\n",
      "Training accuracy epoch: 0.0\n",
      "Training eval\n",
      "tensor(0.9309, device='cuda:2')\n",
      "                                 precision    recall  f1-score   support\n",
      "\n",
      "                          Doubt       0.26      0.69      0.37       518\n",
      "Obfuscation-Vagueness-Confusion       0.05      0.89      0.10        18\n",
      "           Appeal_to_Popularity       0.01      1.00      0.02        15\n",
      "      Exaggeration-Minimisation       0.21      0.56      0.30       466\n",
      "            Conversation_Killer       0.07      0.82      0.12        91\n",
      "                   Whataboutism       0.09      0.94      0.16        16\n",
      "                        Slogans       0.24      0.56      0.34       153\n",
      "           Guilt_by_Association       0.06      1.00      0.11        59\n",
      "            Appeal_to_Hypocrisy       0.04      0.90      0.08        40\n",
      "                     Repetition       0.28      0.41      0.33       544\n",
      "                    Flag_Waving       0.24      0.86      0.37       287\n",
      "          Name_Calling-Labeling       0.37      0.79      0.50       979\n",
      "      Causal_Oversimplification       0.12      0.67      0.20       213\n",
      "                Loaded_Language       0.55      0.81      0.66      1809\n",
      "                    Red_Herring       0.03      1.00      0.06        44\n",
      "        False_Dilemma-No_Choice       0.09      0.89      0.17       122\n",
      "                      Straw_Man       0.01      1.00      0.03        15\n",
      "       Appeal_to_Fear-Prejudice       0.17      0.85      0.28       310\n",
      "            Appeal_to_Authority       0.10      0.83      0.18       154\n",
      "\n",
      "                      micro avg       0.20      0.74      0.31      5853\n",
      "                      macro avg       0.16      0.81      0.23      5853\n",
      "                   weighted avg       0.34      0.74      0.44      5853\n",
      "                    samples avg       0.22      0.74      0.32      5853\n",
      "\n",
      "Test eval\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/lun2/pjwstk.edu.pl/kbaraniak/semeval/sem/lib64/python3.6/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/mnt/lun2/pjwstk.edu.pl/kbaraniak/semeval/sem/lib64/python3.6/site-packages/ipykernel_launcher.py:62: UserWarning: torch.range is deprecated and will be removed in a future release because its behavior is inconsistent with Python's range builtin. Instead, use torch.arange, which produces values in [start, end).\n",
      "/mnt/lun2/pjwstk.edu.pl/kbaraniak/semeval/sem/lib64/python3.6/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                 precision    recall  f1-score   support\n",
      "\n",
      "                          Doubt       0.27      0.65      0.38       187\n",
      "Obfuscation-Vagueness-Confusion       0.03      0.23      0.06        13\n",
      "           Appeal_to_Popularity       0.04      0.12      0.06        34\n",
      "      Exaggeration-Minimisation       0.13      0.40      0.20       115\n",
      "            Conversation_Killer       0.03      0.92      0.06        25\n",
      "                   Whataboutism       0.06      0.50      0.11         2\n",
      "                        Slogans       0.16      0.32      0.21        28\n",
      "           Guilt_by_Association       0.02      0.75      0.05         4\n",
      "            Appeal_to_Hypocrisy       0.03      0.38      0.05         8\n",
      "                     Repetition       0.17      0.13      0.15       141\n",
      "                    Flag_Waving       0.18      0.86      0.30        96\n",
      "          Name_Calling-Labeling       0.35      0.76      0.48       250\n",
      "      Causal_Oversimplification       0.01      0.04      0.02        24\n",
      "                Loaded_Language       0.50      0.60      0.55       483\n",
      "                    Red_Herring       0.05      0.63      0.09        19\n",
      "        False_Dilemma-No_Choice       0.16      0.78      0.26        63\n",
      "                      Straw_Man       0.01      0.33      0.03         9\n",
      "       Appeal_to_Fear-Prejudice       0.23      0.47      0.31       137\n",
      "            Appeal_to_Authority       0.03      0.29      0.06        28\n",
      "\n",
      "                      micro avg       0.18      0.56      0.28      1666\n",
      "                      macro avg       0.13      0.48      0.18      1666\n",
      "                   weighted avg       0.29      0.56      0.36      1666\n",
      "                    samples avg       0.20      0.56      0.28      1666\n",
      "\n",
      "tensor(1.5203, device='cuda:2')\n",
      "tensor(0.9309, device='cuda:2') tensor(1.5203, device='cuda:2') 0.3087506683300659 0.27709231455329275\n",
      "Training epoch: 4\n",
      "Start\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/lun2/pjwstk.edu.pl/kbaraniak/semeval/sem/lib64/python3.6/site-packages/ipykernel_launcher.py:62: UserWarning: torch.range is deprecated and will be removed in a future release because its behavior is inconsistent with Python's range builtin. Instead, use torch.arange, which produces values in [start, end).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss per 100 training steps: 0.7208813428878784\n",
      "Training loss per 100 training steps: 0.9750003909120465\n",
      "Training loss per 100 training steps: 0.9367511325807714\n",
      "Training loss per 100 training steps: 0.9459503982154238\n",
      "Training loss per 100 training steps: 0.9516455317821884\n",
      "Training loss epoch: 0.9551895658386514\n",
      "Training accuracy epoch: 0.0\n",
      "Training eval\n",
      "tensor(0.8239, device='cuda:2')\n",
      "                                 precision    recall  f1-score   support\n",
      "\n",
      "                          Doubt       0.29      0.66      0.41       518\n",
      "Obfuscation-Vagueness-Confusion       0.04      1.00      0.08        18\n",
      "           Appeal_to_Popularity       0.04      0.93      0.07        15\n",
      "      Exaggeration-Minimisation       0.19      0.78      0.30       466\n",
      "            Conversation_Killer       0.05      0.93      0.09        91\n",
      "                   Whataboutism       0.02      0.94      0.04        16\n",
      "                        Slogans       0.10      0.95      0.18       153\n",
      "           Guilt_by_Association       0.08      1.00      0.15        59\n",
      "            Appeal_to_Hypocrisy       0.05      1.00      0.10        40\n",
      "                     Repetition       0.23      0.69      0.34       544\n",
      "                    Flag_Waving       0.18      0.96      0.30       287\n",
      "          Name_Calling-Labeling       0.41      0.72      0.52       979\n",
      "      Causal_Oversimplification       0.09      0.93      0.16       213\n",
      "                Loaded_Language       0.60      0.73      0.66      1809\n",
      "                    Red_Herring       0.03      1.00      0.06        44\n",
      "        False_Dilemma-No_Choice       0.08      0.97      0.15       122\n",
      "                      Straw_Man       0.04      1.00      0.07        15\n",
      "       Appeal_to_Fear-Prejudice       0.17      0.90      0.29       310\n",
      "            Appeal_to_Authority       0.10      0.90      0.19       154\n",
      "\n",
      "                      micro avg       0.18      0.78      0.29      5853\n",
      "                      macro avg       0.15      0.89      0.22      5853\n",
      "                   weighted avg       0.35      0.78      0.44      5853\n",
      "                    samples avg       0.20      0.77      0.30      5853\n",
      "\n",
      "Test eval\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/lun2/pjwstk.edu.pl/kbaraniak/semeval/sem/lib64/python3.6/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/mnt/lun2/pjwstk.edu.pl/kbaraniak/semeval/sem/lib64/python3.6/site-packages/ipykernel_launcher.py:62: UserWarning: torch.range is deprecated and will be removed in a future release because its behavior is inconsistent with Python's range builtin. Instead, use torch.arange, which produces values in [start, end).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                 precision    recall  f1-score   support\n",
      "\n",
      "                          Doubt       0.27      0.57      0.37       187\n",
      "Obfuscation-Vagueness-Confusion       0.03      0.31      0.06        13\n",
      "           Appeal_to_Popularity       0.00      0.00      0.00        34\n",
      "      Exaggeration-Minimisation       0.13      0.53      0.20       115\n",
      "            Conversation_Killer       0.03      1.00      0.06        25\n",
      "                   Whataboutism       0.01      0.50      0.02         2\n",
      "                        Slogans       0.06      0.82      0.11        28\n",
      "           Guilt_by_Association       0.05      0.75      0.10         4\n",
      "            Appeal_to_Hypocrisy       0.04      0.25      0.07         8\n",
      "                     Repetition       0.16      0.37      0.23       141\n",
      "                    Flag_Waving       0.16      0.94      0.27        96\n",
      "          Name_Calling-Labeling       0.41      0.60      0.49       250\n",
      "      Causal_Oversimplification       0.03      0.38      0.06        24\n",
      "                Loaded_Language       0.53      0.46      0.49       483\n",
      "                    Red_Herring       0.05      0.58      0.09        19\n",
      "        False_Dilemma-No_Choice       0.13      0.87      0.22        63\n",
      "                      Straw_Man       0.01      0.11      0.03         9\n",
      "       Appeal_to_Fear-Prejudice       0.23      0.55      0.33       137\n",
      "            Appeal_to_Authority       0.03      0.36      0.06        28\n",
      "\n",
      "                      micro avg       0.16      0.54      0.24      1666\n",
      "                      macro avg       0.12      0.52      0.17      1666\n",
      "                   weighted avg       0.30      0.54      0.35      1666\n",
      "                    samples avg       0.16      0.52      0.23      1666\n",
      "\n",
      "tensor(1.9899, device='cuda:2')\n",
      "tensor(0.8239, device='cuda:2') tensor(1.9899, device='cuda:2') 0.2949969196848351 0.24154589371980675\n",
      "Training epoch: 5\n",
      "Start\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/lun2/pjwstk.edu.pl/kbaraniak/semeval/sem/lib64/python3.6/site-packages/ipykernel_launcher.py:62: UserWarning: torch.range is deprecated and will be removed in a future release because its behavior is inconsistent with Python's range builtin. Instead, use torch.arange, which produces values in [start, end).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss per 100 training steps: 0.7957789301872253\n",
      "Training loss per 100 training steps: 0.8560346347270625\n",
      "Training loss per 100 training steps: 0.8843014201714625\n",
      "Training loss per 100 training steps: 0.8802322646312143\n",
      "Training loss per 100 training steps: 0.8713066170637744\n",
      "Training loss epoch: 0.870822748858878\n",
      "Training accuracy epoch: 0.0\n",
      "Training eval\n",
      "tensor(0.7876, device='cuda:2')\n",
      "                                 precision    recall  f1-score   support\n",
      "\n",
      "                          Doubt       0.26      0.86      0.39       518\n",
      "Obfuscation-Vagueness-Confusion       0.07      0.94      0.13        18\n",
      "           Appeal_to_Popularity       0.08      0.93      0.15        15\n",
      "      Exaggeration-Minimisation       0.19      0.79      0.30       466\n",
      "            Conversation_Killer       0.18      0.64      0.28        91\n",
      "                   Whataboutism       0.02      1.00      0.04        16\n",
      "                        Slogans       0.19      0.81      0.31       153\n",
      "           Guilt_by_Association       0.17      1.00      0.30        59\n",
      "            Appeal_to_Hypocrisy       0.06      1.00      0.12        40\n",
      "                     Repetition       0.25      0.45      0.33       544\n",
      "                    Flag_Waving       0.37      0.81      0.51       287\n",
      "          Name_Calling-Labeling       0.38      0.79      0.52       979\n",
      "      Causal_Oversimplification       0.15      0.73      0.24       213\n",
      "                Loaded_Language       0.60      0.74      0.66      1809\n",
      "                    Red_Herring       0.02      1.00      0.03        44\n",
      "        False_Dilemma-No_Choice       0.22      0.65      0.33       122\n",
      "                      Straw_Man       0.05      1.00      0.09        15\n",
      "       Appeal_to_Fear-Prejudice       0.28      0.54      0.37       310\n",
      "            Appeal_to_Authority       0.15      0.82      0.26       154\n",
      "\n",
      "                      micro avg       0.23      0.74      0.36      5853\n",
      "                      macro avg       0.19      0.82      0.28      5853\n",
      "                   weighted avg       0.37      0.74      0.47      5853\n",
      "                    samples avg       0.25      0.73      0.35      5853\n",
      "\n",
      "Test eval\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/lun2/pjwstk.edu.pl/kbaraniak/semeval/sem/lib64/python3.6/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/mnt/lun2/pjwstk.edu.pl/kbaraniak/semeval/sem/lib64/python3.6/site-packages/ipykernel_launcher.py:62: UserWarning: torch.range is deprecated and will be removed in a future release because its behavior is inconsistent with Python's range builtin. Instead, use torch.arange, which produces values in [start, end).\n",
      "/mnt/lun2/pjwstk.edu.pl/kbaraniak/semeval/sem/lib64/python3.6/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                 precision    recall  f1-score   support\n",
      "\n",
      "                          Doubt       0.27      0.72      0.39       187\n",
      "Obfuscation-Vagueness-Confusion       0.06      0.15      0.09        13\n",
      "           Appeal_to_Popularity       0.00      0.00      0.00        34\n",
      "      Exaggeration-Minimisation       0.14      0.56      0.22       115\n",
      "            Conversation_Killer       0.06      0.80      0.11        25\n",
      "                   Whataboutism       0.01      0.50      0.02         2\n",
      "                        Slogans       0.12      0.54      0.19        28\n",
      "           Guilt_by_Association       0.12      0.75      0.21         4\n",
      "            Appeal_to_Hypocrisy       0.07      0.25      0.11         8\n",
      "                     Repetition       0.15      0.20      0.17       141\n",
      "                    Flag_Waving       0.29      0.70      0.41        96\n",
      "          Name_Calling-Labeling       0.41      0.67      0.51       250\n",
      "      Causal_Oversimplification       0.05      0.12      0.08        24\n",
      "                Loaded_Language       0.55      0.57      0.56       483\n",
      "                    Red_Herring       0.03      0.79      0.06        19\n",
      "        False_Dilemma-No_Choice       0.23      0.56      0.32        63\n",
      "                      Straw_Man       0.04      0.11      0.06         9\n",
      "       Appeal_to_Fear-Prejudice       0.20      0.14      0.16       137\n",
      "            Appeal_to_Authority       0.05      0.29      0.08        28\n",
      "\n",
      "                      micro avg       0.22      0.52      0.31      1666\n",
      "                      macro avg       0.15      0.44      0.20      1666\n",
      "                   weighted avg       0.32      0.52      0.37      1666\n",
      "                    samples avg       0.23      0.51      0.29      1666\n",
      "\n",
      "tensor(2.4474, device='cuda:2')\n",
      "tensor(0.7876, device='cuda:2') tensor(2.4474, device='cuda:2') 0.35548954078475054 0.30697674418604654\n",
      "Training epoch: 6\n",
      "Start\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/lun2/pjwstk.edu.pl/kbaraniak/semeval/sem/lib64/python3.6/site-packages/ipykernel_launcher.py:62: UserWarning: torch.range is deprecated and will be removed in a future release because its behavior is inconsistent with Python's range builtin. Instead, use torch.arange, which produces values in [start, end).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss per 100 training steps: 0.49536892771720886\n",
      "Training loss per 100 training steps: 0.8044403334065239\n",
      "Training loss per 100 training steps: 0.7856552331008722\n",
      "Training loss per 100 training steps: 0.7892682661249788\n",
      "Training loss per 100 training steps: 0.8090636888495705\n",
      "Training loss epoch: 0.8220683833386035\n",
      "Training accuracy epoch: 0.0\n",
      "Training eval\n",
      "tensor(0.7400, device='cuda:2')\n",
      "                                 precision    recall  f1-score   support\n",
      "\n",
      "                          Doubt       0.36      0.59      0.45       518\n",
      "Obfuscation-Vagueness-Confusion       0.02      1.00      0.03        18\n",
      "           Appeal_to_Popularity       0.02      1.00      0.03        15\n",
      "      Exaggeration-Minimisation       0.23      0.68      0.34       466\n",
      "            Conversation_Killer       0.13      0.80      0.22        91\n",
      "                   Whataboutism       0.02      1.00      0.03        16\n",
      "                        Slogans       0.17      0.90      0.29       153\n",
      "           Guilt_by_Association       0.23      1.00      0.37        59\n",
      "            Appeal_to_Hypocrisy       0.06      1.00      0.11        40\n",
      "                     Repetition       0.22      0.70      0.34       544\n",
      "                    Flag_Waving       0.24      0.96      0.38       287\n",
      "          Name_Calling-Labeling       0.47      0.50      0.49       979\n",
      "      Causal_Oversimplification       0.14      0.83      0.24       213\n",
      "                Loaded_Language       0.62      0.69      0.65      1809\n",
      "                    Red_Herring       0.06      1.00      0.11        44\n",
      "        False_Dilemma-No_Choice       0.13      0.97      0.24       122\n",
      "                      Straw_Man       0.04      1.00      0.07        15\n",
      "       Appeal_to_Fear-Prejudice       0.22      0.81      0.34       310\n",
      "            Appeal_to_Authority       0.09      0.98      0.16       154\n",
      "\n",
      "                      micro avg       0.21      0.70      0.32      5853\n",
      "                      macro avg       0.18      0.86      0.26      5853\n",
      "                   weighted avg       0.39      0.70      0.45      5853\n",
      "                    samples avg       0.25      0.70      0.35      5853\n",
      "\n",
      "Test eval\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/lun2/pjwstk.edu.pl/kbaraniak/semeval/sem/lib64/python3.6/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/mnt/lun2/pjwstk.edu.pl/kbaraniak/semeval/sem/lib64/python3.6/site-packages/ipykernel_launcher.py:62: UserWarning: torch.range is deprecated and will be removed in a future release because its behavior is inconsistent with Python's range builtin. Instead, use torch.arange, which produces values in [start, end).\n",
      "/mnt/lun2/pjwstk.edu.pl/kbaraniak/semeval/sem/lib64/python3.6/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                 precision    recall  f1-score   support\n",
      "\n",
      "                          Doubt       0.34      0.43      0.38       187\n",
      "Obfuscation-Vagueness-Confusion       0.02      0.38      0.04        13\n",
      "           Appeal_to_Popularity       0.06      0.06      0.06        34\n",
      "      Exaggeration-Minimisation       0.15      0.38      0.21       115\n",
      "            Conversation_Killer       0.05      0.80      0.10        25\n",
      "                   Whataboutism       0.01      0.50      0.02         2\n",
      "                        Slogans       0.09      0.68      0.16        28\n",
      "           Guilt_by_Association       0.23      0.75      0.35         4\n",
      "            Appeal_to_Hypocrisy       0.09      0.38      0.14         8\n",
      "                     Repetition       0.16      0.38      0.22       141\n",
      "                    Flag_Waving       0.22      0.89      0.35        96\n",
      "          Name_Calling-Labeling       0.53      0.53      0.53       250\n",
      "      Causal_Oversimplification       0.05      0.17      0.08        24\n",
      "                Loaded_Language       0.56      0.47      0.51       483\n",
      "                    Red_Herring       0.04      0.16      0.06        19\n",
      "        False_Dilemma-No_Choice       0.18      0.68      0.28        63\n",
      "                      Straw_Man       0.05      0.11      0.07         9\n",
      "       Appeal_to_Fear-Prejudice       0.23      0.31      0.27       137\n",
      "            Appeal_to_Authority       0.03      0.32      0.05        28\n",
      "\n",
      "                      micro avg       0.20      0.47      0.28      1666\n",
      "                      macro avg       0.16      0.44      0.20      1666\n",
      "                   weighted avg       0.35      0.47      0.37      1666\n",
      "                    samples avg       0.24      0.46      0.28      1666\n",
      "\n",
      "tensor(2.0237, device='cuda:2')\n",
      "tensor(0.7400, device='cuda:2') tensor(2.0237, device='cuda:2') 0.3239209833876605 0.28317298965329457\n",
      "Training epoch: 7\n",
      "Start\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/lun2/pjwstk.edu.pl/kbaraniak/semeval/sem/lib64/python3.6/site-packages/ipykernel_launcher.py:62: UserWarning: torch.range is deprecated and will be removed in a future release because its behavior is inconsistent with Python's range builtin. Instead, use torch.arange, which produces values in [start, end).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss per 100 training steps: 0.5717795491218567\n",
      "Training loss per 100 training steps: 0.7510000726964214\n",
      "Training loss per 100 training steps: 0.7462342580159506\n",
      "Training loss per 100 training steps: 0.7435373370829611\n",
      "Training loss per 100 training steps: 0.7432090291507226\n",
      "Training loss epoch: 0.742673124468073\n",
      "Training accuracy epoch: 0.0\n",
      "Training eval\n",
      "tensor(0.6735, device='cuda:2')\n",
      "                                 precision    recall  f1-score   support\n",
      "\n",
      "                          Doubt       0.35      0.65      0.46       518\n",
      "Obfuscation-Vagueness-Confusion       0.14      1.00      0.25        18\n",
      "           Appeal_to_Popularity       0.12      1.00      0.22        15\n",
      "      Exaggeration-Minimisation       0.19      0.81      0.31       466\n",
      "            Conversation_Killer       0.15      0.81      0.25        91\n",
      "                   Whataboutism       0.24      1.00      0.39        16\n",
      "                        Slogans       0.17      0.94      0.29       153\n",
      "           Guilt_by_Association       0.15      1.00      0.27        59\n",
      "            Appeal_to_Hypocrisy       0.03      1.00      0.06        40\n",
      "                     Repetition       0.28      0.42      0.34       544\n",
      "                    Flag_Waving       0.18      0.98      0.30       287\n",
      "          Name_Calling-Labeling       0.37      0.87      0.52       979\n",
      "      Causal_Oversimplification       0.09      0.97      0.17       213\n",
      "                Loaded_Language       0.58      0.85      0.69      1809\n",
      "                    Red_Herring       0.05      1.00      0.10        44\n",
      "        False_Dilemma-No_Choice       0.15      0.96      0.26       122\n",
      "                      Straw_Man       0.12      1.00      0.21        15\n",
      "       Appeal_to_Fear-Prejudice       0.18      0.92      0.30       310\n",
      "            Appeal_to_Authority       0.18      0.90      0.30       154\n",
      "\n",
      "                      micro avg       0.24      0.82      0.37      5853\n",
      "                      macro avg       0.20      0.90      0.30      5853\n",
      "                   weighted avg       0.35      0.82      0.46      5853\n",
      "                    samples avg       0.26      0.81      0.37      5853\n",
      "\n",
      "Test eval\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/lun2/pjwstk.edu.pl/kbaraniak/semeval/sem/lib64/python3.6/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/mnt/lun2/pjwstk.edu.pl/kbaraniak/semeval/sem/lib64/python3.6/site-packages/ipykernel_launcher.py:62: UserWarning: torch.range is deprecated and will be removed in a future release because its behavior is inconsistent with Python's range builtin. Instead, use torch.arange, which produces values in [start, end).\n",
      "/mnt/lun2/pjwstk.edu.pl/kbaraniak/semeval/sem/lib64/python3.6/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                 precision    recall  f1-score   support\n",
      "\n",
      "                          Doubt       0.32      0.49      0.39       187\n",
      "Obfuscation-Vagueness-Confusion       0.04      0.23      0.06        13\n",
      "           Appeal_to_Popularity       0.00      0.00      0.00        34\n",
      "      Exaggeration-Minimisation       0.16      0.51      0.24       115\n",
      "            Conversation_Killer       0.05      0.88      0.09        25\n",
      "                   Whataboutism       0.00      0.00      0.00         2\n",
      "                        Slogans       0.09      0.68      0.15        28\n",
      "           Guilt_by_Association       0.12      0.75      0.21         4\n",
      "            Appeal_to_Hypocrisy       0.03      0.50      0.05         8\n",
      "                     Repetition       0.14      0.10      0.12       141\n",
      "                    Flag_Waving       0.17      0.95      0.29        96\n",
      "          Name_Calling-Labeling       0.38      0.69      0.49       250\n",
      "      Causal_Oversimplification       0.03      0.46      0.06        24\n",
      "                Loaded_Language       0.55      0.63      0.58       483\n",
      "                    Red_Herring       0.01      0.05      0.02        19\n",
      "        False_Dilemma-No_Choice       0.14      0.83      0.24        63\n",
      "                      Straw_Man       0.00      0.00      0.00         9\n",
      "       Appeal_to_Fear-Prejudice       0.21      0.53      0.30       137\n",
      "            Appeal_to_Authority       0.06      0.32      0.10        28\n",
      "\n",
      "                      micro avg       0.20      0.56      0.30      1666\n",
      "                      macro avg       0.13      0.45      0.18      1666\n",
      "                   weighted avg       0.31      0.56      0.37      1666\n",
      "                    samples avg       0.22      0.55      0.29      1666\n",
      "\n",
      "tensor(2.4420, device='cuda:2')\n",
      "tensor(0.6735, device='cuda:2') tensor(2.4420, device='cuda:2') 0.3708722078123185 0.297879177377892\n",
      "Training epoch: 8\n",
      "Start\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/lun2/pjwstk.edu.pl/kbaraniak/semeval/sem/lib64/python3.6/site-packages/ipykernel_launcher.py:62: UserWarning: torch.range is deprecated and will be removed in a future release because its behavior is inconsistent with Python's range builtin. Instead, use torch.arange, which produces values in [start, end).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss per 100 training steps: 0.5768918991088867\n",
      "Training loss per 100 training steps: 0.7134822137875132\n",
      "Training loss per 100 training steps: 0.7206667999723064\n",
      "Training loss per 100 training steps: 0.7490404235366175\n",
      "Training loss per 100 training steps: 0.7502071861911593\n",
      "Training loss epoch: 0.7482936837571732\n",
      "Training accuracy epoch: 0.0\n",
      "Training eval\n",
      "tensor(0.7138, device='cuda:2')\n",
      "                                 precision    recall  f1-score   support\n",
      "\n",
      "                          Doubt       0.23      0.92      0.36       518\n",
      "Obfuscation-Vagueness-Confusion       0.05      1.00      0.09        18\n",
      "           Appeal_to_Popularity       0.04      1.00      0.08        15\n",
      "      Exaggeration-Minimisation       0.25      0.68      0.36       466\n",
      "            Conversation_Killer       0.24      0.87      0.37        91\n",
      "                   Whataboutism       0.01      1.00      0.01        16\n",
      "                        Slogans       0.22      0.97      0.35       153\n",
      "           Guilt_by_Association       0.08      1.00      0.15        59\n",
      "            Appeal_to_Hypocrisy       0.05      1.00      0.10        40\n",
      "                     Repetition       0.25      0.65      0.36       544\n",
      "                    Flag_Waving       0.35      0.92      0.50       287\n",
      "          Name_Calling-Labeling       0.46      0.63      0.53       979\n",
      "      Causal_Oversimplification       0.09      0.97      0.17       213\n",
      "                Loaded_Language       0.68      0.54      0.60      1809\n",
      "                    Red_Herring       0.03      1.00      0.06        44\n",
      "        False_Dilemma-No_Choice       0.21      0.96      0.35       122\n",
      "                      Straw_Man       0.02      1.00      0.03        15\n",
      "       Appeal_to_Fear-Prejudice       0.28      0.78      0.41       310\n",
      "            Appeal_to_Authority       0.16      0.95      0.28       154\n",
      "\n",
      "                      micro avg       0.20      0.71      0.31      5853\n",
      "                      macro avg       0.19      0.89      0.27      5853\n",
      "                   weighted avg       0.40      0.71      0.45      5853\n",
      "                    samples avg       0.22      0.69      0.31      5853\n",
      "\n",
      "Test eval\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/lun2/pjwstk.edu.pl/kbaraniak/semeval/sem/lib64/python3.6/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/mnt/lun2/pjwstk.edu.pl/kbaraniak/semeval/sem/lib64/python3.6/site-packages/ipykernel_launcher.py:62: UserWarning: torch.range is deprecated and will be removed in a future release because its behavior is inconsistent with Python's range builtin. Instead, use torch.arange, which produces values in [start, end).\n",
      "/mnt/lun2/pjwstk.edu.pl/kbaraniak/semeval/sem/lib64/python3.6/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                 precision    recall  f1-score   support\n",
      "\n",
      "                          Doubt       0.24      0.82      0.37       187\n",
      "Obfuscation-Vagueness-Confusion       0.03      0.23      0.06        13\n",
      "           Appeal_to_Popularity       0.00      0.00      0.00        34\n",
      "      Exaggeration-Minimisation       0.17      0.38      0.24       115\n",
      "            Conversation_Killer       0.05      0.72      0.09        25\n",
      "                   Whataboutism       0.00      1.00      0.01         2\n",
      "                        Slogans       0.14      0.43      0.21        28\n",
      "           Guilt_by_Association       0.11      0.75      0.19         4\n",
      "            Appeal_to_Hypocrisy       0.09      0.50      0.16         8\n",
      "                     Repetition       0.16      0.21      0.18       141\n",
      "                    Flag_Waving       0.26      0.80      0.39        96\n",
      "          Name_Calling-Labeling       0.54      0.48      0.51       250\n",
      "      Causal_Oversimplification       0.04      0.42      0.07        24\n",
      "                Loaded_Language       0.62      0.30      0.41       483\n",
      "                    Red_Herring       0.02      0.32      0.04        19\n",
      "        False_Dilemma-No_Choice       0.20      0.59      0.29        63\n",
      "                      Straw_Man       0.01      0.11      0.01         9\n",
      "       Appeal_to_Fear-Prejudice       0.23      0.21      0.22       137\n",
      "            Appeal_to_Authority       0.04      0.18      0.07        28\n",
      "\n",
      "                      micro avg       0.17      0.42      0.24      1666\n",
      "                      macro avg       0.16      0.44      0.19      1666\n",
      "                   weighted avg       0.36      0.42      0.33      1666\n",
      "                    samples avg       0.19      0.41      0.23      1666\n",
      "\n",
      "tensor(2.2556, device='cuda:2')\n",
      "tensor(0.7138, device='cuda:2') tensor(2.2556, device='cuda:2') 0.3110110673419621 0.23816013628620103\n",
      "Training epoch: 9\n",
      "Start\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/lun2/pjwstk.edu.pl/kbaraniak/semeval/sem/lib64/python3.6/site-packages/ipykernel_launcher.py:62: UserWarning: torch.range is deprecated and will be removed in a future release because its behavior is inconsistent with Python's range builtin. Instead, use torch.arange, which produces values in [start, end).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss per 100 training steps: 0.7235702872276306\n",
      "Training loss per 100 training steps: 0.6859605610370636\n",
      "Training loss per 100 training steps: 0.6679904248880509\n",
      "Training loss per 100 training steps: 0.6787575072426336\n",
      "Training loss per 100 training steps: 0.6811940210715791\n",
      "Training loss epoch: 0.6790030652538259\n",
      "Training accuracy epoch: 0.0\n",
      "Training eval\n",
      "tensor(0.6379, device='cuda:2')\n",
      "                                 precision    recall  f1-score   support\n",
      "\n",
      "                          Doubt       0.26      0.92      0.40       518\n",
      "Obfuscation-Vagueness-Confusion       0.23      1.00      0.37        18\n",
      "           Appeal_to_Popularity       0.31      1.00      0.48        15\n",
      "      Exaggeration-Minimisation       0.37      0.26      0.31       466\n",
      "            Conversation_Killer       0.23      0.95      0.37        91\n",
      "                   Whataboutism       0.27      1.00      0.43        16\n",
      "                        Slogans       0.40      0.88      0.55       153\n",
      "           Guilt_by_Association       0.26      1.00      0.42        59\n",
      "            Appeal_to_Hypocrisy       0.09      1.00      0.17        40\n",
      "                     Repetition       0.22      0.76      0.34       544\n",
      "                    Flag_Waving       0.44      0.87      0.59       287\n",
      "          Name_Calling-Labeling       0.40      0.80      0.53       979\n",
      "      Causal_Oversimplification       0.09      0.99      0.16       213\n",
      "                Loaded_Language       0.72      0.34      0.46      1809\n",
      "                    Red_Herring       0.02      1.00      0.04        44\n",
      "        False_Dilemma-No_Choice       0.16      0.99      0.27       122\n",
      "                      Straw_Man       0.07      1.00      0.13        15\n",
      "       Appeal_to_Fear-Prejudice       0.33      0.73      0.45       310\n",
      "            Appeal_to_Authority       0.14      0.99      0.25       154\n",
      "\n",
      "                      micro avg       0.23      0.65      0.34      5853\n",
      "                      macro avg       0.26      0.87      0.35      5853\n",
      "                   weighted avg       0.43      0.65      0.42      5853\n",
      "                    samples avg       0.25      0.64      0.34      5853\n",
      "\n",
      "Test eval\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/lun2/pjwstk.edu.pl/kbaraniak/semeval/sem/lib64/python3.6/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/mnt/lun2/pjwstk.edu.pl/kbaraniak/semeval/sem/lib64/python3.6/site-packages/ipykernel_launcher.py:62: UserWarning: torch.range is deprecated and will be removed in a future release because its behavior is inconsistent with Python's range builtin. Instead, use torch.arange, which produces values in [start, end).\n",
      "/mnt/lun2/pjwstk.edu.pl/kbaraniak/semeval/sem/lib64/python3.6/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/mnt/lun2/pjwstk.edu.pl/kbaraniak/semeval/sem/lib64/python3.6/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                 precision    recall  f1-score   support\n",
      "\n",
      "                          Doubt       0.30      0.68      0.42       187\n",
      "Obfuscation-Vagueness-Confusion       0.11      0.08      0.09        13\n",
      "           Appeal_to_Popularity       0.00      0.00      0.00        34\n",
      "      Exaggeration-Minimisation       0.15      0.11      0.13       115\n",
      "            Conversation_Killer       0.03      0.40      0.06        25\n",
      "                   Whataboutism       0.00      0.00      0.00         2\n",
      "                        Slogans       0.20      0.39      0.27        28\n",
      "           Guilt_by_Association       0.25      0.75      0.38         4\n",
      "            Appeal_to_Hypocrisy       0.14      0.25      0.18         8\n",
      "                     Repetition       0.16      0.35      0.22       141\n",
      "                    Flag_Waving       0.34      0.79      0.47        96\n",
      "          Name_Calling-Labeling       0.43      0.64      0.51       250\n",
      "      Causal_Oversimplification       0.04      0.58      0.08        24\n",
      "                Loaded_Language       0.66      0.24      0.35       483\n",
      "                    Red_Herring       0.03      0.53      0.05        19\n",
      "        False_Dilemma-No_Choice       0.16      0.68      0.25        63\n",
      "                      Straw_Man       0.00      0.00      0.00         9\n",
      "       Appeal_to_Fear-Prejudice       0.22      0.23      0.22       137\n",
      "            Appeal_to_Authority       0.06      0.36      0.10        28\n",
      "\n",
      "                      micro avg       0.21      0.41      0.27      1666\n",
      "                      macro avg       0.17      0.37      0.20      1666\n",
      "                   weighted avg       0.36      0.41      0.32      1666\n",
      "                    samples avg       0.21      0.40      0.25      1666\n",
      "\n",
      "tensor(2.7454, device='cuda:2')\n",
      "tensor(0.6379, device='cuda:2') tensor(2.7454, device='cuda:2') 0.34261010537692516 0.2744223753546818\n",
      "Training epoch: 10\n",
      "Start\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/lun2/pjwstk.edu.pl/kbaraniak/semeval/sem/lib64/python3.6/site-packages/ipykernel_launcher.py:62: UserWarning: torch.range is deprecated and will be removed in a future release because its behavior is inconsistent with Python's range builtin. Instead, use torch.arange, which produces values in [start, end).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss per 100 training steps: 0.731935441493988\n",
      "Training loss per 100 training steps: 0.6279753428874629\n",
      "Training loss per 100 training steps: 0.6230263652196572\n",
      "Training loss per 100 training steps: 0.6314582178164955\n",
      "Training loss per 100 training steps: 0.6281916589065085\n",
      "Training loss epoch: 0.6277413243943072\n",
      "Training accuracy epoch: 0.0\n",
      "Training eval\n",
      "tensor(0.5399, device='cuda:2')\n",
      "                                 precision    recall  f1-score   support\n",
      "\n",
      "                          Doubt       0.34      0.79      0.47       518\n",
      "Obfuscation-Vagueness-Confusion       0.15      1.00      0.26        18\n",
      "           Appeal_to_Popularity       0.24      1.00      0.38        15\n",
      "      Exaggeration-Minimisation       0.28      0.70      0.40       466\n",
      "            Conversation_Killer       0.21      1.00      0.34        91\n",
      "                   Whataboutism       0.33      1.00      0.49        16\n",
      "                        Slogans       0.28      0.97      0.43       153\n",
      "           Guilt_by_Association       0.34      1.00      0.50        59\n",
      "            Appeal_to_Hypocrisy       0.59      0.93      0.72        40\n",
      "                     Repetition       0.26      0.62      0.37       544\n",
      "                    Flag_Waving       0.39      0.91      0.55       287\n",
      "          Name_Calling-Labeling       0.36      0.88      0.51       979\n",
      "      Causal_Oversimplification       0.12      0.97      0.22       213\n",
      "                Loaded_Language       0.57      0.87      0.69      1809\n",
      "                    Red_Herring       0.51      1.00      0.67        44\n",
      "        False_Dilemma-No_Choice       0.20      0.99      0.33       122\n",
      "                      Straw_Man       0.34      1.00      0.51        15\n",
      "       Appeal_to_Fear-Prejudice       0.31      0.78      0.45       310\n",
      "            Appeal_to_Authority       0.27      0.94      0.41       154\n",
      "\n",
      "                      micro avg       0.34      0.84      0.48      5853\n",
      "                      macro avg       0.32      0.91      0.46      5853\n",
      "                   weighted avg       0.39      0.84      0.52      5853\n",
      "                    samples avg       0.37      0.85      0.49      5853\n",
      "\n",
      "Test eval\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/lun2/pjwstk.edu.pl/kbaraniak/semeval/sem/lib64/python3.6/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/mnt/lun2/pjwstk.edu.pl/kbaraniak/semeval/sem/lib64/python3.6/site-packages/ipykernel_launcher.py:62: UserWarning: torch.range is deprecated and will be removed in a future release because its behavior is inconsistent with Python's range builtin. Instead, use torch.arange, which produces values in [start, end).\n",
      "/mnt/lun2/pjwstk.edu.pl/kbaraniak/semeval/sem/lib64/python3.6/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/mnt/lun2/pjwstk.edu.pl/kbaraniak/semeval/sem/lib64/python3.6/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                 precision    recall  f1-score   support\n",
      "\n",
      "                          Doubt       0.34      0.48      0.40       187\n",
      "Obfuscation-Vagueness-Confusion       0.08      0.08      0.08        13\n",
      "           Appeal_to_Popularity       0.00      0.00      0.00        34\n",
      "      Exaggeration-Minimisation       0.18      0.52      0.27       115\n",
      "            Conversation_Killer       0.05      0.72      0.09        25\n",
      "                   Whataboutism       0.00      0.00      0.00         2\n",
      "                        Slogans       0.14      0.61      0.23        28\n",
      "           Guilt_by_Association       0.38      0.75      0.50         4\n",
      "            Appeal_to_Hypocrisy       0.00      0.00      0.00         8\n",
      "                     Repetition       0.17      0.21      0.19       141\n",
      "                    Flag_Waving       0.27      0.80      0.40        96\n",
      "          Name_Calling-Labeling       0.36      0.78      0.49       250\n",
      "      Causal_Oversimplification       0.06      0.42      0.11        24\n",
      "                Loaded_Language       0.53      0.75      0.62       483\n",
      "                    Red_Herring       0.00      0.00      0.00        19\n",
      "        False_Dilemma-No_Choice       0.19      0.60      0.29        63\n",
      "                      Straw_Man       0.00      0.00      0.00         9\n",
      "       Appeal_to_Fear-Prejudice       0.20      0.21      0.21       137\n",
      "            Appeal_to_Authority       0.02      0.04      0.02        28\n",
      "\n",
      "                      micro avg       0.27      0.56      0.37      1666\n",
      "                      macro avg       0.16      0.37      0.20      1666\n",
      "                   weighted avg       0.32      0.56      0.39      1666\n",
      "                    samples avg       0.29      0.57      0.36      1666\n",
      "\n",
      "tensor(2.9879, device='cuda:2')\n",
      "tensor(0.5399, device='cuda:2') tensor(2.9879, device='cuda:2') 0.48098051662678837 0.36811994476228055\n",
      "Training epoch: 11\n",
      "Start\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/lun2/pjwstk.edu.pl/kbaraniak/semeval/sem/lib64/python3.6/site-packages/ipykernel_launcher.py:62: UserWarning: torch.range is deprecated and will be removed in a future release because its behavior is inconsistent with Python's range builtin. Instead, use torch.arange, which produces values in [start, end).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss per 100 training steps: 0.5954131484031677\n",
      "Training loss per 100 training steps: 0.5729564271941043\n",
      "Training loss per 100 training steps: 0.5604251461539103\n",
      "Training loss per 100 training steps: 0.5824298891316221\n",
      "Training loss per 100 training steps: 0.5964436916044525\n",
      "Training loss epoch: 0.6045565995130133\n",
      "Training accuracy epoch: 0.0\n",
      "Training eval\n",
      "tensor(0.5491, device='cuda:2')\n",
      "                                 precision    recall  f1-score   support\n",
      "\n",
      "                          Doubt       0.32      0.86      0.47       518\n",
      "Obfuscation-Vagueness-Confusion       0.13      1.00      0.24        18\n",
      "           Appeal_to_Popularity       0.15      1.00      0.26        15\n",
      "      Exaggeration-Minimisation       0.19      0.95      0.31       466\n",
      "            Conversation_Killer       0.07      1.00      0.14        91\n",
      "                   Whataboutism       0.09      1.00      0.16        16\n",
      "                        Slogans       0.30      0.99      0.46       153\n",
      "           Guilt_by_Association       0.24      1.00      0.39        59\n",
      "            Appeal_to_Hypocrisy       0.07      1.00      0.13        40\n",
      "                     Repetition       0.28      0.62      0.39       544\n",
      "                    Flag_Waving       0.25      0.99      0.40       287\n",
      "          Name_Calling-Labeling       0.47      0.63      0.54       979\n",
      "      Causal_Oversimplification       0.19      0.92      0.32       213\n",
      "                Loaded_Language       0.60      0.82      0.69      1809\n",
      "                    Red_Herring       0.06      1.00      0.11        44\n",
      "        False_Dilemma-No_Choice       0.24      1.00      0.39       122\n",
      "                      Straw_Man       0.11      1.00      0.20        15\n",
      "       Appeal_to_Fear-Prejudice       0.20      0.97      0.33       310\n",
      "            Appeal_to_Authority       0.16      1.00      0.27       154\n",
      "\n",
      "                      micro avg       0.27      0.82      0.41      5853\n",
      "                      macro avg       0.22      0.93      0.33      5853\n",
      "                   weighted avg       0.39      0.82      0.49      5853\n",
      "                    samples avg       0.30      0.82      0.42      5853\n",
      "\n",
      "Test eval\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/lun2/pjwstk.edu.pl/kbaraniak/semeval/sem/lib64/python3.6/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/mnt/lun2/pjwstk.edu.pl/kbaraniak/semeval/sem/lib64/python3.6/site-packages/ipykernel_launcher.py:62: UserWarning: torch.range is deprecated and will be removed in a future release because its behavior is inconsistent with Python's range builtin. Instead, use torch.arange, which produces values in [start, end).\n",
      "/mnt/lun2/pjwstk.edu.pl/kbaraniak/semeval/sem/lib64/python3.6/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                 precision    recall  f1-score   support\n",
      "\n",
      "                          Doubt       0.30      0.53      0.39       187\n",
      "Obfuscation-Vagueness-Confusion       0.10      0.08      0.09        13\n",
      "           Appeal_to_Popularity       0.00      0.00      0.00        34\n",
      "      Exaggeration-Minimisation       0.14      0.80      0.24       115\n",
      "            Conversation_Killer       0.03      0.88      0.07        25\n",
      "                   Whataboutism       0.00      0.00      0.00         2\n",
      "                        Slogans       0.12      0.39      0.19        28\n",
      "           Guilt_by_Association       0.27      0.75      0.40         4\n",
      "            Appeal_to_Hypocrisy       0.10      0.50      0.17         8\n",
      "                     Repetition       0.13      0.09      0.11       141\n",
      "                    Flag_Waving       0.24      0.90      0.37        96\n",
      "          Name_Calling-Labeling       0.49      0.48      0.49       250\n",
      "      Causal_Oversimplification       0.10      0.25      0.14        24\n",
      "                Loaded_Language       0.55      0.67      0.60       483\n",
      "                    Red_Herring       0.01      0.05      0.02        19\n",
      "        False_Dilemma-No_Choice       0.20      0.62      0.30        63\n",
      "                      Straw_Man       0.00      0.00      0.00         9\n",
      "       Appeal_to_Fear-Prejudice       0.23      0.45      0.30       137\n",
      "            Appeal_to_Authority       0.05      0.25      0.08        28\n",
      "\n",
      "                      micro avg       0.23      0.53      0.32      1666\n",
      "                      macro avg       0.16      0.40      0.21      1666\n",
      "                   weighted avg       0.34      0.53      0.38      1666\n",
      "                    samples avg       0.25      0.53      0.31      1666\n",
      "\n",
      "tensor(2.7498, device='cuda:2')\n",
      "tensor(0.5491, device='cuda:2') tensor(2.7498, device='cuda:2') 0.408699707465977 0.3224519405150526\n",
      "Training epoch: 12\n",
      "Start\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/lun2/pjwstk.edu.pl/kbaraniak/semeval/sem/lib64/python3.6/site-packages/ipykernel_launcher.py:62: UserWarning: torch.range is deprecated and will be removed in a future release because its behavior is inconsistent with Python's range builtin. Instead, use torch.arange, which produces values in [start, end).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss per 100 training steps: 0.4712960124015808\n",
      "Training loss per 100 training steps: 0.5943891683427414\n",
      "Training loss per 100 training steps: 0.5808334779086991\n",
      "Training loss per 100 training steps: 0.566556506081673\n",
      "Training loss per 100 training steps: 0.5759853797957785\n",
      "Training loss epoch: 0.5882298784053072\n",
      "Training accuracy epoch: 0.0\n",
      "Training eval\n",
      "tensor(0.5098, device='cuda:2')\n",
      "                                 precision    recall  f1-score   support\n",
      "\n",
      "                          Doubt       0.36      0.78      0.49       518\n",
      "Obfuscation-Vagueness-Confusion       0.05      1.00      0.10        18\n",
      "           Appeal_to_Popularity       0.06      1.00      0.11        15\n",
      "      Exaggeration-Minimisation       0.22      0.91      0.35       466\n",
      "            Conversation_Killer       0.15      1.00      0.26        91\n",
      "                   Whataboutism       0.05      1.00      0.09        16\n",
      "                        Slogans       0.48      0.98      0.64       153\n",
      "           Guilt_by_Association       0.30      1.00      0.46        59\n",
      "            Appeal_to_Hypocrisy       0.30      1.00      0.46        40\n",
      "                     Repetition       0.32      0.52      0.39       544\n",
      "                    Flag_Waving       0.51      0.89      0.65       287\n",
      "          Name_Calling-Labeling       0.34      0.92      0.50       979\n",
      "      Causal_Oversimplification       0.17      0.95      0.30       213\n",
      "                Loaded_Language       0.59      0.84      0.69      1809\n",
      "                    Red_Herring       0.12      1.00      0.22        44\n",
      "        False_Dilemma-No_Choice       0.29      0.98      0.44       122\n",
      "                      Straw_Man       0.05      1.00      0.09        15\n",
      "       Appeal_to_Fear-Prejudice       0.34      0.85      0.48       310\n",
      "            Appeal_to_Authority       0.15      1.00      0.26       154\n",
      "\n",
      "                      micro avg       0.31      0.85      0.46      5853\n",
      "                      macro avg       0.26      0.93      0.37      5853\n",
      "                   weighted avg       0.40      0.85      0.52      5853\n",
      "                    samples avg       0.36      0.86      0.48      5853\n",
      "\n",
      "Test eval\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/lun2/pjwstk.edu.pl/kbaraniak/semeval/sem/lib64/python3.6/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/mnt/lun2/pjwstk.edu.pl/kbaraniak/semeval/sem/lib64/python3.6/site-packages/ipykernel_launcher.py:62: UserWarning: torch.range is deprecated and will be removed in a future release because its behavior is inconsistent with Python's range builtin. Instead, use torch.arange, which produces values in [start, end).\n",
      "/mnt/lun2/pjwstk.edu.pl/kbaraniak/semeval/sem/lib64/python3.6/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                 precision    recall  f1-score   support\n",
      "\n",
      "                          Doubt       0.32      0.47      0.38       187\n",
      "Obfuscation-Vagueness-Confusion       0.03      0.08      0.04        13\n",
      "           Appeal_to_Popularity       0.00      0.00      0.00        34\n",
      "      Exaggeration-Minimisation       0.15      0.63      0.24       115\n",
      "            Conversation_Killer       0.05      0.64      0.09        25\n",
      "                   Whataboutism       0.00      0.00      0.00         2\n",
      "                        Slogans       0.24      0.32      0.28        28\n",
      "           Guilt_by_Association       0.43      0.75      0.55         4\n",
      "            Appeal_to_Hypocrisy       0.00      0.00      0.00         8\n",
      "                     Repetition       0.18      0.07      0.10       141\n",
      "                    Flag_Waving       0.38      0.65      0.48        96\n",
      "          Name_Calling-Labeling       0.35      0.80      0.48       250\n",
      "      Causal_Oversimplification       0.09      0.33      0.14        24\n",
      "                Loaded_Language       0.54      0.69      0.60       483\n",
      "                    Red_Herring       0.00      0.00      0.00        19\n",
      "        False_Dilemma-No_Choice       0.27      0.38      0.32        63\n",
      "                      Straw_Man       0.00      0.00      0.00         9\n",
      "       Appeal_to_Fear-Prejudice       0.21      0.24      0.23       137\n",
      "            Appeal_to_Authority       0.03      0.14      0.05        28\n",
      "\n",
      "                      micro avg       0.27      0.52      0.36      1666\n",
      "                      macro avg       0.17      0.33      0.21      1666\n",
      "                   weighted avg       0.33      0.52      0.38      1666\n",
      "                    samples avg       0.28      0.52      0.34      1666\n",
      "\n",
      "tensor(2.8581, device='cuda:2')\n",
      "tensor(0.5098, device='cuda:2') tensor(2.8581, device='cuda:2') 0.45661261426799576 0.35767634854771785\n",
      "Training epoch: 13\n",
      "Start\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/lun2/pjwstk.edu.pl/kbaraniak/semeval/sem/lib64/python3.6/site-packages/ipykernel_launcher.py:62: UserWarning: torch.range is deprecated and will be removed in a future release because its behavior is inconsistent with Python's range builtin. Instead, use torch.arange, which produces values in [start, end).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss per 100 training steps: 0.4119436740875244\n",
      "Training loss per 100 training steps: 0.5355332366900869\n",
      "Training loss per 100 training steps: 0.5306439112074932\n",
      "Training loss per 100 training steps: 0.5341330720142669\n",
      "Training loss per 100 training steps: 0.5284340502763925\n",
      "Training loss epoch: 0.5300873765920071\n",
      "Training accuracy epoch: 0.0\n",
      "Training eval\n",
      "tensor(0.4400, device='cuda:2')\n",
      "                                 precision    recall  f1-score   support\n",
      "\n",
      "                          Doubt       0.33      0.92      0.48       518\n",
      "Obfuscation-Vagueness-Confusion       0.16      1.00      0.27        18\n",
      "           Appeal_to_Popularity       0.19      1.00      0.31        15\n",
      "      Exaggeration-Minimisation       0.34      0.72      0.46       466\n",
      "            Conversation_Killer       0.33      1.00      0.49        91\n",
      "                   Whataboutism       0.13      1.00      0.23        16\n",
      "                        Slogans       0.40      0.99      0.56       153\n",
      "           Guilt_by_Association       0.29      1.00      0.45        59\n",
      "            Appeal_to_Hypocrisy       0.17      1.00      0.29        40\n",
      "                     Repetition       0.26      0.82      0.39       544\n",
      "                    Flag_Waving       0.40      0.97      0.56       287\n",
      "          Name_Calling-Labeling       0.43      0.80      0.56       979\n",
      "      Causal_Oversimplification       0.15      0.99      0.26       213\n",
      "                Loaded_Language       0.64      0.75      0.69      1809\n",
      "                    Red_Herring       0.14      1.00      0.25        44\n",
      "        False_Dilemma-No_Choice       0.29      1.00      0.45       122\n",
      "                      Straw_Man       0.09      1.00      0.16        15\n",
      "       Appeal_to_Fear-Prejudice       0.38      0.90      0.53       310\n",
      "            Appeal_to_Authority       0.24      1.00      0.39       154\n",
      "\n",
      "                      micro avg       0.35      0.83      0.50      5853\n",
      "                      macro avg       0.28      0.94      0.41      5853\n",
      "                   weighted avg       0.43      0.83      0.54      5853\n",
      "                    samples avg       0.40      0.83      0.51      5853\n",
      "\n",
      "Test eval\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/lun2/pjwstk.edu.pl/kbaraniak/semeval/sem/lib64/python3.6/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/mnt/lun2/pjwstk.edu.pl/kbaraniak/semeval/sem/lib64/python3.6/site-packages/ipykernel_launcher.py:62: UserWarning: torch.range is deprecated and will be removed in a future release because its behavior is inconsistent with Python's range builtin. Instead, use torch.arange, which produces values in [start, end).\n",
      "/mnt/lun2/pjwstk.edu.pl/kbaraniak/semeval/sem/lib64/python3.6/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                 precision    recall  f1-score   support\n",
      "\n",
      "                          Doubt       0.32      0.49      0.39       187\n",
      "Obfuscation-Vagueness-Confusion       0.07      0.08      0.07        13\n",
      "           Appeal_to_Popularity       0.00      0.00      0.00        34\n",
      "      Exaggeration-Minimisation       0.20      0.31      0.24       115\n",
      "            Conversation_Killer       0.05      0.40      0.08        25\n",
      "                   Whataboutism       0.00      0.00      0.00         2\n",
      "                        Slogans       0.17      0.50      0.26        28\n",
      "           Guilt_by_Association       0.43      0.75      0.55         4\n",
      "            Appeal_to_Hypocrisy       0.12      0.25      0.17         8\n",
      "                     Repetition       0.15      0.35      0.21       141\n",
      "                    Flag_Waving       0.33      0.77      0.46        96\n",
      "          Name_Calling-Labeling       0.46      0.58      0.51       250\n",
      "      Causal_Oversimplification       0.11      0.50      0.18        24\n",
      "                Loaded_Language       0.54      0.52      0.53       483\n",
      "                    Red_Herring       0.00      0.00      0.00        19\n",
      "        False_Dilemma-No_Choice       0.23      0.49      0.32        63\n",
      "                      Straw_Man       0.00      0.00      0.00         9\n",
      "       Appeal_to_Fear-Prejudice       0.25      0.25      0.25       137\n",
      "            Appeal_to_Authority       0.04      0.14      0.06        28\n",
      "\n",
      "                      micro avg       0.28      0.46      0.35      1666\n",
      "                      macro avg       0.18      0.34      0.23      1666\n",
      "                   weighted avg       0.35      0.46      0.38      1666\n",
      "                    samples avg       0.30      0.45      0.33      1666\n",
      "\n",
      "tensor(3.0114, device='cuda:2')\n",
      "tensor(0.4400, device='cuda:2') tensor(3.0114, device='cuda:2') 0.49521009681179995 0.35006909258406266\n",
      "Training epoch: 14\n",
      "Start\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/lun2/pjwstk.edu.pl/kbaraniak/semeval/sem/lib64/python3.6/site-packages/ipykernel_launcher.py:62: UserWarning: torch.range is deprecated and will be removed in a future release because its behavior is inconsistent with Python's range builtin. Instead, use torch.arange, which produces values in [start, end).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss per 100 training steps: 0.34776297211647034\n",
      "Training loss per 100 training steps: 0.4703644578999812\n",
      "Training loss per 100 training steps: 0.48209940408592794\n",
      "Training loss per 100 training steps: 0.4892367086933301\n",
      "Training loss per 100 training steps: 0.493596450794962\n",
      "Training loss epoch: 0.4974290684816685\n",
      "Training accuracy epoch: 0.0\n",
      "Training eval\n",
      "tensor(0.4450, device='cuda:2')\n",
      "                                 precision    recall  f1-score   support\n",
      "\n",
      "                          Doubt       0.46      0.82      0.59       518\n",
      "Obfuscation-Vagueness-Confusion       0.31      1.00      0.47        18\n",
      "           Appeal_to_Popularity       0.09      1.00      0.16        15\n",
      "      Exaggeration-Minimisation       0.30      0.85      0.44       466\n",
      "            Conversation_Killer       0.37      1.00      0.54        91\n",
      "                   Whataboutism       0.34      1.00      0.51        16\n",
      "                        Slogans       0.37      1.00      0.54       153\n",
      "           Guilt_by_Association       0.35      1.00      0.52        59\n",
      "            Appeal_to_Hypocrisy       0.64      0.93      0.76        40\n",
      "                     Repetition       0.34      0.66      0.45       544\n",
      "                    Flag_Waving       0.32      0.98      0.49       287\n",
      "          Name_Calling-Labeling       0.48      0.67      0.56       979\n",
      "      Causal_Oversimplification       0.18      1.00      0.31       213\n",
      "                Loaded_Language       0.62      0.80      0.70      1809\n",
      "                    Red_Herring       0.61      1.00      0.76        44\n",
      "        False_Dilemma-No_Choice       0.21      1.00      0.35       122\n",
      "                      Straw_Man       0.37      1.00      0.54        15\n",
      "       Appeal_to_Fear-Prejudice       0.29      0.98      0.44       310\n",
      "            Appeal_to_Authority       0.30      1.00      0.46       154\n",
      "\n",
      "                      micro avg       0.38      0.82      0.52      5853\n",
      "                      macro avg       0.37      0.93      0.50      5853\n",
      "                   weighted avg       0.45      0.82      0.56      5853\n",
      "                    samples avg       0.43      0.82      0.53      5853\n",
      "\n",
      "Test eval\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/lun2/pjwstk.edu.pl/kbaraniak/semeval/sem/lib64/python3.6/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/mnt/lun2/pjwstk.edu.pl/kbaraniak/semeval/sem/lib64/python3.6/site-packages/ipykernel_launcher.py:62: UserWarning: torch.range is deprecated and will be removed in a future release because its behavior is inconsistent with Python's range builtin. Instead, use torch.arange, which produces values in [start, end).\n",
      "/mnt/lun2/pjwstk.edu.pl/kbaraniak/semeval/sem/lib64/python3.6/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/mnt/lun2/pjwstk.edu.pl/kbaraniak/semeval/sem/lib64/python3.6/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                 precision    recall  f1-score   support\n",
      "\n",
      "                          Doubt       0.31      0.41      0.36       187\n",
      "Obfuscation-Vagueness-Confusion       0.00      0.00      0.00        13\n",
      "           Appeal_to_Popularity       0.00      0.00      0.00        34\n",
      "      Exaggeration-Minimisation       0.17      0.49      0.26       115\n",
      "            Conversation_Killer       0.05      0.40      0.08        25\n",
      "                   Whataboutism       0.00      0.00      0.00         2\n",
      "                        Slogans       0.21      0.43      0.29        28\n",
      "           Guilt_by_Association       0.30      0.75      0.43         4\n",
      "            Appeal_to_Hypocrisy       0.00      0.00      0.00         8\n",
      "                     Repetition       0.15      0.12      0.13       141\n",
      "                    Flag_Waving       0.25      0.84      0.39        96\n",
      "          Name_Calling-Labeling       0.51      0.42      0.46       250\n",
      "      Causal_Oversimplification       0.05      0.42      0.09        24\n",
      "                Loaded_Language       0.54      0.57      0.56       483\n",
      "                    Red_Herring       0.00      0.00      0.00        19\n",
      "        False_Dilemma-No_Choice       0.19      0.52      0.28        63\n",
      "                      Straw_Man       0.00      0.00      0.00         9\n",
      "       Appeal_to_Fear-Prejudice       0.23      0.38      0.28       137\n",
      "            Appeal_to_Authority       0.02      0.07      0.04        28\n",
      "\n",
      "                      micro avg       0.27      0.44      0.34      1666\n",
      "                      macro avg       0.16      0.31      0.19      1666\n",
      "                   weighted avg       0.34      0.44      0.36      1666\n",
      "                    samples avg       0.28      0.44      0.31      1666\n",
      "\n",
      "tensor(3.0336, device='cuda:2')\n",
      "tensor(0.4450, device='cuda:2') tensor(3.0336, device='cuda:2') 0.5238874345549738 0.3363970588235294\n",
      "Training epoch: 15\n",
      "Start\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/lun2/pjwstk.edu.pl/kbaraniak/semeval/sem/lib64/python3.6/site-packages/ipykernel_launcher.py:62: UserWarning: torch.range is deprecated and will be removed in a future release because its behavior is inconsistent with Python's range builtin. Instead, use torch.arange, which produces values in [start, end).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss per 100 training steps: 0.3641529083251953\n",
      "Training loss per 100 training steps: 0.4652148361253266\n",
      "Training loss per 100 training steps: 0.4666732656421946\n",
      "Training loss per 100 training steps: 0.46098403944525607\n",
      "Training loss per 100 training steps: 0.46555866334503726\n",
      "Training loss epoch: 0.4724139961790531\n",
      "Training accuracy epoch: 0.0\n",
      "Training eval\n",
      "tensor(0.4308, device='cuda:2')\n",
      "                                 precision    recall  f1-score   support\n",
      "\n",
      "                          Doubt       0.64      0.69      0.66       518\n",
      "Obfuscation-Vagueness-Confusion       0.12      1.00      0.21        18\n",
      "           Appeal_to_Popularity       0.08      1.00      0.15        15\n",
      "      Exaggeration-Minimisation       0.38      0.86      0.53       466\n",
      "            Conversation_Killer       0.53      0.99      0.69        91\n",
      "                   Whataboutism       0.10      1.00      0.18        16\n",
      "                        Slogans       0.21      1.00      0.35       153\n",
      "           Guilt_by_Association       0.25      1.00      0.40        59\n",
      "            Appeal_to_Hypocrisy       0.09      1.00      0.16        40\n",
      "                     Repetition       0.27      0.87      0.41       544\n",
      "                    Flag_Waving       0.36      0.99      0.52       287\n",
      "          Name_Calling-Labeling       0.50      0.68      0.57       979\n",
      "      Causal_Oversimplification       0.31      1.00      0.48       213\n",
      "                Loaded_Language       0.65      0.66      0.66      1809\n",
      "                    Red_Herring       0.23      1.00      0.38        44\n",
      "        False_Dilemma-No_Choice       0.18      1.00      0.31       122\n",
      "                      Straw_Man       0.08      1.00      0.15        15\n",
      "       Appeal_to_Fear-Prejudice       0.19      1.00      0.32       310\n",
      "            Appeal_to_Authority       0.16      1.00      0.27       154\n",
      "\n",
      "                      micro avg       0.34      0.79      0.47      5853\n",
      "                      macro avg       0.28      0.93      0.39      5853\n",
      "                   weighted avg       0.46      0.79      0.54      5853\n",
      "                    samples avg       0.39      0.80      0.49      5853\n",
      "\n",
      "Test eval\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/lun2/pjwstk.edu.pl/kbaraniak/semeval/sem/lib64/python3.6/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/mnt/lun2/pjwstk.edu.pl/kbaraniak/semeval/sem/lib64/python3.6/site-packages/ipykernel_launcher.py:62: UserWarning: torch.range is deprecated and will be removed in a future release because its behavior is inconsistent with Python's range builtin. Instead, use torch.arange, which produces values in [start, end).\n",
      "/mnt/lun2/pjwstk.edu.pl/kbaraniak/semeval/sem/lib64/python3.6/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                 precision    recall  f1-score   support\n",
      "\n",
      "                          Doubt       0.35      0.24      0.28       187\n",
      "Obfuscation-Vagueness-Confusion       0.07      0.08      0.07        13\n",
      "           Appeal_to_Popularity       0.00      0.00      0.00        34\n",
      "      Exaggeration-Minimisation       0.19      0.44      0.26       115\n",
      "            Conversation_Killer       0.03      0.12      0.05        25\n",
      "                   Whataboutism       0.00      0.00      0.00         2\n",
      "                        Slogans       0.12      0.64      0.20        28\n",
      "           Guilt_by_Association       0.30      0.75      0.43         4\n",
      "            Appeal_to_Hypocrisy       0.09      0.38      0.14         8\n",
      "                     Repetition       0.15      0.25      0.19       141\n",
      "                    Flag_Waving       0.33      0.77      0.47        96\n",
      "          Name_Calling-Labeling       0.44      0.56      0.49       250\n",
      "      Causal_Oversimplification       0.13      0.33      0.19        24\n",
      "                Loaded_Language       0.56      0.53      0.54       483\n",
      "                    Red_Herring       0.00      0.00      0.00        19\n",
      "        False_Dilemma-No_Choice       0.20      0.48      0.28        63\n",
      "                      Straw_Man       0.00      0.00      0.00         9\n",
      "       Appeal_to_Fear-Prejudice       0.20      0.52      0.29       137\n",
      "            Appeal_to_Authority       0.02      0.11      0.03        28\n",
      "\n",
      "                      micro avg       0.28      0.44      0.34      1666\n",
      "                      macro avg       0.17      0.33      0.21      1666\n",
      "                   weighted avg       0.34      0.44      0.37      1666\n",
      "                    samples avg       0.28      0.44      0.31      1666\n",
      "\n",
      "tensor(2.9758, device='cuda:2')\n",
      "tensor(0.4308, device='cuda:2') tensor(2.9758, device='cuda:2') 0.47155551016239405 0.3399355135882082\n",
      "Training epoch: 16\n",
      "Start\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/lun2/pjwstk.edu.pl/kbaraniak/semeval/sem/lib64/python3.6/site-packages/ipykernel_launcher.py:62: UserWarning: torch.range is deprecated and will be removed in a future release because its behavior is inconsistent with Python's range builtin. Instead, use torch.arange, which produces values in [start, end).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss per 100 training steps: 0.47289809584617615\n",
      "Training loss per 100 training steps: 0.43126645802271246\n",
      "Training loss per 100 training steps: 0.42741616085097567\n",
      "Training loss per 100 training steps: 0.4324975550372735\n",
      "Training loss per 100 training steps: 0.4434493164023259\n",
      "Training loss epoch: 0.44356781944949575\n",
      "Training accuracy epoch: 0.0\n",
      "Training eval\n",
      "tensor(0.3932, device='cuda:2')\n",
      "                                 precision    recall  f1-score   support\n",
      "\n",
      "                          Doubt       0.72      0.68      0.70       518\n",
      "Obfuscation-Vagueness-Confusion       0.21      1.00      0.35        18\n",
      "           Appeal_to_Popularity       0.09      1.00      0.17        15\n",
      "      Exaggeration-Minimisation       0.23      0.98      0.37       466\n",
      "            Conversation_Killer       0.59      1.00      0.74        91\n",
      "                   Whataboutism       0.13      1.00      0.23        16\n",
      "                        Slogans       0.18      1.00      0.31       153\n",
      "           Guilt_by_Association       0.19      1.00      0.32        59\n",
      "            Appeal_to_Hypocrisy       0.11      1.00      0.21        40\n",
      "                     Repetition       0.27      0.91      0.41       544\n",
      "                    Flag_Waving       0.31      1.00      0.48       287\n",
      "          Name_Calling-Labeling       0.45      0.83      0.59       979\n",
      "      Causal_Oversimplification       0.56      1.00      0.72       213\n",
      "                Loaded_Language       0.63      0.81      0.71      1809\n",
      "                    Red_Herring       0.22      1.00      0.36        44\n",
      "        False_Dilemma-No_Choice       0.38      1.00      0.55       122\n",
      "                      Straw_Man       0.11      1.00      0.20        15\n",
      "       Appeal_to_Fear-Prejudice       0.23      1.00      0.37       310\n",
      "            Appeal_to_Authority       0.54      1.00      0.70       154\n",
      "\n",
      "                      micro avg       0.36      0.88      0.51      5853\n",
      "                      macro avg       0.32      0.96      0.45      5853\n",
      "                   weighted avg       0.47      0.88      0.57      5853\n",
      "                    samples avg       0.41      0.89      0.53      5853\n",
      "\n",
      "Test eval\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/lun2/pjwstk.edu.pl/kbaraniak/semeval/sem/lib64/python3.6/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/mnt/lun2/pjwstk.edu.pl/kbaraniak/semeval/sem/lib64/python3.6/site-packages/ipykernel_launcher.py:62: UserWarning: torch.range is deprecated and will be removed in a future release because its behavior is inconsistent with Python's range builtin. Instead, use torch.arange, which produces values in [start, end).\n",
      "/mnt/lun2/pjwstk.edu.pl/kbaraniak/semeval/sem/lib64/python3.6/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                 precision    recall  f1-score   support\n",
      "\n",
      "                          Doubt       0.36      0.20      0.26       187\n",
      "Obfuscation-Vagueness-Confusion       0.00      0.00      0.00        13\n",
      "           Appeal_to_Popularity       0.00      0.00      0.00        34\n",
      "      Exaggeration-Minimisation       0.15      0.67      0.24       115\n",
      "            Conversation_Killer       0.03      0.08      0.04        25\n",
      "                   Whataboutism       0.00      0.00      0.00         2\n",
      "                        Slogans       0.10      0.54      0.17        28\n",
      "           Guilt_by_Association       0.27      0.75      0.40         4\n",
      "            Appeal_to_Hypocrisy       0.05      0.12      0.07         8\n",
      "                     Repetition       0.16      0.37      0.22       141\n",
      "                    Flag_Waving       0.31      0.83      0.46        96\n",
      "          Name_Calling-Labeling       0.39      0.65      0.49       250\n",
      "      Causal_Oversimplification       0.17      0.21      0.19        24\n",
      "                Loaded_Language       0.52      0.67      0.58       483\n",
      "                    Red_Herring       0.00      0.00      0.00        19\n",
      "        False_Dilemma-No_Choice       0.19      0.29      0.23        63\n",
      "                      Straw_Man       0.00      0.00      0.00         9\n",
      "       Appeal_to_Fear-Prejudice       0.23      0.49      0.31       137\n",
      "            Appeal_to_Authority       0.04      0.04      0.04        28\n",
      "\n",
      "                      micro avg       0.28      0.51      0.36      1666\n",
      "                      macro avg       0.16      0.31      0.19      1666\n",
      "                   weighted avg       0.32      0.51      0.38      1666\n",
      "                    samples avg       0.28      0.50      0.34      1666\n",
      "\n",
      "tensor(3.1734, device='cuda:2')\n",
      "tensor(0.3932, device='cuda:2') tensor(3.1734, device='cuda:2') 0.5136124341940337 0.36391107273904594\n",
      "Training epoch: 17\n",
      "Start\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/lun2/pjwstk.edu.pl/kbaraniak/semeval/sem/lib64/python3.6/site-packages/ipykernel_launcher.py:62: UserWarning: torch.range is deprecated and will be removed in a future release because its behavior is inconsistent with Python's range builtin. Instead, use torch.arange, which produces values in [start, end).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss per 100 training steps: 0.6274340748786926\n",
      "Training loss per 100 training steps: 0.4236298634274171\n",
      "Training loss per 100 training steps: 0.41582480376929193\n",
      "Training loss per 100 training steps: 0.41437868853146054\n",
      "Training loss per 100 training steps: 0.4131655139370155\n",
      "Training loss epoch: 0.41760431065204295\n",
      "Training accuracy epoch: 0.0\n",
      "Training eval\n",
      "tensor(0.3446, device='cuda:2')\n",
      "                                 precision    recall  f1-score   support\n",
      "\n",
      "                          Doubt       0.58      0.93      0.72       518\n",
      "Obfuscation-Vagueness-Confusion       0.12      1.00      0.22        18\n",
      "           Appeal_to_Popularity       0.10      1.00      0.18        15\n",
      "      Exaggeration-Minimisation       0.49      0.89      0.64       466\n",
      "            Conversation_Killer       0.30      1.00      0.46        91\n",
      "                   Whataboutism       0.10      1.00      0.18        16\n",
      "                        Slogans       0.38      1.00      0.55       153\n",
      "           Guilt_by_Association       0.26      1.00      0.42        59\n",
      "            Appeal_to_Hypocrisy       0.20      1.00      0.34        40\n",
      "                     Repetition       0.47      0.71      0.57       544\n",
      "                    Flag_Waving       0.49      0.99      0.66       287\n",
      "          Name_Calling-Labeling       0.49      0.79      0.61       979\n",
      "      Causal_Oversimplification       0.35      1.00      0.52       213\n",
      "                Loaded_Language       0.66      0.63      0.65      1809\n",
      "                    Red_Herring       0.22      1.00      0.36        44\n",
      "        False_Dilemma-No_Choice       0.17      1.00      0.29       122\n",
      "                      Straw_Man       0.09      1.00      0.16        15\n",
      "       Appeal_to_Fear-Prejudice       0.51      0.99      0.67       310\n",
      "            Appeal_to_Authority       0.58      1.00      0.73       154\n",
      "\n",
      "                      micro avg       0.45      0.81      0.58      5853\n",
      "                      macro avg       0.35      0.94      0.47      5853\n",
      "                   weighted avg       0.53      0.81      0.61      5853\n",
      "                    samples avg       0.51      0.81      0.59      5853\n",
      "\n",
      "Test eval\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/lun2/pjwstk.edu.pl/kbaraniak/semeval/sem/lib64/python3.6/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/mnt/lun2/pjwstk.edu.pl/kbaraniak/semeval/sem/lib64/python3.6/site-packages/ipykernel_launcher.py:62: UserWarning: torch.range is deprecated and will be removed in a future release because its behavior is inconsistent with Python's range builtin. Instead, use torch.arange, which produces values in [start, end).\n",
      "/mnt/lun2/pjwstk.edu.pl/kbaraniak/semeval/sem/lib64/python3.6/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                 precision    recall  f1-score   support\n",
      "\n",
      "                          Doubt       0.29      0.27      0.28       187\n",
      "Obfuscation-Vagueness-Confusion       0.06      0.08      0.07        13\n",
      "           Appeal_to_Popularity       0.00      0.00      0.00        34\n",
      "      Exaggeration-Minimisation       0.18      0.30      0.23       115\n",
      "            Conversation_Killer       0.04      0.44      0.07        25\n",
      "                   Whataboutism       0.00      0.00      0.00         2\n",
      "                        Slogans       0.19      0.39      0.26        28\n",
      "           Guilt_by_Association       0.30      0.75      0.43         4\n",
      "            Appeal_to_Hypocrisy       0.09      0.12      0.11         8\n",
      "                     Repetition       0.19      0.07      0.10       141\n",
      "                    Flag_Waving       0.36      0.72      0.48        96\n",
      "          Name_Calling-Labeling       0.44      0.49      0.47       250\n",
      "      Causal_Oversimplification       0.08      0.21      0.12        24\n",
      "                Loaded_Language       0.56      0.41      0.47       483\n",
      "                    Red_Herring       0.00      0.00      0.00        19\n",
      "        False_Dilemma-No_Choice       0.17      0.52      0.26        63\n",
      "                      Straw_Man       0.07      0.11      0.09         9\n",
      "       Appeal_to_Fear-Prejudice       0.29      0.18      0.22       137\n",
      "            Appeal_to_Authority       0.07      0.07      0.07        28\n",
      "\n",
      "                      micro avg       0.29      0.35      0.31      1666\n",
      "                      macro avg       0.18      0.27      0.20      1666\n",
      "                   weighted avg       0.35      0.35      0.33      1666\n",
      "                    samples avg       0.25      0.34      0.26      1666\n",
      "\n",
      "tensor(3.2054, device='cuda:2')\n",
      "tensor(0.3446, device='cuda:2') tensor(3.2054, device='cuda:2') 0.5782587429689411 0.3129251700680272\n",
      "Training epoch: 18\n",
      "Start\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/lun2/pjwstk.edu.pl/kbaraniak/semeval/sem/lib64/python3.6/site-packages/ipykernel_launcher.py:62: UserWarning: torch.range is deprecated and will be removed in a future release because its behavior is inconsistent with Python's range builtin. Instead, use torch.arange, which produces values in [start, end).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss per 100 training steps: 0.5391333103179932\n",
      "Training loss per 100 training steps: 0.3868803802398172\n",
      "Training loss per 100 training steps: 0.3889057253723714\n",
      "Training loss per 100 training steps: 0.38600445768959896\n",
      "Training loss per 100 training steps: 0.3858913243039885\n",
      "Training loss epoch: 0.3878484165731897\n",
      "Training accuracy epoch: 0.0\n",
      "Training eval\n",
      "tensor(0.3151, device='cuda:2')\n",
      "                                 precision    recall  f1-score   support\n",
      "\n",
      "                          Doubt       0.37      0.99      0.53       518\n",
      "Obfuscation-Vagueness-Confusion       0.19      1.00      0.32        18\n",
      "           Appeal_to_Popularity       0.19      1.00      0.32        15\n",
      "      Exaggeration-Minimisation       0.36      0.98      0.53       466\n",
      "            Conversation_Killer       0.55      1.00      0.71        91\n",
      "                   Whataboutism       0.13      1.00      0.23        16\n",
      "                        Slogans       0.74      1.00      0.85       153\n",
      "           Guilt_by_Association       0.25      1.00      0.40        59\n",
      "            Appeal_to_Hypocrisy       0.28      1.00      0.44        40\n",
      "                     Repetition       0.44      0.85      0.58       544\n",
      "                    Flag_Waving       0.54      1.00      0.70       287\n",
      "          Name_Calling-Labeling       0.51      0.81      0.62       979\n",
      "      Causal_Oversimplification       0.29      1.00      0.45       213\n",
      "                Loaded_Language       0.65      0.76      0.70      1809\n",
      "                    Red_Herring       0.18      1.00      0.31        44\n",
      "        False_Dilemma-No_Choice       0.51      1.00      0.67       122\n",
      "                      Straw_Man       0.16      1.00      0.27        15\n",
      "       Appeal_to_Fear-Prejudice       0.58      0.98      0.73       310\n",
      "            Appeal_to_Authority       0.66      1.00      0.79       154\n",
      "\n",
      "                      micro avg       0.47      0.88      0.61      5853\n",
      "                      macro avg       0.40      0.97      0.54      5853\n",
      "                   weighted avg       0.52      0.88      0.63      5853\n",
      "                    samples avg       0.53      0.89      0.63      5853\n",
      "\n",
      "Test eval\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/lun2/pjwstk.edu.pl/kbaraniak/semeval/sem/lib64/python3.6/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/mnt/lun2/pjwstk.edu.pl/kbaraniak/semeval/sem/lib64/python3.6/site-packages/ipykernel_launcher.py:62: UserWarning: torch.range is deprecated and will be removed in a future release because its behavior is inconsistent with Python's range builtin. Instead, use torch.arange, which produces values in [start, end).\n",
      "/mnt/lun2/pjwstk.edu.pl/kbaraniak/semeval/sem/lib64/python3.6/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/mnt/lun2/pjwstk.edu.pl/kbaraniak/semeval/sem/lib64/python3.6/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                 precision    recall  f1-score   support\n",
      "\n",
      "                          Doubt       0.24      0.57      0.34       187\n",
      "Obfuscation-Vagueness-Confusion       0.33      0.08      0.12        13\n",
      "           Appeal_to_Popularity       0.00      0.00      0.00        34\n",
      "      Exaggeration-Minimisation       0.17      0.45      0.25       115\n",
      "            Conversation_Killer       0.02      0.04      0.02        25\n",
      "                   Whataboutism       0.00      0.00      0.00         2\n",
      "                        Slogans       0.32      0.21      0.26        28\n",
      "           Guilt_by_Association       0.38      0.75      0.50         4\n",
      "            Appeal_to_Hypocrisy       0.00      0.00      0.00         8\n",
      "                     Repetition       0.16      0.13      0.14       141\n",
      "                    Flag_Waving       0.38      0.60      0.47        96\n",
      "          Name_Calling-Labeling       0.47      0.50      0.48       250\n",
      "      Causal_Oversimplification       0.08      0.21      0.11        24\n",
      "                Loaded_Language       0.53      0.58      0.56       483\n",
      "                    Red_Herring       0.00      0.00      0.00        19\n",
      "        False_Dilemma-No_Choice       0.31      0.14      0.20        63\n",
      "                      Straw_Man       0.00      0.00      0.00         9\n",
      "       Appeal_to_Fear-Prejudice       0.26      0.20      0.22       137\n",
      "            Appeal_to_Authority       0.20      0.07      0.11        28\n",
      "\n",
      "                      micro avg       0.33      0.42      0.37      1666\n",
      "                      macro avg       0.20      0.24      0.20      1666\n",
      "                   weighted avg       0.35      0.42      0.36      1666\n",
      "                    samples avg       0.31      0.42      0.32      1666\n",
      "\n",
      "tensor(3.6367, device='cuda:2')\n",
      "tensor(0.3151, device='cuda:2') tensor(3.6367, device='cuda:2') 0.6077583654130886 0.3656932386214154\n",
      "Training epoch: 19\n",
      "Start\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/lun2/pjwstk.edu.pl/kbaraniak/semeval/sem/lib64/python3.6/site-packages/ipykernel_launcher.py:62: UserWarning: torch.range is deprecated and will be removed in a future release because its behavior is inconsistent with Python's range builtin. Instead, use torch.arange, which produces values in [start, end).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss per 100 training steps: 0.33514276146888733\n",
      "Training loss per 100 training steps: 0.35075370760837404\n",
      "Training loss per 100 training steps: 0.3580649025108091\n",
      "Training loss per 100 training steps: 0.36445485055446625\n",
      "Training loss per 100 training steps: 0.37134043151452356\n",
      "Training loss epoch: 0.3703593054984478\n",
      "Training accuracy epoch: 0.0\n",
      "Training eval\n",
      "tensor(0.2859, device='cuda:2')\n",
      "                                 precision    recall  f1-score   support\n",
      "\n",
      "                          Doubt       0.53      0.99      0.69       518\n",
      "Obfuscation-Vagueness-Confusion       0.28      1.00      0.44        18\n",
      "           Appeal_to_Popularity       0.22      1.00      0.36        15\n",
      "      Exaggeration-Minimisation       0.62      0.95      0.75       466\n",
      "            Conversation_Killer       0.54      1.00      0.70        91\n",
      "                   Whataboutism       0.15      1.00      0.26        16\n",
      "                        Slogans       0.41      1.00      0.58       153\n",
      "           Guilt_by_Association       0.43      1.00      0.60        59\n",
      "            Appeal_to_Hypocrisy       0.26      1.00      0.42        40\n",
      "                     Repetition       0.49      0.87      0.63       544\n",
      "                    Flag_Waving       0.47      1.00      0.64       287\n",
      "          Name_Calling-Labeling       0.55      0.80      0.65       979\n",
      "      Causal_Oversimplification       0.71      1.00      0.83       213\n",
      "                Loaded_Language       0.66      0.65      0.66      1809\n",
      "                    Red_Herring       0.47      1.00      0.64        44\n",
      "        False_Dilemma-No_Choice       0.40      1.00      0.58       122\n",
      "                      Straw_Man       0.12      1.00      0.21        15\n",
      "       Appeal_to_Fear-Prejudice       0.51      1.00      0.67       310\n",
      "            Appeal_to_Authority       0.76      1.00      0.86       154\n",
      "\n",
      "                      micro avg       0.54      0.84      0.66      5853\n",
      "                      macro avg       0.45      0.96      0.59      5853\n",
      "                   weighted avg       0.57      0.84      0.67      5853\n",
      "                    samples avg       0.60      0.85      0.67      5853\n",
      "\n",
      "Test eval\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/lun2/pjwstk.edu.pl/kbaraniak/semeval/sem/lib64/python3.6/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/mnt/lun2/pjwstk.edu.pl/kbaraniak/semeval/sem/lib64/python3.6/site-packages/ipykernel_launcher.py:62: UserWarning: torch.range is deprecated and will be removed in a future release because its behavior is inconsistent with Python's range builtin. Instead, use torch.arange, which produces values in [start, end).\n",
      "/mnt/lun2/pjwstk.edu.pl/kbaraniak/semeval/sem/lib64/python3.6/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/mnt/lun2/pjwstk.edu.pl/kbaraniak/semeval/sem/lib64/python3.6/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                 precision    recall  f1-score   support\n",
      "\n",
      "                          Doubt       0.24      0.35      0.29       187\n",
      "Obfuscation-Vagueness-Confusion       0.00      0.00      0.00        13\n",
      "           Appeal_to_Popularity       0.00      0.00      0.00        34\n",
      "      Exaggeration-Minimisation       0.18      0.29      0.22       115\n",
      "            Conversation_Killer       0.02      0.04      0.02        25\n",
      "                   Whataboutism       0.00      0.00      0.00         2\n",
      "                        Slogans       0.20      0.36      0.26        28\n",
      "           Guilt_by_Association       0.20      0.25      0.22         4\n",
      "            Appeal_to_Hypocrisy       0.00      0.00      0.00         8\n",
      "                     Repetition       0.14      0.06      0.09       141\n",
      "                    Flag_Waving       0.36      0.64      0.46        96\n",
      "          Name_Calling-Labeling       0.43      0.48      0.45       250\n",
      "      Causal_Oversimplification       0.11      0.08      0.09        24\n",
      "                Loaded_Language       0.52      0.47      0.50       483\n",
      "                    Red_Herring       0.00      0.00      0.00        19\n",
      "        False_Dilemma-No_Choice       0.27      0.14      0.19        63\n",
      "                      Straw_Man       0.00      0.00      0.00         9\n",
      "       Appeal_to_Fear-Prejudice       0.29      0.20      0.24       137\n",
      "            Appeal_to_Authority       0.33      0.04      0.06        28\n",
      "\n",
      "                      micro avg       0.34      0.34      0.34      1666\n",
      "                      macro avg       0.17      0.18      0.16      1666\n",
      "                   weighted avg       0.33      0.34      0.33      1666\n",
      "                    samples avg       0.28      0.35      0.28      1666\n",
      "\n",
      "tensor(3.9029, device='cuda:2')\n",
      "tensor(0.2859, device='cuda:2') tensor(3.9029, device='cuda:2') 0.6557507987220448 0.3396339633963396\n",
      "Training epoch: 20\n",
      "Start\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/lun2/pjwstk.edu.pl/kbaraniak/semeval/sem/lib64/python3.6/site-packages/ipykernel_launcher.py:62: UserWarning: torch.range is deprecated and will be removed in a future release because its behavior is inconsistent with Python's range builtin. Instead, use torch.arange, which produces values in [start, end).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss per 100 training steps: 0.221308633685112\n",
      "Training loss per 100 training steps: 0.3703864976616189\n",
      "Training loss per 100 training steps: 0.3616649164489253\n",
      "Training loss per 100 training steps: 0.35522418813253953\n",
      "Training loss per 100 training steps: 0.3504918523857421\n",
      "Training loss epoch: 0.35310604286954755\n",
      "Training accuracy epoch: 0.0\n",
      "Training eval\n",
      "tensor(0.2997, device='cuda:2')\n",
      "                                 precision    recall  f1-score   support\n",
      "\n",
      "                          Doubt       0.54      0.99      0.70       518\n",
      "Obfuscation-Vagueness-Confusion       0.11      1.00      0.20        18\n",
      "           Appeal_to_Popularity       0.04      1.00      0.08        15\n",
      "      Exaggeration-Minimisation       0.55      0.98      0.71       466\n",
      "            Conversation_Killer       0.58      1.00      0.74        91\n",
      "                   Whataboutism       0.09      1.00      0.17        16\n",
      "                        Slogans       0.76      1.00      0.86       153\n",
      "           Guilt_by_Association       0.30      1.00      0.46        59\n",
      "            Appeal_to_Hypocrisy       0.35      1.00      0.52        40\n",
      "                     Repetition       0.35      0.97      0.51       544\n",
      "                    Flag_Waving       0.84      0.97      0.90       287\n",
      "          Name_Calling-Labeling       0.53      0.85      0.65       979\n",
      "      Causal_Oversimplification       0.28      1.00      0.44       213\n",
      "                Loaded_Language       0.63      0.83      0.72      1809\n",
      "                    Red_Herring       0.48      1.00      0.65        44\n",
      "        False_Dilemma-No_Choice       0.55      1.00      0.71       122\n",
      "                      Straw_Man       0.14      1.00      0.24        15\n",
      "       Appeal_to_Fear-Prejudice       0.39      1.00      0.56       310\n",
      "            Appeal_to_Authority       0.51      1.00      0.67       154\n",
      "\n",
      "                      micro avg       0.48      0.92      0.63      5853\n",
      "                      macro avg       0.42      0.98      0.55      5853\n",
      "                   weighted avg       0.54      0.92      0.67      5853\n",
      "                    samples avg       0.56      0.92      0.66      5853\n",
      "\n",
      "Test eval\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/lun2/pjwstk.edu.pl/kbaraniak/semeval/sem/lib64/python3.6/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/mnt/lun2/pjwstk.edu.pl/kbaraniak/semeval/sem/lib64/python3.6/site-packages/ipykernel_launcher.py:62: UserWarning: torch.range is deprecated and will be removed in a future release because its behavior is inconsistent with Python's range builtin. Instead, use torch.arange, which produces values in [start, end).\n",
      "/mnt/lun2/pjwstk.edu.pl/kbaraniak/semeval/sem/lib64/python3.6/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/mnt/lun2/pjwstk.edu.pl/kbaraniak/semeval/sem/lib64/python3.6/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                 precision    recall  f1-score   support\n",
      "\n",
      "                          Doubt       0.25      0.33      0.28       187\n",
      "Obfuscation-Vagueness-Confusion       0.17      0.08      0.11        13\n",
      "           Appeal_to_Popularity       0.00      0.00      0.00        34\n",
      "      Exaggeration-Minimisation       0.17      0.24      0.20       115\n",
      "            Conversation_Killer       0.07      0.16      0.09        25\n",
      "                   Whataboutism       0.00      0.00      0.00         2\n",
      "                        Slogans       0.24      0.14      0.18        28\n",
      "           Guilt_by_Association       0.33      0.50      0.40         4\n",
      "            Appeal_to_Hypocrisy       0.00      0.00      0.00         8\n",
      "                     Repetition       0.14      0.25      0.18       141\n",
      "                    Flag_Waving       0.45      0.41      0.43        96\n",
      "          Name_Calling-Labeling       0.46      0.45      0.45       250\n",
      "      Causal_Oversimplification       0.07      0.25      0.11        24\n",
      "                Loaded_Language       0.53      0.63      0.57       483\n",
      "                    Red_Herring       0.00      0.00      0.00        19\n",
      "        False_Dilemma-No_Choice       0.26      0.11      0.16        63\n",
      "                      Straw_Man       0.00      0.00      0.00         9\n",
      "       Appeal_to_Fear-Prejudice       0.22      0.28      0.24       137\n",
      "            Appeal_to_Authority       0.07      0.07      0.07        28\n",
      "\n",
      "                      micro avg       0.32      0.39      0.35      1666\n",
      "                      macro avg       0.18      0.21      0.18      1666\n",
      "                   weighted avg       0.34      0.39      0.35      1666\n",
      "                    samples avg       0.31      0.40      0.32      1666\n",
      "\n",
      "tensor(3.4099, device='cuda:2')\n",
      "tensor(0.2997, device='cuda:2') tensor(3.4099, device='cuda:2') 0.627781681892715 0.3517862012544314\n",
      "Training epoch: 21\n",
      "Start\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/lun2/pjwstk.edu.pl/kbaraniak/semeval/sem/lib64/python3.6/site-packages/ipykernel_launcher.py:62: UserWarning: torch.range is deprecated and will be removed in a future release because its behavior is inconsistent with Python's range builtin. Instead, use torch.arange, which produces values in [start, end).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss per 100 training steps: 0.49346035718917847\n",
      "Training loss per 100 training steps: 0.3412521574461814\n",
      "Training loss per 100 training steps: 0.335312513421424\n",
      "Training loss per 100 training steps: 0.3335048697418549\n",
      "Training loss per 100 training steps: 0.3360574404126094\n",
      "Training loss epoch: 0.33908424570839457\n",
      "Training accuracy epoch: 0.0\n",
      "Training eval\n",
      "tensor(0.2735, device='cuda:2')\n",
      "                                 precision    recall  f1-score   support\n",
      "\n",
      "                          Doubt       0.64      0.99      0.78       518\n",
      "Obfuscation-Vagueness-Confusion       0.30      1.00      0.46        18\n",
      "           Appeal_to_Popularity       0.22      1.00      0.36        15\n",
      "      Exaggeration-Minimisation       0.69      0.98      0.81       466\n",
      "            Conversation_Killer       0.63      0.99      0.77        91\n",
      "                   Whataboutism       0.28      1.00      0.44        16\n",
      "                        Slogans       0.65      1.00      0.79       153\n",
      "           Guilt_by_Association       0.48      1.00      0.65        59\n",
      "            Appeal_to_Hypocrisy       0.53      1.00      0.69        40\n",
      "                     Repetition       0.59      0.89      0.71       544\n",
      "                    Flag_Waving       0.60      1.00      0.75       287\n",
      "          Name_Calling-Labeling       0.34      0.98      0.51       979\n",
      "      Causal_Oversimplification       0.35      1.00      0.52       213\n",
      "                Loaded_Language       0.58      0.93      0.72      1809\n",
      "                    Red_Herring       0.54      1.00      0.70        44\n",
      "        False_Dilemma-No_Choice       0.64      1.00      0.78       122\n",
      "                      Straw_Man       0.27      1.00      0.43        15\n",
      "       Appeal_to_Fear-Prejudice       0.69      1.00      0.81       310\n",
      "            Appeal_to_Authority       0.78      1.00      0.88       154\n",
      "\n",
      "                      micro avg       0.52      0.96      0.68      5853\n",
      "                      macro avg       0.52      0.99      0.66      5853\n",
      "                   weighted avg       0.56      0.96      0.70      5853\n",
      "                    samples avg       0.56      0.97      0.69      5853\n",
      "\n",
      "Test eval\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/lun2/pjwstk.edu.pl/kbaraniak/semeval/sem/lib64/python3.6/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/mnt/lun2/pjwstk.edu.pl/kbaraniak/semeval/sem/lib64/python3.6/site-packages/ipykernel_launcher.py:62: UserWarning: torch.range is deprecated and will be removed in a future release because its behavior is inconsistent with Python's range builtin. Instead, use torch.arange, which produces values in [start, end).\n",
      "/mnt/lun2/pjwstk.edu.pl/kbaraniak/semeval/sem/lib64/python3.6/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/mnt/lun2/pjwstk.edu.pl/kbaraniak/semeval/sem/lib64/python3.6/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                 precision    recall  f1-score   support\n",
      "\n",
      "                          Doubt       0.26      0.32      0.29       187\n",
      "Obfuscation-Vagueness-Confusion       0.00      0.00      0.00        13\n",
      "           Appeal_to_Popularity       0.00      0.00      0.00        34\n",
      "      Exaggeration-Minimisation       0.21      0.26      0.23       115\n",
      "            Conversation_Killer       0.00      0.00      0.00        25\n",
      "                   Whataboutism       0.00      0.00      0.00         2\n",
      "                        Slogans       0.30      0.25      0.27        28\n",
      "           Guilt_by_Association       0.00      0.00      0.00         4\n",
      "            Appeal_to_Hypocrisy       0.00      0.00      0.00         8\n",
      "                     Repetition       0.18      0.07      0.10       141\n",
      "                    Flag_Waving       0.40      0.59      0.48        96\n",
      "          Name_Calling-Labeling       0.28      0.86      0.42       250\n",
      "      Causal_Oversimplification       0.06      0.17      0.09        24\n",
      "                Loaded_Language       0.49      0.88      0.63       483\n",
      "                    Red_Herring       0.00      0.00      0.00        19\n",
      "        False_Dilemma-No_Choice       0.27      0.05      0.08        63\n",
      "                      Straw_Man       0.00      0.00      0.00         9\n",
      "       Appeal_to_Fear-Prejudice       0.21      0.09      0.13       137\n",
      "            Appeal_to_Authority       0.00      0.00      0.00        28\n",
      "\n",
      "                      micro avg       0.34      0.50      0.40      1666\n",
      "                      macro avg       0.14      0.19      0.14      1666\n",
      "                   weighted avg       0.30      0.50      0.35      1666\n",
      "                    samples avg       0.34      0.51      0.38      1666\n",
      "\n",
      "tensor(4.3191, device='cuda:2')\n",
      "tensor(0.2735, device='cuda:2') tensor(4.3191, device='cuda:2') 0.6760681709073452 0.40480274442538594\n",
      "Training epoch: 22\n",
      "Start\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/lun2/pjwstk.edu.pl/kbaraniak/semeval/sem/lib64/python3.6/site-packages/ipykernel_launcher.py:62: UserWarning: torch.range is deprecated and will be removed in a future release because its behavior is inconsistent with Python's range builtin. Instead, use torch.arange, which produces values in [start, end).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss per 100 training steps: 0.27646204829216003\n",
      "Training loss per 100 training steps: 0.3099773387507637\n",
      "Training loss per 100 training steps: 0.31530229569371065\n",
      "Training loss per 100 training steps: 0.3148878131593977\n",
      "Training loss per 100 training steps: 0.315698267627238\n",
      "Training loss epoch: 0.3183232286192001\n",
      "Training accuracy epoch: 0.0\n",
      "Training eval\n",
      "tensor(0.2578, device='cuda:2')\n",
      "                                 precision    recall  f1-score   support\n",
      "\n",
      "                          Doubt       0.72      0.99      0.83       518\n",
      "Obfuscation-Vagueness-Confusion       0.32      1.00      0.48        18\n",
      "           Appeal_to_Popularity       0.33      1.00      0.49        15\n",
      "      Exaggeration-Minimisation       0.38      1.00      0.55       466\n",
      "            Conversation_Killer       0.66      1.00      0.79        91\n",
      "                   Whataboutism       0.26      1.00      0.42        16\n",
      "                        Slogans       0.78      1.00      0.88       153\n",
      "           Guilt_by_Association       0.61      1.00      0.76        59\n",
      "            Appeal_to_Hypocrisy       0.59      1.00      0.74        40\n",
      "                     Repetition       0.65      0.94      0.77       544\n",
      "                    Flag_Waving       0.64      1.00      0.78       287\n",
      "          Name_Calling-Labeling       0.55      0.89      0.68       979\n",
      "      Causal_Oversimplification       0.70      1.00      0.82       213\n",
      "                Loaded_Language       0.63      0.85      0.72      1809\n",
      "                    Red_Herring       0.56      1.00      0.72        44\n",
      "        False_Dilemma-No_Choice       0.73      1.00      0.84       122\n",
      "                      Straw_Man       0.28      1.00      0.44        15\n",
      "       Appeal_to_Fear-Prejudice       0.73      1.00      0.85       310\n",
      "            Appeal_to_Authority       0.85      1.00      0.92       154\n",
      "\n",
      "                      micro avg       0.60      0.93      0.73      5853\n",
      "                      macro avg       0.58      0.98      0.71      5853\n",
      "                   weighted avg       0.62      0.93      0.74      5853\n",
      "                    samples avg       0.67      0.94      0.75      5853\n",
      "\n",
      "Test eval\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/lun2/pjwstk.edu.pl/kbaraniak/semeval/sem/lib64/python3.6/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/mnt/lun2/pjwstk.edu.pl/kbaraniak/semeval/sem/lib64/python3.6/site-packages/ipykernel_launcher.py:62: UserWarning: torch.range is deprecated and will be removed in a future release because its behavior is inconsistent with Python's range builtin. Instead, use torch.arange, which produces values in [start, end).\n",
      "/mnt/lun2/pjwstk.edu.pl/kbaraniak/semeval/sem/lib64/python3.6/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/mnt/lun2/pjwstk.edu.pl/kbaraniak/semeval/sem/lib64/python3.6/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                 precision    recall  f1-score   support\n",
      "\n",
      "                          Doubt       0.24      0.33      0.28       187\n",
      "Obfuscation-Vagueness-Confusion       0.00      0.00      0.00        13\n",
      "           Appeal_to_Popularity       0.00      0.00      0.00        34\n",
      "      Exaggeration-Minimisation       0.19      0.40      0.26       115\n",
      "            Conversation_Killer       0.00      0.00      0.00        25\n",
      "                   Whataboutism       0.00      0.00      0.00         2\n",
      "                        Slogans       0.29      0.07      0.11        28\n",
      "           Guilt_by_Association       0.00      0.00      0.00         4\n",
      "            Appeal_to_Hypocrisy       0.00      0.00      0.00         8\n",
      "                     Repetition       0.14      0.06      0.09       141\n",
      "                    Flag_Waving       0.38      0.49      0.43        96\n",
      "          Name_Calling-Labeling       0.45      0.45      0.45       250\n",
      "      Causal_Oversimplification       0.00      0.00      0.00        24\n",
      "                Loaded_Language       0.51      0.66      0.57       483\n",
      "                    Red_Herring       0.00      0.00      0.00        19\n",
      "        False_Dilemma-No_Choice       0.25      0.05      0.08        63\n",
      "                      Straw_Man       0.00      0.00      0.00         9\n",
      "       Appeal_to_Fear-Prejudice       0.20      0.08      0.11       137\n",
      "            Appeal_to_Authority       0.17      0.04      0.06        28\n",
      "\n",
      "                      micro avg       0.36      0.37      0.37      1666\n",
      "                      macro avg       0.15      0.14      0.13      1666\n",
      "                   weighted avg       0.32      0.37      0.33      1666\n",
      "                    samples avg       0.32      0.38      0.32      1666\n",
      "\n",
      "tensor(4.5423, device='cuda:2')\n",
      "tensor(0.2578, device='cuda:2') tensor(4.5423, device='cuda:2') 0.7285255552582285 0.3659701492537313\n",
      "Training epoch: 23\n",
      "Start\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/lun2/pjwstk.edu.pl/kbaraniak/semeval/sem/lib64/python3.6/site-packages/ipykernel_launcher.py:62: UserWarning: torch.range is deprecated and will be removed in a future release because its behavior is inconsistent with Python's range builtin. Instead, use torch.arange, which produces values in [start, end).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss per 100 training steps: 0.22834736108779907\n",
      "Training loss per 100 training steps: 0.30659859870920086\n",
      "Training loss per 100 training steps: 0.30863931856641724\n",
      "Training loss per 100 training steps: 0.31103022035174194\n",
      "Training loss per 100 training steps: 0.3137188254300496\n",
      "Training loss epoch: 0.3202018030780427\n",
      "Training accuracy epoch: 0.0\n",
      "Training eval\n",
      "tensor(0.2297, device='cuda:2')\n",
      "                                 precision    recall  f1-score   support\n",
      "\n",
      "                          Doubt       0.62      1.00      0.77       518\n",
      "Obfuscation-Vagueness-Confusion       0.23      1.00      0.37        18\n",
      "           Appeal_to_Popularity       0.21      1.00      0.35        15\n",
      "      Exaggeration-Minimisation       0.64      1.00      0.78       466\n",
      "            Conversation_Killer       0.62      1.00      0.77        91\n",
      "                   Whataboutism       0.12      1.00      0.22        16\n",
      "                        Slogans       0.61      1.00      0.76       153\n",
      "           Guilt_by_Association       0.31      1.00      0.48        59\n",
      "            Appeal_to_Hypocrisy       0.21      1.00      0.34        40\n",
      "                     Repetition       0.64      0.97      0.77       544\n",
      "                    Flag_Waving       0.76      1.00      0.86       287\n",
      "          Name_Calling-Labeling       0.50      0.93      0.65       979\n",
      "      Causal_Oversimplification       0.44      1.00      0.62       213\n",
      "                Loaded_Language       0.67      0.73      0.70      1809\n",
      "                    Red_Herring       0.30      1.00      0.47        44\n",
      "        False_Dilemma-No_Choice       0.56      1.00      0.72       122\n",
      "                      Straw_Man       0.15      1.00      0.26        15\n",
      "       Appeal_to_Fear-Prejudice       0.62      1.00      0.77       310\n",
      "            Appeal_to_Authority       0.65      1.00      0.79       154\n",
      "\n",
      "                      micro avg       0.57      0.90      0.70      5853\n",
      "                      macro avg       0.47      0.98      0.60      5853\n",
      "                   weighted avg       0.61      0.90      0.71      5853\n",
      "                    samples avg       0.66      0.91      0.73      5853\n",
      "\n",
      "Test eval\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/lun2/pjwstk.edu.pl/kbaraniak/semeval/sem/lib64/python3.6/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/mnt/lun2/pjwstk.edu.pl/kbaraniak/semeval/sem/lib64/python3.6/site-packages/ipykernel_launcher.py:62: UserWarning: torch.range is deprecated and will be removed in a future release because its behavior is inconsistent with Python's range builtin. Instead, use torch.arange, which produces values in [start, end).\n",
      "/mnt/lun2/pjwstk.edu.pl/kbaraniak/semeval/sem/lib64/python3.6/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/mnt/lun2/pjwstk.edu.pl/kbaraniak/semeval/sem/lib64/python3.6/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                 precision    recall  f1-score   support\n",
      "\n",
      "                          Doubt       0.23      0.32      0.26       187\n",
      "Obfuscation-Vagueness-Confusion       0.00      0.00      0.00        13\n",
      "           Appeal_to_Popularity       0.00      0.00      0.00        34\n",
      "      Exaggeration-Minimisation       0.17      0.26      0.21       115\n",
      "            Conversation_Killer       0.03      0.04      0.04        25\n",
      "                   Whataboutism       0.00      0.00      0.00         2\n",
      "                        Slogans       0.24      0.25      0.25        28\n",
      "           Guilt_by_Association       0.43      0.75      0.55         4\n",
      "            Appeal_to_Hypocrisy       0.00      0.00      0.00         8\n",
      "                     Repetition       0.15      0.07      0.10       141\n",
      "                    Flag_Waving       0.41      0.36      0.39        96\n",
      "          Name_Calling-Labeling       0.38      0.62      0.47       250\n",
      "      Causal_Oversimplification       0.06      0.12      0.08        24\n",
      "                Loaded_Language       0.53      0.57      0.55       483\n",
      "                    Red_Herring       0.00      0.00      0.00        19\n",
      "        False_Dilemma-No_Choice       0.25      0.08      0.12        63\n",
      "                      Straw_Man       0.00      0.00      0.00         9\n",
      "       Appeal_to_Fear-Prejudice       0.25      0.18      0.21       137\n",
      "            Appeal_to_Authority       0.07      0.04      0.05        28\n",
      "\n",
      "                      micro avg       0.34      0.37      0.35      1666\n",
      "                      macro avg       0.17      0.19      0.17      1666\n",
      "                   weighted avg       0.32      0.37      0.33      1666\n",
      "                    samples avg       0.29      0.37      0.30      1666\n",
      "\n",
      "tensor(4.4091, device='cuda:2')\n",
      "tensor(0.2297, device='cuda:2') tensor(4.4091, device='cuda:2') 0.6967451706800741 0.35141373341027116\n",
      "Training epoch: 24\n",
      "Start\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/lun2/pjwstk.edu.pl/kbaraniak/semeval/sem/lib64/python3.6/site-packages/ipykernel_launcher.py:62: UserWarning: torch.range is deprecated and will be removed in a future release because its behavior is inconsistent with Python's range builtin. Instead, use torch.arange, which produces values in [start, end).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss per 100 training steps: 0.2044469565153122\n",
      "Training loss per 100 training steps: 0.2631976046774647\n",
      "Training loss per 100 training steps: 0.27421060026581606\n",
      "Training loss per 100 training steps: 0.28218361789800006\n",
      "Training loss per 100 training steps: 0.2924254211107097\n",
      "Training loss epoch: 0.29846889566867907\n",
      "Training accuracy epoch: 0.0\n",
      "Training eval\n",
      "tensor(0.2280, device='cuda:2')\n",
      "                                 precision    recall  f1-score   support\n",
      "\n",
      "                          Doubt       0.94      0.92      0.93       518\n",
      "Obfuscation-Vagueness-Confusion       0.23      1.00      0.37        18\n",
      "           Appeal_to_Popularity       0.18      1.00      0.31        15\n",
      "      Exaggeration-Minimisation       0.62      1.00      0.77       466\n",
      "            Conversation_Killer       0.53      1.00      0.69        91\n",
      "                   Whataboutism       0.13      1.00      0.23        16\n",
      "                        Slogans       0.46      1.00      0.63       153\n",
      "           Guilt_by_Association       0.43      1.00      0.61        59\n",
      "            Appeal_to_Hypocrisy       0.38      1.00      0.55        40\n",
      "                     Repetition       0.63      0.98      0.76       544\n",
      "                    Flag_Waving       0.76      1.00      0.86       287\n",
      "          Name_Calling-Labeling       0.61      0.91      0.73       979\n",
      "      Causal_Oversimplification       0.56      1.00      0.72       213\n",
      "                Loaded_Language       0.60      0.91      0.72      1809\n",
      "                    Red_Herring       0.51      1.00      0.67        44\n",
      "        False_Dilemma-No_Choice       0.35      1.00      0.52       122\n",
      "                      Straw_Man       0.15      1.00      0.27        15\n",
      "       Appeal_to_Fear-Prejudice       0.76      1.00      0.86       310\n",
      "            Appeal_to_Authority       0.81      1.00      0.90       154\n",
      "\n",
      "                      micro avg       0.60      0.95      0.74      5853\n",
      "                      macro avg       0.51      0.99      0.64      5853\n",
      "                   weighted avg       0.64      0.95      0.75      5853\n",
      "                    samples avg       0.70      0.97      0.78      5853\n",
      "\n",
      "Test eval\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/lun2/pjwstk.edu.pl/kbaraniak/semeval/sem/lib64/python3.6/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/mnt/lun2/pjwstk.edu.pl/kbaraniak/semeval/sem/lib64/python3.6/site-packages/ipykernel_launcher.py:62: UserWarning: torch.range is deprecated and will be removed in a future release because its behavior is inconsistent with Python's range builtin. Instead, use torch.arange, which produces values in [start, end).\n",
      "/mnt/lun2/pjwstk.edu.pl/kbaraniak/semeval/sem/lib64/python3.6/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/mnt/lun2/pjwstk.edu.pl/kbaraniak/semeval/sem/lib64/python3.6/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                 precision    recall  f1-score   support\n",
      "\n",
      "                          Doubt       0.39      0.12      0.18       187\n",
      "Obfuscation-Vagueness-Confusion       0.00      0.00      0.00        13\n",
      "           Appeal_to_Popularity       0.00      0.00      0.00        34\n",
      "      Exaggeration-Minimisation       0.23      0.28      0.25       115\n",
      "            Conversation_Killer       0.00      0.00      0.00        25\n",
      "                   Whataboutism       0.00      0.00      0.00         2\n",
      "                        Slogans       0.18      0.36      0.24        28\n",
      "           Guilt_by_Association       0.50      0.75      0.60         4\n",
      "            Appeal_to_Hypocrisy       0.00      0.00      0.00         8\n",
      "                     Repetition       0.13      0.09      0.10       141\n",
      "                    Flag_Waving       0.44      0.38      0.41        96\n",
      "          Name_Calling-Labeling       0.41      0.49      0.45       250\n",
      "      Causal_Oversimplification       0.03      0.04      0.04        24\n",
      "                Loaded_Language       0.48      0.86      0.62       483\n",
      "                    Red_Herring       0.00      0.00      0.00        19\n",
      "        False_Dilemma-No_Choice       0.17      0.11      0.14        63\n",
      "                      Straw_Man       0.00      0.00      0.00         9\n",
      "       Appeal_to_Fear-Prejudice       0.24      0.09      0.13       137\n",
      "            Appeal_to_Authority       0.50      0.04      0.07        28\n",
      "\n",
      "                      micro avg       0.39      0.40      0.39      1666\n",
      "                      macro avg       0.20      0.19      0.17      1666\n",
      "                   weighted avg       0.34      0.40      0.34      1666\n",
      "                    samples avg       0.38      0.42      0.37      1666\n",
      "\n",
      "tensor(4.4145, device='cuda:2')\n",
      "tensor(0.2280, device='cuda:2') tensor(4.4145, device='cuda:2') 0.736604774535809 0.39483719565855097\n",
      "Training epoch: 25\n",
      "Start\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/lun2/pjwstk.edu.pl/kbaraniak/semeval/sem/lib64/python3.6/site-packages/ipykernel_launcher.py:62: UserWarning: torch.range is deprecated and will be removed in a future release because its behavior is inconsistent with Python's range builtin. Instead, use torch.arange, which produces values in [start, end).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss per 100 training steps: 0.2860342860221863\n",
      "Training loss per 100 training steps: 0.2573862581855\n",
      "Training loss per 100 training steps: 0.2644024460173365\n",
      "Training loss per 100 training steps: 0.26750332166586205\n",
      "Training loss per 100 training steps: 0.2710269507847522\n",
      "Training loss epoch: 0.27633748802732916\n",
      "Training accuracy epoch: 0.0\n",
      "Training eval\n",
      "tensor(0.2114, device='cuda:2')\n",
      "                                 precision    recall  f1-score   support\n",
      "\n",
      "                          Doubt       0.90      1.00      0.95       518\n",
      "Obfuscation-Vagueness-Confusion       0.08      1.00      0.14        18\n",
      "           Appeal_to_Popularity       0.12      1.00      0.22        15\n",
      "      Exaggeration-Minimisation       0.61      1.00      0.76       466\n",
      "            Conversation_Killer       0.48      1.00      0.65        91\n",
      "                   Whataboutism       0.08      1.00      0.16        16\n",
      "                        Slogans       0.48      1.00      0.64       153\n",
      "           Guilt_by_Association       0.49      1.00      0.66        59\n",
      "            Appeal_to_Hypocrisy       0.27      1.00      0.43        40\n",
      "                     Repetition       0.73      0.99      0.84       544\n",
      "                    Flag_Waving       0.65      1.00      0.79       287\n",
      "          Name_Calling-Labeling       0.62      0.93      0.74       979\n",
      "      Causal_Oversimplification       0.61      1.00      0.76       213\n",
      "                Loaded_Language       0.63      0.88      0.74      1809\n",
      "                    Red_Herring       0.44      1.00      0.62        44\n",
      "        False_Dilemma-No_Choice       0.49      1.00      0.66       122\n",
      "                      Straw_Man       0.08      1.00      0.14        15\n",
      "       Appeal_to_Fear-Prejudice       0.75      1.00      0.86       310\n",
      "            Appeal_to_Authority       0.50      1.00      0.67       154\n",
      "\n",
      "                      micro avg       0.59      0.95      0.73      5853\n",
      "                      macro avg       0.47      0.99      0.60      5853\n",
      "                   weighted avg       0.64      0.95      0.76      5853\n",
      "                    samples avg       0.72      0.96      0.79      5853\n",
      "\n",
      "Test eval\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/lun2/pjwstk.edu.pl/kbaraniak/semeval/sem/lib64/python3.6/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/mnt/lun2/pjwstk.edu.pl/kbaraniak/semeval/sem/lib64/python3.6/site-packages/ipykernel_launcher.py:62: UserWarning: torch.range is deprecated and will be removed in a future release because its behavior is inconsistent with Python's range builtin. Instead, use torch.arange, which produces values in [start, end).\n",
      "/mnt/lun2/pjwstk.edu.pl/kbaraniak/semeval/sem/lib64/python3.6/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/mnt/lun2/pjwstk.edu.pl/kbaraniak/semeval/sem/lib64/python3.6/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                 precision    recall  f1-score   support\n",
      "\n",
      "                          Doubt       0.37      0.19      0.25       187\n",
      "Obfuscation-Vagueness-Confusion       0.00      0.00      0.00        13\n",
      "           Appeal_to_Popularity       0.00      0.00      0.00        34\n",
      "      Exaggeration-Minimisation       0.20      0.26      0.23       115\n",
      "            Conversation_Killer       0.02      0.04      0.03        25\n",
      "                   Whataboutism       0.00      0.00      0.00         2\n",
      "                        Slogans       0.23      0.36      0.28        28\n",
      "           Guilt_by_Association       0.25      0.25      0.25         4\n",
      "            Appeal_to_Hypocrisy       0.00      0.00      0.00         8\n",
      "                     Repetition       0.13      0.06      0.09       141\n",
      "                    Flag_Waving       0.41      0.43      0.42        96\n",
      "          Name_Calling-Labeling       0.40      0.51      0.45       250\n",
      "      Causal_Oversimplification       0.05      0.04      0.04        24\n",
      "                Loaded_Language       0.51      0.78      0.62       483\n",
      "                    Red_Herring       0.00      0.00      0.00        19\n",
      "        False_Dilemma-No_Choice       0.21      0.11      0.14        63\n",
      "                      Straw_Man       0.00      0.00      0.00         9\n",
      "       Appeal_to_Fear-Prejudice       0.22      0.09      0.13       137\n",
      "            Appeal_to_Authority       0.06      0.04      0.04        28\n",
      "\n",
      "                      micro avg       0.38      0.39      0.39      1666\n",
      "                      macro avg       0.16      0.17      0.16      1666\n",
      "                   weighted avg       0.33      0.39      0.34      1666\n",
      "                    samples avg       0.36      0.40      0.35      1666\n",
      "\n",
      "tensor(4.3218, device='cuda:2')\n",
      "tensor(0.2114, device='cuda:2') tensor(4.3218, device='cuda:2') 0.7267852471880722 0.3858407079646018\n",
      "Training epoch: 26\n",
      "Start\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/lun2/pjwstk.edu.pl/kbaraniak/semeval/sem/lib64/python3.6/site-packages/ipykernel_launcher.py:62: UserWarning: torch.range is deprecated and will be removed in a future release because its behavior is inconsistent with Python's range builtin. Instead, use torch.arange, which produces values in [start, end).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss per 100 training steps: 0.4425853490829468\n",
      "Training loss per 100 training steps: 0.25821549482274764\n",
      "Training loss per 100 training steps: 0.2702782828712938\n",
      "Training loss per 100 training steps: 0.26681930465357645\n",
      "Training loss per 100 training steps: 0.2658219900809024\n",
      "Training loss epoch: 0.2707360078679754\n",
      "Training accuracy epoch: 0.0\n",
      "Training eval\n",
      "tensor(0.2112, device='cuda:2')\n",
      "                                 precision    recall  f1-score   support\n",
      "\n",
      "                          Doubt       0.86      1.00      0.92       518\n",
      "Obfuscation-Vagueness-Confusion       0.23      1.00      0.38        18\n",
      "           Appeal_to_Popularity       0.16      1.00      0.28        15\n",
      "      Exaggeration-Minimisation       0.62      1.00      0.76       466\n",
      "            Conversation_Killer       0.68      0.98      0.80        91\n",
      "                   Whataboutism       0.18      1.00      0.31        16\n",
      "                        Slogans       0.34      1.00      0.50       153\n",
      "           Guilt_by_Association       0.53      1.00      0.69        59\n",
      "            Appeal_to_Hypocrisy       0.21      1.00      0.35        40\n",
      "                     Repetition       0.79      0.99      0.88       544\n",
      "                    Flag_Waving       0.78      1.00      0.87       287\n",
      "          Name_Calling-Labeling       0.52      0.97      0.67       979\n",
      "      Causal_Oversimplification       0.80      1.00      0.89       213\n",
      "                Loaded_Language       0.60      0.93      0.73      1809\n",
      "                    Red_Herring       0.43      1.00      0.60        44\n",
      "        False_Dilemma-No_Choice       0.62      1.00      0.76       122\n",
      "                      Straw_Man       0.18      1.00      0.31        15\n",
      "       Appeal_to_Fear-Prejudice       0.72      1.00      0.84       310\n",
      "            Appeal_to_Authority       0.54      1.00      0.70       154\n",
      "\n",
      "                      micro avg       0.59      0.97      0.74      5853\n",
      "                      macro avg       0.51      0.99      0.64      5853\n",
      "                   weighted avg       0.63      0.97      0.76      5853\n",
      "                    samples avg       0.69      0.98      0.78      5853\n",
      "\n",
      "Test eval\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/lun2/pjwstk.edu.pl/kbaraniak/semeval/sem/lib64/python3.6/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/mnt/lun2/pjwstk.edu.pl/kbaraniak/semeval/sem/lib64/python3.6/site-packages/ipykernel_launcher.py:62: UserWarning: torch.range is deprecated and will be removed in a future release because its behavior is inconsistent with Python's range builtin. Instead, use torch.arange, which produces values in [start, end).\n",
      "/mnt/lun2/pjwstk.edu.pl/kbaraniak/semeval/sem/lib64/python3.6/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                 precision    recall  f1-score   support\n",
      "\n",
      "                          Doubt       0.28      0.24      0.25       187\n",
      "Obfuscation-Vagueness-Confusion       0.00      0.00      0.00        13\n",
      "           Appeal_to_Popularity       0.00      0.00      0.00        34\n",
      "      Exaggeration-Minimisation       0.20      0.23      0.21       115\n",
      "            Conversation_Killer       0.00      0.00      0.00        25\n",
      "                   Whataboutism       0.00      0.00      0.00         2\n",
      "                        Slogans       0.18      0.36      0.24        28\n",
      "           Guilt_by_Association       0.20      0.25      0.22         4\n",
      "            Appeal_to_Hypocrisy       0.00      0.00      0.00         8\n",
      "                     Repetition       0.11      0.04      0.06       141\n",
      "                    Flag_Waving       0.46      0.35      0.40        96\n",
      "          Name_Calling-Labeling       0.38      0.62      0.47       250\n",
      "      Causal_Oversimplification       0.00      0.00      0.00        24\n",
      "                Loaded_Language       0.47      0.85      0.61       483\n",
      "                    Red_Herring       0.00      0.00      0.00        19\n",
      "        False_Dilemma-No_Choice       0.19      0.08      0.11        63\n",
      "                      Straw_Man       0.00      0.00      0.00         9\n",
      "       Appeal_to_Fear-Prejudice       0.23      0.13      0.17       137\n",
      "            Appeal_to_Authority       0.06      0.04      0.04        28\n",
      "\n",
      "                      micro avg       0.37      0.43      0.40      1666\n",
      "                      macro avg       0.15      0.17      0.15      1666\n",
      "                   weighted avg       0.31      0.43      0.34      1666\n",
      "                    samples avg       0.37      0.45      0.37      1666\n",
      "\n",
      "tensor(4.5662, device='cuda:2')\n",
      "tensor(0.2112, device='cuda:2') tensor(4.5662, device='cuda:2') 0.7374837872892349 0.39688282772056777\n",
      "Training epoch: 27\n",
      "Start\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/lun2/pjwstk.edu.pl/kbaraniak/semeval/sem/lib64/python3.6/site-packages/ipykernel_launcher.py:62: UserWarning: torch.range is deprecated and will be removed in a future release because its behavior is inconsistent with Python's range builtin. Instead, use torch.arange, which produces values in [start, end).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss per 100 training steps: 0.21347826719284058\n",
      "Training loss per 100 training steps: 0.250872969996221\n",
      "Training loss per 100 training steps: 0.2621333680268544\n",
      "Training loss per 100 training steps: 0.2577254563025462\n",
      "Training loss per 100 training steps: 0.26117084968714344\n",
      "Training loss epoch: 0.2686115613326113\n",
      "Training accuracy epoch: 0.0\n",
      "Training eval\n",
      "tensor(0.2096, device='cuda:2')\n",
      "                                 precision    recall  f1-score   support\n",
      "\n",
      "                          Doubt       0.78      1.00      0.87       518\n",
      "Obfuscation-Vagueness-Confusion       0.25      1.00      0.40        18\n",
      "           Appeal_to_Popularity       0.23      1.00      0.38        15\n",
      "      Exaggeration-Minimisation       0.90      0.99      0.94       466\n",
      "            Conversation_Killer       0.62      1.00      0.76        91\n",
      "                   Whataboutism       0.18      1.00      0.31        16\n",
      "                        Slogans       0.76      0.99      0.86       153\n",
      "           Guilt_by_Association       0.62      1.00      0.77        59\n",
      "            Appeal_to_Hypocrisy       0.59      1.00      0.74        40\n",
      "                     Repetition       0.72      0.99      0.84       544\n",
      "                    Flag_Waving       0.88      0.99      0.93       287\n",
      "          Name_Calling-Labeling       0.87      0.80      0.84       979\n",
      "      Causal_Oversimplification       0.74      1.00      0.85       213\n",
      "                Loaded_Language       0.65      0.83      0.73      1809\n",
      "                    Red_Herring       0.45      1.00      0.62        44\n",
      "        False_Dilemma-No_Choice       0.75      1.00      0.86       122\n",
      "                      Straw_Man       0.17      1.00      0.29        15\n",
      "       Appeal_to_Fear-Prejudice       0.82      1.00      0.90       310\n",
      "            Appeal_to_Authority       0.63      1.00      0.78       154\n",
      "\n",
      "                      micro avg       0.72      0.91      0.80      5853\n",
      "                      macro avg       0.61      0.98      0.72      5853\n",
      "                   weighted avg       0.75      0.91      0.81      5853\n",
      "                    samples avg       0.81      0.93      0.84      5853\n",
      "\n",
      "Test eval\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/lun2/pjwstk.edu.pl/kbaraniak/semeval/sem/lib64/python3.6/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/mnt/lun2/pjwstk.edu.pl/kbaraniak/semeval/sem/lib64/python3.6/site-packages/ipykernel_launcher.py:62: UserWarning: torch.range is deprecated and will be removed in a future release because its behavior is inconsistent with Python's range builtin. Instead, use torch.arange, which produces values in [start, end).\n",
      "/mnt/lun2/pjwstk.edu.pl/kbaraniak/semeval/sem/lib64/python3.6/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/mnt/lun2/pjwstk.edu.pl/kbaraniak/semeval/sem/lib64/python3.6/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                 precision    recall  f1-score   support\n",
      "\n",
      "                          Doubt       0.25      0.31      0.28       187\n",
      "Obfuscation-Vagueness-Confusion       0.00      0.00      0.00        13\n",
      "           Appeal_to_Popularity       0.00      0.00      0.00        34\n",
      "      Exaggeration-Minimisation       0.16      0.06      0.09       115\n",
      "            Conversation_Killer       0.00      0.00      0.00        25\n",
      "                   Whataboutism       0.00      0.00      0.00         2\n",
      "                        Slogans       0.33      0.04      0.06        28\n",
      "           Guilt_by_Association       0.00      0.00      0.00         4\n",
      "            Appeal_to_Hypocrisy       0.00      0.00      0.00         8\n",
      "                     Repetition       0.12      0.06      0.08       141\n",
      "                    Flag_Waving       0.48      0.32      0.39        96\n",
      "          Name_Calling-Labeling       0.54      0.19      0.28       250\n",
      "      Causal_Oversimplification       0.05      0.04      0.05        24\n",
      "                Loaded_Language       0.52      0.67      0.59       483\n",
      "                    Red_Herring       0.00      0.00      0.00        19\n",
      "        False_Dilemma-No_Choice       0.33      0.02      0.03        63\n",
      "                      Straw_Man       0.00      0.00      0.00         9\n",
      "       Appeal_to_Fear-Prejudice       0.26      0.07      0.11       137\n",
      "            Appeal_to_Authority       0.12      0.07      0.09        28\n",
      "\n",
      "                      micro avg       0.40      0.29      0.34      1666\n",
      "                      macro avg       0.17      0.10      0.11      1666\n",
      "                   weighted avg       0.35      0.29      0.29      1666\n",
      "                    samples avg       0.34      0.31      0.30      1666\n",
      "\n",
      "tensor(4.8911, device='cuda:2')\n",
      "tensor(0.2096, device='cuda:2') tensor(4.8911, device='cuda:2') 0.8037874802735402 0.33887733887733884\n",
      "Training epoch: 28\n",
      "Start\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/lun2/pjwstk.edu.pl/kbaraniak/semeval/sem/lib64/python3.6/site-packages/ipykernel_launcher.py:62: UserWarning: torch.range is deprecated and will be removed in a future release because its behavior is inconsistent with Python's range builtin. Instead, use torch.arange, which produces values in [start, end).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss per 100 training steps: 0.30876579880714417\n",
      "Training loss per 100 training steps: 0.25641207824839224\n",
      "Training loss per 100 training steps: 0.24302255440114148\n",
      "Training loss per 100 training steps: 0.24157288071523078\n",
      "Training loss per 100 training steps: 0.24803455619889306\n",
      "Training loss epoch: 0.25543137199067056\n",
      "Training accuracy epoch: 0.0\n",
      "Training eval\n",
      "tensor(0.2004, device='cuda:2')\n",
      "                                 precision    recall  f1-score   support\n",
      "\n",
      "                          Doubt       0.89      1.00      0.94       518\n",
      "Obfuscation-Vagueness-Confusion       0.31      1.00      0.47        18\n",
      "           Appeal_to_Popularity       0.26      1.00      0.41        15\n",
      "      Exaggeration-Minimisation       0.95      1.00      0.97       466\n",
      "            Conversation_Killer       0.70      1.00      0.82        91\n",
      "                   Whataboutism       0.33      1.00      0.50        16\n",
      "                        Slogans       0.66      1.00      0.79       153\n",
      "           Guilt_by_Association       0.60      1.00      0.75        59\n",
      "            Appeal_to_Hypocrisy       0.41      1.00      0.58        40\n",
      "                     Repetition       0.73      0.99      0.84       544\n",
      "                    Flag_Waving       0.88      1.00      0.94       287\n",
      "          Name_Calling-Labeling       0.70      0.95      0.81       979\n",
      "      Causal_Oversimplification       0.92      0.99      0.95       213\n",
      "                Loaded_Language       0.61      0.91      0.73      1809\n",
      "                    Red_Herring       0.72      1.00      0.84        44\n",
      "        False_Dilemma-No_Choice       0.65      1.00      0.79       122\n",
      "                      Straw_Man       0.19      1.00      0.32        15\n",
      "       Appeal_to_Fear-Prejudice       0.58      1.00      0.74       310\n",
      "            Appeal_to_Authority       0.90      1.00      0.95       154\n",
      "\n",
      "                      micro avg       0.69      0.96      0.80      5853\n",
      "                      macro avg       0.63      0.99      0.74      5853\n",
      "                   weighted avg       0.72      0.96      0.82      5853\n",
      "                    samples avg       0.77      0.97      0.84      5853\n",
      "\n",
      "Test eval\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/lun2/pjwstk.edu.pl/kbaraniak/semeval/sem/lib64/python3.6/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/mnt/lun2/pjwstk.edu.pl/kbaraniak/semeval/sem/lib64/python3.6/site-packages/ipykernel_launcher.py:62: UserWarning: torch.range is deprecated and will be removed in a future release because its behavior is inconsistent with Python's range builtin. Instead, use torch.arange, which produces values in [start, end).\n",
      "/mnt/lun2/pjwstk.edu.pl/kbaraniak/semeval/sem/lib64/python3.6/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/mnt/lun2/pjwstk.edu.pl/kbaraniak/semeval/sem/lib64/python3.6/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                 precision    recall  f1-score   support\n",
      "\n",
      "                          Doubt       0.29      0.20      0.24       187\n",
      "Obfuscation-Vagueness-Confusion       0.00      0.00      0.00        13\n",
      "           Appeal_to_Popularity       0.00      0.00      0.00        34\n",
      "      Exaggeration-Minimisation       0.14      0.04      0.07       115\n",
      "            Conversation_Killer       0.00      0.00      0.00        25\n",
      "                   Whataboutism       0.00      0.00      0.00         2\n",
      "                        Slogans       0.19      0.11      0.14        28\n",
      "           Guilt_by_Association       0.00      0.00      0.00         4\n",
      "            Appeal_to_Hypocrisy       0.00      0.00      0.00         8\n",
      "                     Repetition       0.11      0.06      0.08       141\n",
      "                    Flag_Waving       0.47      0.29      0.36        96\n",
      "          Name_Calling-Labeling       0.45      0.33      0.38       250\n",
      "      Causal_Oversimplification       0.00      0.00      0.00        24\n",
      "                Loaded_Language       0.49      0.82      0.61       483\n",
      "                    Red_Herring       0.00      0.00      0.00        19\n",
      "        False_Dilemma-No_Choice       0.20      0.08      0.11        63\n",
      "                      Straw_Man       0.00      0.00      0.00         9\n",
      "       Appeal_to_Fear-Prejudice       0.21      0.18      0.19       137\n",
      "            Appeal_to_Authority       0.50      0.04      0.07        28\n",
      "\n",
      "                      micro avg       0.40      0.36      0.38      1666\n",
      "                      macro avg       0.16      0.11      0.12      1666\n",
      "                   weighted avg       0.33      0.36      0.32      1666\n",
      "                    samples avg       0.38      0.38      0.35      1666\n",
      "\n",
      "tensor(4.9447, device='cuda:2')\n",
      "tensor(0.2004, device='cuda:2') tensor(4.9447, device='cuda:2') 0.8045370238265088 0.37599237853286754\n",
      "Training epoch: 29\n",
      "Start\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/lun2/pjwstk.edu.pl/kbaraniak/semeval/sem/lib64/python3.6/site-packages/ipykernel_launcher.py:62: UserWarning: torch.range is deprecated and will be removed in a future release because its behavior is inconsistent with Python's range builtin. Instead, use torch.arange, which produces values in [start, end).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss per 100 training steps: 0.15931765735149384\n",
      "Training loss per 100 training steps: 0.26149859301524586\n",
      "Training loss per 100 training steps: 0.25917483191585067\n",
      "Training loss per 100 training steps: 0.2501049651160985\n",
      "Training loss per 100 training steps: 0.24709834689808605\n",
      "Training loss epoch: 0.24618107063022066\n",
      "Training accuracy epoch: 0.0\n",
      "Training eval\n",
      "tensor(0.1746, device='cuda:2')\n",
      "                                 precision    recall  f1-score   support\n",
      "\n",
      "                          Doubt       0.84      1.00      0.91       518\n",
      "Obfuscation-Vagueness-Confusion       0.29      1.00      0.44        18\n",
      "           Appeal_to_Popularity       0.26      1.00      0.41        15\n",
      "      Exaggeration-Minimisation       0.88      1.00      0.94       466\n",
      "            Conversation_Killer       0.59      1.00      0.74        91\n",
      "                   Whataboutism       0.22      1.00      0.36        16\n",
      "                        Slogans       0.80      1.00      0.89       153\n",
      "           Guilt_by_Association       0.64      1.00      0.78        59\n",
      "            Appeal_to_Hypocrisy       0.45      1.00      0.62        40\n",
      "                     Repetition       0.89      0.99      0.94       544\n",
      "                    Flag_Waving       0.73      1.00      0.85       287\n",
      "          Name_Calling-Labeling       0.88      0.90      0.89       979\n",
      "      Causal_Oversimplification       0.93      1.00      0.96       213\n",
      "                Loaded_Language       0.67      0.85      0.75      1809\n",
      "                    Red_Herring       0.42      1.00      0.59        44\n",
      "        False_Dilemma-No_Choice       0.69      1.00      0.81       122\n",
      "                      Straw_Man       0.23      1.00      0.38        15\n",
      "       Appeal_to_Fear-Prejudice       0.78      1.00      0.88       310\n",
      "            Appeal_to_Authority       0.85      1.00      0.92       154\n",
      "\n",
      "                      micro avg       0.75      0.93      0.83      5853\n",
      "                      macro avg       0.63      0.99      0.74      5853\n",
      "                   weighted avg       0.77      0.93      0.84      5853\n",
      "                    samples avg       0.84      0.96      0.87      5853\n",
      "\n",
      "Test eval\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/lun2/pjwstk.edu.pl/kbaraniak/semeval/sem/lib64/python3.6/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/mnt/lun2/pjwstk.edu.pl/kbaraniak/semeval/sem/lib64/python3.6/site-packages/ipykernel_launcher.py:62: UserWarning: torch.range is deprecated and will be removed in a future release because its behavior is inconsistent with Python's range builtin. Instead, use torch.arange, which produces values in [start, end).\n",
      "/mnt/lun2/pjwstk.edu.pl/kbaraniak/semeval/sem/lib64/python3.6/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/mnt/lun2/pjwstk.edu.pl/kbaraniak/semeval/sem/lib64/python3.6/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                 precision    recall  f1-score   support\n",
      "\n",
      "                          Doubt       0.26      0.27      0.26       187\n",
      "Obfuscation-Vagueness-Confusion       0.00      0.00      0.00        13\n",
      "           Appeal_to_Popularity       0.00      0.00      0.00        34\n",
      "      Exaggeration-Minimisation       0.19      0.16      0.17       115\n",
      "            Conversation_Killer       0.03      0.04      0.03        25\n",
      "                   Whataboutism       0.00      0.00      0.00         2\n",
      "                        Slogans       0.18      0.07      0.10        28\n",
      "           Guilt_by_Association       0.00      0.00      0.00         4\n",
      "            Appeal_to_Hypocrisy       0.00      0.00      0.00         8\n",
      "                     Repetition       0.12      0.03      0.05       141\n",
      "                    Flag_Waving       0.44      0.38      0.40        96\n",
      "          Name_Calling-Labeling       0.49      0.22      0.30       250\n",
      "      Causal_Oversimplification       0.00      0.00      0.00        24\n",
      "                Loaded_Language       0.51      0.77      0.61       483\n",
      "                    Red_Herring       0.00      0.00      0.00        19\n",
      "        False_Dilemma-No_Choice       0.19      0.06      0.10        63\n",
      "                      Straw_Man       0.00      0.00      0.00         9\n",
      "       Appeal_to_Fear-Prejudice       0.21      0.12      0.15       137\n",
      "            Appeal_to_Authority       0.25      0.04      0.06        28\n",
      "\n",
      "                      micro avg       0.40      0.34      0.36      1666\n",
      "                      macro avg       0.15      0.11      0.12      1666\n",
      "                   weighted avg       0.33      0.34      0.31      1666\n",
      "                    samples avg       0.38      0.36      0.34      1666\n",
      "\n",
      "tensor(5.0611, device='cuda:2')\n",
      "tensor(0.1746, device='cuda:2') tensor(5.0611, device='cuda:2') 0.8306641366223908 0.36357723577235773\n",
      "Training epoch: 30\n",
      "Start\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/lun2/pjwstk.edu.pl/kbaraniak/semeval/sem/lib64/python3.6/site-packages/ipykernel_launcher.py:62: UserWarning: torch.range is deprecated and will be removed in a future release because its behavior is inconsistent with Python's range builtin. Instead, use torch.arange, which produces values in [start, end).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss per 100 training steps: 0.1594698280096054\n",
      "Training loss per 100 training steps: 0.23653937322963584\n",
      "Training loss per 100 training steps: 0.2501224999997153\n",
      "Training loss per 100 training steps: 0.25108122486509754\n",
      "Training loss per 100 training steps: 0.24714540654881637\n",
      "Training loss epoch: 0.247159979920438\n",
      "Training accuracy epoch: 0.0\n",
      "Training eval\n",
      "tensor(0.1813, device='cuda:2')\n",
      "                                 precision    recall  f1-score   support\n",
      "\n",
      "                          Doubt       0.86      1.00      0.93       518\n",
      "Obfuscation-Vagueness-Confusion       0.16      1.00      0.27        18\n",
      "           Appeal_to_Popularity       0.17      1.00      0.30        15\n",
      "      Exaggeration-Minimisation       0.62      1.00      0.77       466\n",
      "            Conversation_Killer       0.61      1.00      0.76        91\n",
      "                   Whataboutism       0.14      1.00      0.24        16\n",
      "                        Slogans       0.60      1.00      0.75       153\n",
      "           Guilt_by_Association       0.48      1.00      0.65        59\n",
      "            Appeal_to_Hypocrisy       0.14      1.00      0.25        40\n",
      "                     Repetition       0.78      1.00      0.88       544\n",
      "                    Flag_Waving       0.68      1.00      0.81       287\n",
      "          Name_Calling-Labeling       0.70      0.98      0.82       979\n",
      "      Causal_Oversimplification       0.61      1.00      0.76       213\n",
      "                Loaded_Language       0.67      0.85      0.75      1809\n",
      "                    Red_Herring       0.31      1.00      0.47        44\n",
      "        False_Dilemma-No_Choice       0.51      1.00      0.68       122\n",
      "                      Straw_Man       0.14      1.00      0.25        15\n",
      "       Appeal_to_Fear-Prejudice       0.58      1.00      0.73       310\n",
      "            Appeal_to_Authority       0.68      1.00      0.81       154\n",
      "\n",
      "                      micro avg       0.63      0.95      0.76      5853\n",
      "                      macro avg       0.50      0.99      0.62      5853\n",
      "                   weighted avg       0.67      0.95      0.78      5853\n",
      "                    samples avg       0.76      0.97      0.82      5853\n",
      "\n",
      "Test eval\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/lun2/pjwstk.edu.pl/kbaraniak/semeval/sem/lib64/python3.6/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/mnt/lun2/pjwstk.edu.pl/kbaraniak/semeval/sem/lib64/python3.6/site-packages/ipykernel_launcher.py:62: UserWarning: torch.range is deprecated and will be removed in a future release because its behavior is inconsistent with Python's range builtin. Instead, use torch.arange, which produces values in [start, end).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                 precision    recall  f1-score   support\n",
      "\n",
      "                          Doubt       0.26      0.23      0.25       187\n",
      "Obfuscation-Vagueness-Confusion       0.00      0.00      0.00        13\n",
      "           Appeal_to_Popularity       0.00      0.00      0.00        34\n",
      "      Exaggeration-Minimisation       0.20      0.30      0.24       115\n",
      "            Conversation_Killer       0.00      0.00      0.00        25\n",
      "                   Whataboutism       0.00      0.00      0.00         2\n",
      "                        Slogans       0.21      0.29      0.24        28\n",
      "           Guilt_by_Association       0.50      0.25      0.33         4\n",
      "            Appeal_to_Hypocrisy       0.00      0.00      0.00         8\n",
      "                     Repetition       0.12      0.06      0.08       141\n",
      "                    Flag_Waving       0.41      0.40      0.40        96\n",
      "          Name_Calling-Labeling       0.39      0.57      0.47       250\n",
      "      Causal_Oversimplification       0.00      0.00      0.00        24\n",
      "                Loaded_Language       0.50      0.76      0.60       483\n",
      "                    Red_Herring       0.00      0.00      0.00        19\n",
      "        False_Dilemma-No_Choice       0.20      0.13      0.16        63\n",
      "                      Straw_Man       0.00      0.00      0.00         9\n",
      "       Appeal_to_Fear-Prejudice       0.23      0.17      0.19       137\n",
      "            Appeal_to_Authority       0.08      0.04      0.05        28\n",
      "\n",
      "                      micro avg       0.36      0.40      0.38      1666\n",
      "                      macro avg       0.16      0.17      0.16      1666\n",
      "                   weighted avg       0.31      0.40      0.35      1666\n",
      "                    samples avg       0.36      0.42      0.35      1666\n",
      "\n",
      "tensor(4.8374, device='cuda:2')\n",
      "tensor(0.1813, device='cuda:2') tensor(4.8374, device='cuda:2') 0.7559782608695651 0.3819009675583381\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/lun2/pjwstk.edu.pl/kbaraniak/semeval/sem/lib64/python3.6/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/mnt/lun2/pjwstk.edu.pl/kbaraniak/semeval/sem/lib64/python3.6/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "train_loss_history=[]\n",
    "test_loss_history=[]\n",
    "train_f1micro_history=[]\n",
    "test_f1micro_history=[]\n",
    "\n",
    "model= PropagandaClassifier(len(frames_to_ids),len(tags_to_ids), 0.1, BERT_MODEL)\n",
    "model=model.to(device)\n",
    "\n",
    "\n",
    "optimizer = torch.optim.Adam(params=model.parameters(), lr=LEARNING_RATE, weight_decay=0.01) # AdamW\n",
    "\n",
    "class_weights=torch.as_tensor(class_weights).to(device, dtype = torch.float)\n",
    "\n",
    "loss_fct =  nn.BCEWithLogitsLoss(pos_weight=class_weights)\n",
    "\n",
    "loss_fct2 =  nn.CrossEntropyLoss()\n",
    "\n",
    "\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    print(f\"Training epoch: {epoch + 1}\")\n",
    "    loss_tr, loss_te, f1_tr, f1_te=training(epoch)\n",
    "    print(loss_tr, loss_te, f1_tr, f1_te)\n",
    "    train_loss_history.append(loss_tr)\n",
    "    test_loss_history.append(loss_te)\n",
    "    train_f1micro_history.append(f1_tr)\n",
    "    test_f1micro_history.append(f1_te)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "E96DITIBrvDV"
   },
   "outputs": [],
   "source": [
    "train_loss_history=[t.item() for t in train_loss_history]\n",
    "test_loss_history=[t.item() for t in test_loss_history]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(train_loss_history, \"--\")\n",
    "plt.plot(test_loss_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 283
    },
    "executionInfo": {
     "elapsed": 17,
     "status": "ok",
     "timestamp": 1671044051391,
     "user": {
      "displayName": "Katarzyna Baraniak",
      "userId": "09959407714606546607"
     },
     "user_tz": -60
    },
    "id": "jI1Bt3wh07Pm",
    "outputId": "b212e614-e2fc-46e2-882b-ff7ab18c64d7"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(train_f1micro_history, \"o\")\n",
    "plt.plot(test_f1micro_history)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyPrZYEk1sZ9UG8sS8kvwY3Y",
   "machine_shape": "hm",
   "mount_file_id": "1lZWuHlVDHleipPAfhRLHEheh_XBUftLd",
   "provenance": [],
   "toc_visible": true
  },
  "gpuClass": "premium",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "2e6cb11d793040f7940221279053ad1b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_498f1ac1fdd64441856eef36bf717276",
      "max": 3760,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_9a89037cc5a3425e8811fd3de0fa696e",
      "value": 3760
     }
    },
    "498f1ac1fdd64441856eef36bf717276": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5f4b1b43ff284fabbcb3cedd4acabd2e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6aab9c00fc0441948ab55483ba849245": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "7258d508c61e447eb18f3ee1b9393c17": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "81ce3f1390b843778e9d83441f25f72c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5f4b1b43ff284fabbcb3cedd4acabd2e",
      "placeholder": "​",
      "style": "IPY_MODEL_9d84110857414d49ba319128e7d9b08f",
      "value": " 3760/3760 [00:00&lt;00:00, 10995.59it/s]"
     }
    },
    "9a89037cc5a3425e8811fd3de0fa696e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "9d84110857414d49ba319128e7d9b08f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "b12494951bae49d29fc7706a2b8a0114": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_cf3a355dad12440cb799b467a92b7b04",
      "placeholder": "​",
      "style": "IPY_MODEL_6aab9c00fc0441948ab55483ba849245",
      "value": "100%"
     }
    },
    "cf3a355dad12440cb799b467a92b7b04": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "da22f896c64c48fbb5f098e1b6cb8cb3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_b12494951bae49d29fc7706a2b8a0114",
       "IPY_MODEL_2e6cb11d793040f7940221279053ad1b",
       "IPY_MODEL_81ce3f1390b843778e9d83441f25f72c"
      ],
      "layout": "IPY_MODEL_7258d508c61e447eb18f3ee1b9393c17"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
