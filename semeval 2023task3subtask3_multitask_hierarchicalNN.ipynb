{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0OWqzAD081Ph"
   },
   "source": [
    "# Multitask Hierachical Neural Network for Persuasion Techniques Detection\n",
    "\n",
    "This is a solution of kb team for Semeval 2023 task 3 subtask 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 109,
     "status": "ok",
     "timestamp": 1671050265516,
     "user": {
      "displayName": "Katarzyna Baraniak",
      "userId": "09959407714606546607"
     },
     "user_tz": -60
    },
    "id": "GD5x6JMgZTio"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "def seed_everything(seed=73):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    # some cudnn methods can be random even after fixing the seed unless you tell it to be deterministic\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "seed_everything(1234)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 79,
     "status": "ok",
     "timestamp": 1671050265517,
     "user": {
      "displayName": "Katarzyna Baraniak",
      "userId": "09959407714606546607"
     },
     "user_tz": -60
    },
    "id": "V2LNzgO5kKcr",
    "outputId": "fd6ed375-2d29-4267-a1b4-834c2f1cad99",
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "lang=\"en\" #set language"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## READ input data and spans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "def make_dataframe_subtask3(input_folder, labels_fn=None, spans=None):\n",
    "    txt_files = [f for  f in os.listdir(spans) if f.endswith('.txt')]\n",
    "    print(\"number of files: \", len(txt_files))\n",
    "    # print()\n",
    "    df_labels = pd.DataFrame(columns=[\"id\",\"label\", \"start\", \"end\"])\n",
    "    # print(txt_files)\n",
    "    for i, js in enumerate(txt_files):\n",
    "        # print(js\n",
    "        with open(os.path.join(spans, js)) as file:\n",
    "            line=file.readline()\n",
    "            # print(line)\n",
    "            while line!=\"\":\n",
    "                l=line.split()\n",
    "                # print(l[0])\n",
    "                df_labels=df_labels.append({\"id\":l[0], \"label\":l[1], \"start\":l[2], \"end\":l[3]}, ignore_index=True)\n",
    "                line=file.readline()\n",
    "\n",
    "    #MAKE TXT DATAFRAME\n",
    "    text = pd.DataFrame()\n",
    "    articles=[]\n",
    "    for fil in tqdm(filter(lambda x: x.endswith('.txt') and x.startswith(\"art\"), os.listdir(input_folder))):\n",
    "        iD = fil[7:].split('.')[0]\n",
    "        # print(\"------------------------------------------\")\n",
    "        # print(fil)\n",
    "        art_labels=df_labels[df_labels[\"id\"]==iD]\n",
    "        art_labels[\"start\"]=art_labels[\"start\"].astype(int)\n",
    "        art_labels[\"end\"]=art_labels[\"end\"].astype(int)\n",
    "\n",
    "        article=open(input_folder+fil,'r', encoding=\"utf-8\", errors='ignore').read()\n",
    "        # print(article)\n",
    "        for row in art_labels.iterrows():\n",
    "            start= int(row[1][\"start\"])#-12\n",
    "            end= int(row[1][\"end\"])#-12\n",
    "            # print(article[start : end], row[1][\"label\"])\n",
    "        lines = list(enumerate(open(input_folder+fil,'r', encoding=\"utf-8\", errors='ignore').read().splitlines(),1))\n",
    "        start_line=0\n",
    "        end_line=0\n",
    "        start_ends=()\n",
    "        for line in lines:\n",
    "            # print(line[1])\n",
    "            start_line=end_line\n",
    "            end_line=end_line+len(line[1])\n",
    "            # print(start_line)\n",
    "            od_do=list()\n",
    "            for span in art_labels[(art_labels.start>=start_line)&(art_labels.end<end_line)].iterrows():\n",
    "                od=span[1].start-start_line\n",
    "                do=span[1].end-start_line\n",
    "                od_do.append({\"start\":od, \"end\":do, \"label\":span[1][\"label\"]})\n",
    "            text=text.append({\"id\": iD, \"line\":line[0], \"text\":line[1], \"spans\":od_do}, ignore_index=True)\n",
    "            \n",
    "                \n",
    "        # text.extend([(iD,) + line for line in lines])\n",
    "    print(text)\n",
    "    df_text = pd.DataFrame(text, columns=['id','line','text', \"spans\"])\n",
    "    df_text.id = df_text.id.apply(int)\n",
    "    df_text.line = df_text.line.apply(int)\n",
    "    df_text = df_text[df_text.text.str.strip().str.len() > 0].copy()\n",
    "    df_text = df_text.set_index(['id','line'])\n",
    "    \n",
    "    df = df_text\n",
    "\n",
    "    if labels_fn:\n",
    "        #MAKE LABEL DATAFRAME\n",
    "        labels = pd.read_csv(labels_fn,sep='\\t',encoding='utf-8',header=None)\n",
    "        labels = labels.rename(columns={0:'id',1:'line',2:'labels'})\n",
    "        labels = labels.set_index(['id','line'])\n",
    "        labels = labels[labels.labels.notna()].copy()\n",
    "\n",
    "        #JOIN\n",
    "        df = labels.join(df_text)[['text','spans','labels']]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "labels_test_fn=\"/data/en/dev-labels-subtask-3.txt\"\n",
    "folder_dev=\"/data/en/dev-articles-subtask-3/\"\n",
    "labels_train_fn=\"/data/en/train-labels-subtask-3.txt\"\n",
    "folder_train=\"/data/en/train-articles-subtask-3/\"\n",
    "train_span=\"/data/\"+lang+\"/train-labels-subtask-3-spans\"\n",
    "test_span=\"/data/\"+lang+\"/dev-labels-subtask-3-spans\"\n",
    "\n",
    "print('Loading training...')\n",
    "train=make_dataframe_subtask3(folder_train, labels_train_fn, train_span)\n",
    "print('Loading dev...')\n",
    "test=make_dataframe_subtask3(folder_dev, labels_test_fn, test_span)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "executionInfo": {
     "elapsed": 13,
     "status": "ok",
     "timestamp": 1671050266280,
     "user": {
      "displayName": "Katarzyna Baraniak",
      "userId": "09959407714606546607"
     },
     "user_tz": -60
    },
    "id": "Z7namsVGMJ5t",
    "outputId": "0f434e79-b639-4e80-b438-1181e996ba52"
   },
   "outputs": [],
   "source": [
    "train.reset_index(inplace=True)\n",
    "test.reset_index(inplace=True)\n",
    "\n",
    "train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Change span to IO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import spacy\n",
    "\n",
    "\n",
    "#add spacy model for chosen language\n",
    "if lang==\"po\":\n",
    "    nlp = spacy.load(\"pl_core_news_sm\")\n",
    "if lang==\"en\":\n",
    "    nlp = spacy.load(\"en_core_web_sm\")\n",
    "    \n",
    "train[\"tokens\"]=\"\"\n",
    "train[\"pos\"]=\"\"\n",
    "train[\"mani_tags\"]=\"\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#train\n",
    "for i, (sentence, annotations) in enumerate(zip(train[\"text\"],train[\"spans\"])):\n",
    "\n",
    "\n",
    "        doc = self.nlp(text)\n",
    "        token_list = []\n",
    "        tag = []\n",
    "\n",
    "        for token in doc:\n",
    "            token_list.append(str(token.text))\n",
    "        # print(token_list)\n",
    "\n",
    "        if len(spans) == 0:\n",
    "\n",
    "            for j in range(0, len(token_list)):\n",
    "                tag.append(\"O\")\n",
    "        else:\n",
    "            start = 0\n",
    "            endprev = 0  # endign of previous tag\n",
    "            ann_mani = pd.DataFrame(spans)\n",
    "            ann_mani = ann_mani.sort_values(\"start\")\n",
    "            token_idx = 0  # count tokend\n",
    "\n",
    "            for j, ann in ann_mani.iterrows():\n",
    "                tag_idx = 0\n",
    "                token_idx = ann[\"start\"]\n",
    "                for token in self.nlp(text[start:ann[\"start\"]].strip()):\n",
    "                    tag.append(\"O\")\n",
    "                    token_idx += 1\n",
    "                for token in self.nlp(text[ann[\"start\"]:ann[\"end\"]].strip()):\n",
    "                    if start <= ann[\"start\"]:  # if end of previous is span is earlier\n",
    "                        start = ann[\"end\"]\n",
    "                        tag_idx = 0\n",
    "\n",
    "                    else:\n",
    "                        tag_idx += 1\n",
    "                        token_idx += 1  # if token is before end of prev we should count it\n",
    "                    if (tag_idx == 0):\n",
    "                        tag.append(\"B-\" + ann[\"label\"])\n",
    "                        token_idx += 1\n",
    "\n",
    "                    elif endprev < token_idx:  # append new I only if prevoious tag end\n",
    "                        tag.append(\"I-\" + ann[\"label\"])\n",
    "                        token_idx += 1\n",
    "                    else:\n",
    "                        token_idx += 1  # count tokens inside previous tag\n",
    "\n",
    "                    tag_idx += 1\n",
    "                start = ann[\"end\"]  # set start at the end of tag sequence\n",
    "                endprev = ann[\"end\"]\n",
    "\n",
    "            for token in self.nlp(text[start:].strip()):\n",
    "                tag.append(\"O\")\n",
    "\n",
    "\n",
    "        train[\"mani_tags\"][i]=tag\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test[\"tokens\"]=\"\"\n",
    "test[\"pos\"]=\"\"\n",
    "test[\"mani_tags\"]=\"\"\n",
    "\n",
    "#test\n",
    "for i, (sentence, annotations) in enumerate(zip(test[\"text\"],test[\"spans\"])):\n",
    "            doc = self.nlp(text)\n",
    "        token_list = []\n",
    "        tag = []\n",
    "\n",
    "        for token in doc:\n",
    "            token_list.append(str(token.text))\n",
    "        # print(token_list)\n",
    "\n",
    "        if len(spans) == 0:\n",
    "\n",
    "            for j in range(0, len(token_list)):\n",
    "                tag.append(\"O\")\n",
    "        else:\n",
    "            start = 0\n",
    "            endprev = 0  # endign of previous tag\n",
    "            ann_mani = pd.DataFrame(spans)\n",
    "            ann_mani = ann_mani.sort_values(\"start\")\n",
    "            token_idx = 0  # count tokend\n",
    "\n",
    "            for j, ann in ann_mani.iterrows():\n",
    "                tag_idx = 0\n",
    "                token_idx = ann[\"start\"]\n",
    "                for token in self.nlp(text[start:ann[\"start\"]].strip()):\n",
    "                    tag.append(\"O\")\n",
    "                    token_idx += 1\n",
    "                for token in self.nlp(text[ann[\"start\"]:ann[\"end\"]].strip()):\n",
    "                    if start <= ann[\"start\"]:  # if end of previous is span is earlier\n",
    "                        start = ann[\"end\"]\n",
    "                        tag_idx = 0\n",
    "\n",
    "                    else:\n",
    "                        tag_idx += 1\n",
    "                        token_idx += 1  # if token is before end of prev we should count it\n",
    "                    if (tag_idx == 0):\n",
    "                        tag.append(\"B-\" + ann[\"label\"])\n",
    "                        token_idx += 1\n",
    "\n",
    "                    elif endprev < token_idx:  # append new I only if prevoious tag end\n",
    "                        tag.append(\"I-\" + ann[\"label\"])\n",
    "                        token_idx += 1\n",
    "                    else:\n",
    "                        token_idx += 1  # count tokens inside previous tag\n",
    "\n",
    "                    tag_idx += 1\n",
    "                start = ann[\"end\"]  # set start at the end of tag sequence\n",
    "                endprev = ann[\"end\"]\n",
    "\n",
    "            for token in self.nlp(text[start:].strip()):\n",
    "                tag.append(\"O\")\n",
    "\n",
    "        test[\"mani_tags\"][i]=tag\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1671050270195,
     "user": {
      "displayName": "Katarzyna Baraniak",
      "userId": "09959407714606546607"
     },
     "user_tz": -60
    },
    "id": "4Qw7RE6u6L4z",
    "outputId": "f6fbb121-7f2f-404f-9311-d20a945a29c6"
   },
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd \n",
    "\n",
    "frames_list=[]\n",
    "for frames in train[\"labels\"]:\n",
    "  fs=frames.split(\",\")\n",
    "  for f in fs:\n",
    "    frames_list.append(f)\n",
    "\n",
    "frames_to_ids = {k: v for v, k in enumerate(set(frames_list))}\n",
    "ids_to_frames = {v: k for v, k in enumerate(set(frames_list))}\n",
    "frames_to_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "tags=[]\n",
    "for tag in train[\"mani_tags\"]:\n",
    "    tags=tags+tag\n",
    "\n",
    "    \n",
    "\n",
    "print(\"Number of tags: {}\".format(len(set(tags))))\n",
    "c = Counter(tags)\n",
    "\n",
    "print( c.items())\n",
    "\n",
    "\n",
    "\n",
    "tags_to_ids = {k: v for v, k in enumerate(set(tags))}\n",
    "ids_to_tags = {v: k for v, k in enumerate(set(tags))}\n",
    "tags_to_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1671050272215,
     "user": {
      "displayName": "Katarzyna Baraniak",
      "userId": "09959407714606546607"
     },
     "user_tz": -60
    },
    "id": "QZZU-1_80GMw"
   },
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "n_labels=len(frames_to_ids)\n",
    "\n",
    "def one_hot_encoder(df):\n",
    "    one_hot_encoding = []\n",
    "    for i in tqdm(range(len(df))):\n",
    "        temp = [0]*n_labels\n",
    "        label_indices = df.iloc[i][\"labels\"].split(\",\")\n",
    "        for index in label_indices:\n",
    "            temp[frames_to_ids[index]] = 1\n",
    "        one_hot_encoding.append(temp)\n",
    "    return pd.DataFrame(one_hot_encoding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 456,
     "referenced_widgets": [
      "da22f896c64c48fbb5f098e1b6cb8cb3",
      "b12494951bae49d29fc7706a2b8a0114",
      "2e6cb11d793040f7940221279053ad1b",
      "81ce3f1390b843778e9d83441f25f72c",
      "7258d508c61e447eb18f3ee1b9393c17",
      "cf3a355dad12440cb799b467a92b7b04",
      "6aab9c00fc0441948ab55483ba849245",
      "498f1ac1fdd64441856eef36bf717276",
      "9a89037cc5a3425e8811fd3de0fa696e",
      "5f4b1b43ff284fabbcb3cedd4acabd2e",
      "9d84110857414d49ba319128e7d9b08f"
     ]
    },
    "executionInfo": {
     "elapsed": 1546,
     "status": "ok",
     "timestamp": 1671050274395,
     "user": {
      "displayName": "Katarzyna Baraniak",
      "userId": "09959407714606546607"
     },
     "user_tz": -60
    },
    "id": "cOHtukdcACMC",
    "outputId": "22b13c57-e463-49da-e847-199887517580"
   },
   "outputs": [],
   "source": [
    "train_ohe_labels = one_hot_encoder(train)\n",
    "test_ohe_labels = one_hot_encoder(test)\n",
    "\n",
    "train_ohe_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "executionInfo": {
     "elapsed": 581,
     "status": "ok",
     "timestamp": 1671050275430,
     "user": {
      "displayName": "Katarzyna Baraniak",
      "userId": "09959407714606546607"
     },
     "user_tz": -60
    },
    "id": "OG_nlSVmaQv1",
    "outputId": "29519264-889f-4954-8f4e-79f2f6ac4265"
   },
   "outputs": [],
   "source": [
    "train = pd.concat([train, train_ohe_labels], axis=1)\n",
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.concat([test, test_ohe_labels], axis=1)\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 509,
     "status": "ok",
     "timestamp": 1671050280024,
     "user": {
      "displayName": "Katarzyna Baraniak",
      "userId": "09959407714606546607"
     },
     "user_tz": -60
    },
    "id": "VfEs2qOoagiR",
    "outputId": "4ad54843-3053-42ca-f019-a4c6a52dbc18"
   },
   "outputs": [],
   "source": [
    "def inspect_category_wise_data(label, n=5):\n",
    "    samples = train[train[label] == 1].sample(n)\n",
    "    sentiment = ids_to_frames[label]\n",
    "    \n",
    "    print(f\"{n} samples from {sentiment} sentiment: \\n\")\n",
    "    for text in samples[\"text\"]:\n",
    "        print(text, end='\\n\\n')\n",
    "\n",
    "inspect_category_wise_data(4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 14,
     "status": "ok",
     "timestamp": 1671050288033,
     "user": {
      "displayName": "Katarzyna Baraniak",
      "userId": "09959407714606546607"
     },
     "user_tz": -60
    },
    "id": "5td1GntgXH-L"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 14,
     "status": "ok",
     "timestamp": 1671050288034,
     "user": {
      "displayName": "Katarzyna Baraniak",
      "userId": "09959407714606546607"
     },
     "user_tz": -60
    },
    "id": "CoVZ8gEEXIAe"
   },
   "outputs": [],
   "source": [
    "BERT_MODEL =\"\" ## add your BERT MODEL\n",
    "\n",
    "from transformers import AutoTokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(BERT_MODEL,local_files_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 23,
     "status": "ok",
     "timestamp": 1671035680384,
     "user": {
      "displayName": "Katarzyna Baraniak",
      "userId": "09959407714606546607"
     },
     "user_tz": -60
    },
    "id": "EOsl0eC726Ui"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 13,
     "status": "ok",
     "timestamp": 1671050288034,
     "user": {
      "displayName": "Katarzyna Baraniak",
      "userId": "09959407714606546607"
     },
     "user_tz": -60
    },
    "id": "XHukMTKbv4uo"
   },
   "outputs": [],
   "source": [
    "import transformers\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FvWMiNa0eO0W"
   },
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1671050288670,
     "user": {
      "displayName": "Katarzyna Baraniak",
      "userId": "09959407714606546607"
     },
     "user_tz": -60
    },
    "id": "a81w8AI5eMxN"
   },
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "\n",
    "class PropagandaClassifier(nn.Module):\n",
    "    def __init__(self, n_classes,num_labels, do_prob, bert_model):\n",
    "        super(PropagandaClassifier, self).__init__()\n",
    "        self.bert = BertModel.from_pretrained(bert_model,local_files_only=True)\n",
    "        \n",
    "\n",
    "        self.dropout = nn.Dropout(do_prob)\n",
    "        self.out = nn.Linear(768, n_classes)\n",
    "        \n",
    "        self.dropout2 = nn.Dropout(do_prob)\n",
    "        self.tagger = nn.Linear(768, num_labels)\n",
    "        self.m=nn.Softmax( dim=2)\n",
    "       \n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        output_bert = self.bert(input_ids, attention_mask=attention_mask)\n",
    "        \n",
    "        \n",
    "        #tokens\n",
    "        output_tag1=self.dropout(output_bert[0])\n",
    "        output_tag=self.tagger(output_tag1)\n",
    "       \n",
    "        softm=self.m(output_tag)\n",
    "        \n",
    "        indexes=torch.argmax(softm, axis=2)\n",
    "        \n",
    "        ind=[]\n",
    "        for i in range(0, indexes.shape[0]):\n",
    "            one=False\n",
    "            for j in range(0, indexes.shape[1]):\n",
    "                \n",
    "                if indexes[i,j]==1:\n",
    "                    ind.append(j)\n",
    "                    one=True\n",
    "                    break\n",
    "            if one==False: #jesli brak 1 to tez chcemy miec index\n",
    "                ind.append(0)\n",
    "    \n",
    "        a=torch.range(0,len(indexes)-1,dtype=torch.long)\n",
    "        \n",
    "        output_1=output_bert[0][a,ind, :]\n",
    "        output_2 = self.dropout(output_1)\n",
    "        output = self.out(output_2)\n",
    "        return output, output_tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2702,
     "status": "ok",
     "timestamp": 1671050294782,
     "user": {
      "displayName": "Katarzyna Baraniak",
      "userId": "09959407714606546607"
     },
     "user_tz": -60
    },
    "id": "iPdwbNWFop8r",
    "outputId": "1fe3d3c2-ea99-421d-f3ed-2eeb9de80f28"
   },
   "outputs": [],
   "source": [
    "from transformers import BertTokenizerFast, BertConfig, BertModel\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hQjYLllc1rgW"
   },
   "source": [
    "## Prepare dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1671050294782,
     "user": {
      "displayName": "Katarzyna Baraniak",
      "userId": "09959407714606546607"
     },
     "user_tz": -60
    },
    "id": "O0SA74jC01gh"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import AutoTokenizer\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class MyDataset(Dataset):\n",
    "\n",
    "  def __init__(self,df, tokenizer, max_len):\n",
    "    \n",
    "    self.article=df[\"text\"]#[t.lower() for t in df[\"text\"]]\n",
    "    \n",
    "\n",
    "    self.tokenizer=tokenizer\n",
    "    self.max_len=max_len\n",
    "    self.id= df[\"id\"]\n",
    "    self.line=df[\"line\"]\n",
    "\n",
    "    if \"labels\" in df.columns:\n",
    "       self.labels=df[range(len(frames_to_ids))].values.tolist()\n",
    "    else:\n",
    "      self.labels=[]\n",
    "    self.mani_tags=[]\n",
    "    if \"mani_tags\" in df.columns:\n",
    "        self.mani_tags=df[\"mani_tags\"]\n",
    "  def __len__(self):\n",
    "    return len(self.article)\n",
    "  \n",
    "  def __getitem__(self,idx):\n",
    "    if len(self.labels)>0:\n",
    "      labels=self.labels[idx]\n",
    "    else:\n",
    "      labels=0\n",
    "    if len( self.mani_tags)>0:\n",
    "        token_word_labels = self.mani_tags[idx][0].split(\",\") \n",
    "        token_labels = [tags_to_ids[label] for label in token_word_labels] \n",
    "    else:\n",
    "        token_labels=[]\n",
    "    idart=self.id[idx]\n",
    "    line=self.line[idx]\n",
    "     # print(labels)\n",
    "    encoding = self.tokenizer(self.article[idx],\n",
    "                             is_split_into_words=False,\n",
    "                             #is_pretokenized=True, \n",
    "                             return_offsets_mapping=True, \n",
    "                             padding='max_length', \n",
    "                             truncation=True, \n",
    "                             max_length=self.max_len)#.set_format(\"torch\")\n",
    "\n",
    "    # create an empty array of -100 of length max_length\n",
    "    encoded_labels = np.ones(len(encoding[\"offset_mapping\"]), dtype=int) * -100\n",
    "        \n",
    "    i = -1\n",
    "    if len( self.mani_tags)>0:\n",
    "        for idx, mapping in enumerate(encoding[\"offset_mapping\"]):\n",
    "    \n",
    "                if mapping[1]!=0:# next\n",
    "                    if mapping[0] == 0:#only if begginign of a word\n",
    "                        i += 1\n",
    "                    encoded_labels[idx] = token_labels[i]\n",
    "\n",
    "    \n",
    "\n",
    "   \n",
    "    \n",
    "\n",
    "    items = {key: torch.as_tensor(val) for key, val in encoding.items()}\n",
    "    items[\"labels\"]=torch.as_tensor(labels) \n",
    "    items[\"id\"]=idart\n",
    "    items[\"line\"]=line\n",
    "    items['token_labels'] = torch.as_tensor(encoded_labels)\n",
    "\n",
    "\n",
    "    \n",
    "    return items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 1120,
     "status": "ok",
     "timestamp": 1671050308939,
     "user": {
      "displayName": "Katarzyna Baraniak",
      "userId": "09959407714606546607"
     },
     "user_tz": -60
    },
    "id": "SqYGM2sY01h-"
   },
   "outputs": [],
   "source": [
    "#setup\n",
    "\n",
    "MAX_LEN = 256\n",
    "TRAIN_BATCH_SIZE = 8\n",
    "VALID_BATCH_SIZE = 8\n",
    "EPOCHS = 30\n",
    "LEARNING_RATE = 1e-05\n",
    "MAX_GRAD_NORM = 10\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train_test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"TRAIN Dataset: {}\".format(train.shape))\n",
    "print(\"TEST Dataset: {}\".format(test.shape))\n",
    "training_set = MyDataset(train, tokenizer, MAX_LEN)\n",
    "test_set = MyDataset(test, tokenizer, MAX_LEN)\n",
    "\n",
    "# # myDs=MyDataset(bias_lexical, tokenizer)\n",
    "train_loader=DataLoader(training_set,batch_size=TRAIN_BATCH_SIZE,shuffle=True)\n",
    "test_loader=DataLoader(test_set,batch_size=VALID_BATCH_SIZE, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dnQU65IQFBGM"
   },
   "source": [
    "## log metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 418,
     "status": "ok",
     "timestamp": 1671050333502,
     "user": {
      "displayName": "Katarzyna Baraniak",
      "userId": "09959407714606546607"
     },
     "user_tz": -60
    },
    "id": "ypbE4GDconNa"
   },
   "outputs": [],
   "source": [
    "from sklearn import metrics, model_selection, preprocessing\n",
    "from sklearn.metrics import precision_recall_fscore_support as score\n",
    "\n",
    "\n",
    "def log_metrics(preds, labels):\n",
    "    preds = torch.stack(preds)\n",
    "    # print(preds)\n",
    "    preds = preds.cpu().detach().numpy()\n",
    "    # print(preds)\n",
    "    labels = torch.stack(labels)\n",
    "    labels = labels.cpu().detach().numpy()\n",
    "\n",
    "\n",
    "    preds=preds >0.5\n",
    "    class_rep=classification_report( labels, preds, target_names= frames_to_ids.keys())\n",
    "    print(class_rep)\n",
    "    precision,recall,fscore,support=score(labels, preds,average='micro')\n",
    "    precision,recall,fscore_macro,support=score(labels, preds,average='macro')\n",
    "\n",
    "    return {\"f1_micro\":fscore, \"f1_macro\":fscore_macro}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 912,
     "status": "ok",
     "timestamp": 1671050340101,
     "user": {
      "displayName": "Katarzyna Baraniak",
      "userId": "09959407714606546607"
     },
     "user_tz": -60
    },
    "id": "4e7o3x9g01mB"
   },
   "outputs": [],
   "source": [
    "from transformers import BertTokenizerFast, BertConfig, BertModel\n",
    "from torch.nn import CrossEntropyLoss\n",
    "# from transformers.models.bert.modeling_bert import BertModel\n",
    "from transformers.models.bert import BertPreTrainedModel\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def training(epoch, test=True):\n",
    "    tr_loss, tr_accuracy = 0, 0\n",
    "    nb_tr_examples, nb_tr_steps = 0, 0\n",
    "    tr_preds, tr_labels = [], []\n",
    "    # put model in training mode\n",
    "    model.train()\n",
    "    print(\"Start\")\n",
    "    for idx, batch in enumerate(train_loader):\n",
    "\n",
    "       \n",
    "\n",
    "        ids = batch['input_ids'].to(device, dtype = torch.long)\n",
    "        mask = batch['attention_mask'].to(device, dtype = torch.long)\n",
    "        labels = batch['labels'].to(device, dtype = torch.long)\n",
    "        tag_labels=batch['token_labels'].to(device, dtype = torch.long)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        \n",
    "        output, output_tokens = model(input_ids=ids, attention_mask=mask)\n",
    "        \n",
    "        loss_sequence = loss_fct(output, labels.float())\n",
    "        loss_tokens = loss_fct2(output_tokens.view(-1, len(tags_to_ids)), tag_labels.view(-1))\n",
    "\n",
    "        loss=loss_sequence+loss_tokens*0.5\n",
    "        tr_loss += loss.item()\n",
    "        \n",
    "        tr_logits=output\n",
    "\n",
    "        nb_tr_steps += 1\n",
    "        nb_tr_examples += labels.size(0)\n",
    "        \n",
    "        if idx % 100==0:\n",
    "            loss_step = tr_loss/nb_tr_steps\n",
    "            print(f\"Training loss per 100 training steps: {loss_step}\")\n",
    "           \n",
    "    \n",
    "        # gradient clipping\n",
    "        torch.nn.utils.clip_grad_norm_(\n",
    "            parameters=model.parameters(), max_norm=MAX_GRAD_NORM\n",
    "        )\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        \n",
    "\n",
    "    epoch_loss = tr_loss / nb_tr_steps\n",
    "    tr_accuracy = tr_accuracy / nb_tr_steps\n",
    "    print(f\"Training loss epoch: {epoch_loss}\")\n",
    "    print(f\"Training accuracy epoch: {tr_accuracy}\")\n",
    "\n",
    "    \n",
    "    print(\"Training eval\")\n",
    "    model.eval()\n",
    "    tr_preds, tr_labels = [], []\n",
    "    loss=0\n",
    "    for batch in train_loader:\n",
    "      \n",
    "      ids = batch['input_ids'].to(device, dtype = torch.long)\n",
    "      mask = batch['attention_mask'].to(device, dtype = torch.long)\n",
    "      labels = batch['labels'].to(device, dtype = torch.long)\n",
    "      tag_labels=batch['token_labels'].to(device, dtype = torch.long)\n",
    "\n",
    "      with torch.no_grad():\n",
    "          output, output_tokens = model(input_ids=ids, attention_mask=mask,)\n",
    "          loss+=loss_fct(output, labels.float())\n",
    "          \n",
    "\n",
    "          preds=torch.sigmoid(output)>0.5\n",
    "          tr_labels +=[lab.cpu() for lab in labels ]\n",
    "          tr_preds+=[lab for lab in preds ]\n",
    "         \n",
    "    \n",
    "    loss_train=loss/len(train_loader)\n",
    "    print(loss_train)\n",
    "    res=log_metrics(tr_preds, tr_labels)\n",
    "\n",
    "    print(\"Test eval\")\n",
    "    model.eval()\n",
    "    tr_preds, tr_labels = [], []\n",
    "    loss=0\n",
    "    if test:\n",
    "      for batch in test_loader:\n",
    "        ids = batch['input_ids'].to(device, dtype = torch.long)\n",
    "        mask = batch['attention_mask'].to(device, dtype = torch.long)\n",
    "        labels = batch['labels'].to(device, dtype = torch.long)\n",
    "        tag_labels=batch['token_labels'].to(device, dtype = torch.long)\n",
    "\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            \n",
    "            output, output_tokens = model(input_ids=ids, attention_mask=mask,)\n",
    "            loss+=loss_fct(output, labels.float())\n",
    "            preds=torch.sigmoid(output)>0.5\n",
    "            tr_labels.extend(labels)\n",
    "            tr_preds.extend(preds)\n",
    "            \n",
    "      loss_test=loss/len(test_loader)\n",
    "      res_test=log_metrics(tr_preds, tr_labels)\n",
    "      print(loss_test)\n",
    "      return loss_train, loss_test, res[\"f1_micro\"], res[\"f1_macro\"], res_test[\"f1_micro\"], res_test[\"f1_macro\"]\n",
    "    else:\n",
    "      return loss_train, 0, res[\"f1_micro\"],res[\"f1_macro\"], 0,0\n",
    "\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_weights=[]\n",
    "for i in range(len(frames_to_ids)):\n",
    "    class_weights.append((len(train)-sum(train[i]))/sum(train[i]))\n",
    "class_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5vkgUNgq0130",
    "outputId": "9f927c9e-6607-4fb5-ff56-994b1b48e344",
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_loss_history=[]\n",
    "test_loss_history=[]\n",
    "train_f1micro_history=[]\n",
    "test_f1micro_history=[]\n",
    "\n",
    "model= PropagandaClassifier(len(frames_to_ids),len(tags_to_ids), 0.1, BERT_MODEL)\n",
    "model=model.to(device)\n",
    "\n",
    "\n",
    "optimizer = torch.optim.Adam(params=model.parameters(), lr=LEARNING_RATE, weight_decay=0.01) # AdamW\n",
    "\n",
    "class_weights=torch.as_tensor(class_weights).to(device, dtype = torch.float)\n",
    "\n",
    "loss_fct =  nn.BCEWithLogitsLoss(pos_weight=class_weights)\n",
    "\n",
    "loss_fct2 =  nn.CrossEntropyLoss()\n",
    "\n",
    "\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    print(f\"Training epoch: {epoch + 1}\")\n",
    "    loss_tr, loss_te, f1_tr, f1_te=training(epoch)\n",
    "    print(loss_tr, loss_te, f1_tr, f1_te)\n",
    "    train_loss_history.append(loss_tr)\n",
    "    test_loss_history.append(loss_te)\n",
    "    train_f1micro_history.append(f1_tr)\n",
    "    test_f1micro_history.append(f1_te)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "E96DITIBrvDV"
   },
   "outputs": [],
   "source": [
    "train_loss_history=[t.item() for t in train_loss_history]\n",
    "test_loss_history=[t.item() for t in test_loss_history]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(train_loss_history, \"--\")\n",
    "plt.plot(test_loss_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 283
    },
    "executionInfo": {
     "elapsed": 17,
     "status": "ok",
     "timestamp": 1671044051391,
     "user": {
      "displayName": "Katarzyna Baraniak",
      "userId": "09959407714606546607"
     },
     "user_tz": -60
    },
    "id": "jI1Bt3wh07Pm",
    "outputId": "b212e614-e2fc-46e2-882b-ff7ab18c64d7"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(train_f1micro_history, \"o\")\n",
    "plt.plot(test_f1micro_history)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyPrZYEk1sZ9UG8sS8kvwY3Y",
   "machine_shape": "hm",
   "mount_file_id": "1lZWuHlVDHleipPAfhRLHEheh_XBUftLd",
   "provenance": [],
   "toc_visible": true
  },
  "gpuClass": "premium",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "2e6cb11d793040f7940221279053ad1b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_498f1ac1fdd64441856eef36bf717276",
      "max": 3760,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_9a89037cc5a3425e8811fd3de0fa696e",
      "value": 3760
     }
    },
    "498f1ac1fdd64441856eef36bf717276": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5f4b1b43ff284fabbcb3cedd4acabd2e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6aab9c00fc0441948ab55483ba849245": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "7258d508c61e447eb18f3ee1b9393c17": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "81ce3f1390b843778e9d83441f25f72c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5f4b1b43ff284fabbcb3cedd4acabd2e",
      "placeholder": "​",
      "style": "IPY_MODEL_9d84110857414d49ba319128e7d9b08f",
      "value": " 3760/3760 [00:00&lt;00:00, 10995.59it/s]"
     }
    },
    "9a89037cc5a3425e8811fd3de0fa696e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "9d84110857414d49ba319128e7d9b08f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "b12494951bae49d29fc7706a2b8a0114": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_cf3a355dad12440cb799b467a92b7b04",
      "placeholder": "​",
      "style": "IPY_MODEL_6aab9c00fc0441948ab55483ba849245",
      "value": "100%"
     }
    },
    "cf3a355dad12440cb799b467a92b7b04": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "da22f896c64c48fbb5f098e1b6cb8cb3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_b12494951bae49d29fc7706a2b8a0114",
       "IPY_MODEL_2e6cb11d793040f7940221279053ad1b",
       "IPY_MODEL_81ce3f1390b843778e9d83441f25f72c"
      ],
      "layout": "IPY_MODEL_7258d508c61e447eb18f3ee1b9393c17"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
